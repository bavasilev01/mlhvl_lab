{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgTwEqqdRL6S"
      },
      "source": [
        "# Sequence Processing with Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuI5RQwyRL6U"
      },
      "source": [
        "## Background\n",
        "\n",
        "So far, we have seen how word vectors can be constructed from corpus statistics, and how they can be utilized to infer latent semantic content either in isolation (e.g. genders from names) or in relation to one another (e.g. similarities and analogies).\n",
        "\n",
        "For tasks involving larger linguistic units such as phrases, sentences and dialogues, we need machinery capable of processing _sequences_ or _structures_ of words.\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are an example of such machinery. For this assignment, you will construct a recurrent neural network that will predict properties of the upcoming (not yet seen) text. You know this situation from language models, which try to predict the next word in a sequence given context. What language models do is provide a conditional probability distribution over the whole vocabulary of the upcoming word. Here, however, we will simplify our life. Rather than trying to predict the upcoming word, **we will construct a recurrent neural network that will predict the part-of-speech tag (POS tag) of the upcoming word.** That is, the network will build a conditional probability distribution over the full list of POS tags of the upcoming word given the preceding context.\n",
        "\n",
        "Let's look at a few examples to make it clear what the model will be doing and to gauge intuion on how difficult this is. Sometimes, the task can be fairly easy. For instance, if the sentence starts as 'I want to...' then the next POS tag (the POS tag of the next word given this context) is very likely to be a verb in its base form (e.g., 'sleep'). Other times, it is harder. For instance, if the context is 'John left...' the continuation could be almost any POS tag, from the period (which has its own tag) to a preposition (as in 'John left at noon') through pronouns (as in 'John left us') to determiners (as in 'John left the city').\n",
        "\n",
        "This task can be seen as simplified case of using an RNN as a language model. A good reference point for RNNs as language models and for RNNs as labellers of POS tags is in Jurafsky and Martin [Chapter 8](https://web.stanford.edu/~jurafsky/slp3/8.pdf).\n",
        "\n",
        "You might wonder why anyone would bother modeling such prediction. One reason is that the resulting model can be seen as approximating human behavior, in this case, human behavior in reading and listening. It is a well-known fact that when we process text (or speech), we do not just passively wait for the incoming information. We are immediately interpreting and we predict what will be coming next. This prediction has various levels of abstraction: we might predict concrete words, but we also predict abstract properties of such words, such as gender or their phonological structures. The task that you do here can be seen as one step in this prediction process. We will try to see whether the resulting RNN model is in any way similar to humans.\n",
        "\n",
        "We will take a gradual approach, first inspecting recurrent neural networks, then moving on to data processing using high-grade word vectors before finally moving to the problem at hand.\n",
        "\n",
        "---\n",
        "\n",
        "There are 10 tasks in this assignment. Each comes with its sub-tasks and point distribution. The total of points is 40.\n",
        "\n",
        "---\n",
        "\n",
        "You are greatly encouraged to add comments to your code describing what particular lines of code do (in general, a great habit to have in your coding life).\n",
        "Additionally please follow these rules when submitting the notebook:\n",
        "\n",
        "* Put all code in the cell with the `# YOUR CODE HERE` comment or `NotImplemented`.\n",
        "* For theoretical questions, put your solution in the `YOUR ANSWER HERE` cell and keep the header(!).\n",
        "* Don't change or delete any initially provided cells, either text or code, unless explicitly instructed to do so.\n",
        "* Don't delete the comment lines `# TEST...` or edit their code cells. The test cells are for sanity checking. Passing them doesn't necessarily mean that your code is fine.\n",
        "* Don't change the names of provided functions and variables or arguments of the functions.\n",
        "* Don't clear the output of your code cells.\n",
        "* Don't output unnecessary info (e.g., printing variables for debugging purposes). This clutters the notebook and slows down the grading. You can have print() in the code, but comment them out before submitting the notebook.\n",
        "* Delete those cells that you inserted for your own debugging/testing purposes.\n",
        "* Don't forget to fill in the contribution information.\n",
        "* Test your code and **make sure we can run your notebook** in the colab environment.\n",
        "* A single notebook file (without archiving) per group should be submitted via BB.\n",
        "\n",
        "<font color=\"red\">Following these rules helps us to grade the submissions relatively efficiently. If these rules are violated, a submission will be subject to penalty points.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75FoL1vxRL6W"
      },
      "source": [
        "# <font color=\"red\">Contributions</font>\n",
        "\n",
        "~~Delete this text and write instead of it your:~~\n",
        "* ~~a list of group members names (NOT student IDs)~~\n",
        "* ~~who contributed to which exercises (you don't need to be very detailed)~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kx4_6SCRL6X"
      },
      "source": [
        "## Recurrent Neural Networks\n",
        "Recurrent Neural Networks are a particularly interesting class of neural networks. Unlike standard fully-connected networks that accept a fixed-size input and produce a fixed-size output over a predefined number of computational steps (i.e. network layers), RNNs instead operate on sequences of vectors.\n",
        "\n",
        "Computationally, feedforward networks may be seen as a trainable (but parametrically fixed) function, whereas RNNs act as continuous, stateful programs operating on sequences of inputs.\n",
        "Cognitively, this may be viewed as enhancing our system's perceptive and computational abilities with a notion of memory.\n",
        "In the general case, this statefulness is captured by an intermediate hidden vector which is adjusted throughout the computation, affected by both the immediately previous version of itself __and__ the current input.\n",
        "\n",
        "RNNs are nowadays established as the core machinery of neural sequence processing.\n",
        "\n",
        "A simple recurrent network (SRN or Elman network) is described by the equations:\n",
        "* $h_t = \\theta_h (W_h x_t + U_h h_{t-1} + b_h ) $\n",
        "* $y_t = \\theta_y (W_y h_t + b_y) $\n",
        "\n",
        "where (at timestep $t$) $x_t$, $h_t$, $y_t$ are the network's input, hidden and output representations respectively, $\\theta_h$, $\\theta_y$ are its hidden and output activation functions, and $W_h$, $U_h$, $b_h$, $W_y$, $b_y$ are the parametric tensors to be learned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yz0cCHVARL6Y",
        "lines_to_next_cell": 1
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch ver=2.1.2\n",
            "numpy ver=1.24.3\n",
            "spacy ver=3.7.2\n"
          ]
        }
      ],
      "source": [
        "# Importing - all packages needed in this assignment\n",
        "\n",
        "# numpy for data analysis - should be lower than 2.0, otherwise there are compatibility issues with spacy;\n",
        "\n",
        "import pickle # pickle for loading existing python objects\n",
        "from collections import Counter, defaultdict # counter for simple counting models\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# torch - for NNs\n",
        "import torch\n",
        "print(f\"torch ver={torch.__version__}\\nnumpy ver={np.__version__}\")\n",
        "from torch import FloatTensor, LongTensor\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# sklearn for easy split of training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# matplotlib for plotting results\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# typing to indicate types in code\n",
        "from typing import Tuple, List, Callable, Optional, Dict\n",
        "torch.set_printoptions(precision=8) #to increase precision of printing floats\n",
        "\n",
        "# spacy for pretrained vectors\n",
        "import spacy\n",
        "print(f\"spacy ver={spacy.__version__}\")\n",
        "\n",
        "# tqdm to show progress bars during (long) loops\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17TG_mDURL6Z"
      },
      "source": [
        "We will use the following function to concisely convert torch tensors to numpy arrays before printing tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Po28H1R9RL6a"
      },
      "outputs": [],
      "source": [
        "# Conversion between tensor and np\n",
        "def tr2np(tensor):\n",
        "    \"\"\"Convert torch tensor into numpy array\"\"\"\n",
        "    return tensor.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bvOLGYzW0bVR"
      },
      "outputs": [],
      "source": [
        "# define a global variable for processing unit\n",
        "# set it to cuda if gpu is available\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF_pqTSdRL6b"
      },
      "source": [
        "### Our own SRN\n",
        "Let's make our own simple recurrent network from scratch, to get an idea of its inner workings. To make our life just a bit simpler, we will use `torch.nn.Linear` to model the internal transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNZzwc28RL6b"
      },
      "source": [
        "#### TASK 1\n",
        "Complete the `mySRN` class, which is initialized with the input $d_i$, hidden $d_h$ and output $d_o$ dimensionalities, as well as two non-linear functions $\\theta_h$ and $\\theta_y$, and constructs an SRN implementing three `torch.nn.Linear` layers:\n",
        "1. `x_to_h`: a layer that takes $x_t$ and produces $W_h x_t$\n",
        "2. `h_to_h`: a layer that takes $h_{t-1}$ and produces $U_h h_{t-1} + b_h$\n",
        "3. `h_to_y`: a layer that takes $h_t$ and produces $W_y h_t + b_y$\n",
        "\n",
        "Implement the function `step` that performs a computational step, accepting $x_t$ and $h_{t-1}$ and producing $h_t$ and $y_t$.\n",
        "\n",
        "Implement the function `forward` that accepts a List of inputs $X$, an initial hidden vector $h_{-1}$ and iteratively applies `step` until the input sequence is exhausted, returning a List of outputs $Y$ (of the same length as $X$).\n",
        "\n",
        "<font color=\"red\">_Hint_: Note that `x_to_h` does not have a bias term $b$, since we will incorporate it into `h_to_h`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4yOU88kPRL6c",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# @title c1 [2pt]\n",
        "# simple and slow RNN\n",
        "\n",
        "class MySRN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    SRN module, hand-coded.\n",
        "    The dimension and activation argumenst are self-descriptive.\n",
        "    device points to the device ('cpu' or 'cuda') on which the tensors and computations on them will be allocated.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int,\n",
        "        output_dim: int,\n",
        "        hidden_activation: Callable[[FloatTensor], FloatTensor],\n",
        "        output_activation: Callable[[FloatTensor], FloatTensor],\n",
        "        device: str = 'cpu',\n",
        "        seed: int = 42\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.output_activation = output_activation\n",
        "        self.device = device\n",
        "        #\n",
        "        torch.manual_seed(seed)\n",
        "        self.x_to_h = torch.nn.Linear(input_dim, hidden_dim, bias=False)\n",
        "        self.h_to_h = torch.nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.h_to_y = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def step(self, x: FloatTensor, hprev: FloatTensor) -> Tuple[FloatTensor, FloatTensor]:\n",
        "        \"\"\"\n",
        "        step performs a computational step, accepting x_t and hprev (h_{t-1}) and producing h_t and y_t\n",
        "        \"\"\"\n",
        "        h_t = self.hidden_activation(self.x_to_h(x) + self.h_to_h(hprev))\n",
        "        y_t = self.output_activation(self.h_to_y(h_t))\n",
        "        return h_t, y_t\n",
        "\n",
        "    def forward(self, X: List[FloatTensor], hprev: FloatTensor) -> List[FloatTensor]:\n",
        "        \"\"\"\n",
        "        forward accepts a List of inputs X, an initial hidden vector hprev (h_{tâˆ’1}) and\n",
        "        iteratively applies step until the input sequence is exhausted,\n",
        "        returning a List of outputs Y (of the same length as X).\n",
        "        \"\"\"\n",
        "        Y = []\n",
        "        h_t = hprev\n",
        "        for x_t in X:\n",
        "            h_t, y_t = self.step(x_t, h_t)\n",
        "            Y.append(y_t.detach())\n",
        "        return Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAS-KhboRL6d"
      },
      "source": [
        "The following toy RNN helps you to verify whether your implementation is correct.  \n",
        "Use the numbers below in the functions, and you can manually verify the output of the RNN.  \n",
        "This manual check will help you to see whether you are understanding the calculations behind the RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KDlZ1uyeRL6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X->H \n",
            "matrix:\n",
            " [[ 0.4414065   0.47920525 -0.13525727]\n",
            " [ 0.53036046 -0.1264995   0.11650389]] \n",
            "bias: None\n",
            "H->H \n",
            "matrix:\n",
            " [[-0.3442585   0.41527158]\n",
            " [ 0.62334496 -0.5187534 ]] \n",
            "bias: [0.61461455 0.13234162]\n",
            "H->Y \n",
            "matrix:\n",
            " [[0.5224168  0.09576386]] \n",
            "bias: [0.34095842]\n",
            "output:\n",
            " [tensor([0.66232765]), tensor([0.94909447])]\n"
          ]
        }
      ],
      "source": [
        "# TEST c1\n",
        "# note that the default seed parameter makes output of the cell deterministic\n",
        "# create our RNN with some short dimensions\n",
        "my_rnn = MySRN(3, 2, 1, torch.nn.ReLU(), torch.nn.ReLU(), device='cpu')\n",
        "\n",
        "# printing initilized weights and biases\n",
        "print(\"X->H\", \"\\nmatrix:\\n\", tr2np(my_rnn.x_to_h.weight), \"\\nbias:\", my_rnn.x_to_h.bias)\n",
        "print(\"H->H\", \"\\nmatrix:\\n\", tr2np(my_rnn.h_to_h.weight), \"\\nbias:\", tr2np(my_rnn.h_to_h.bias))\n",
        "print(\"H->Y\", \"\\nmatrix:\\n\", tr2np(my_rnn.h_to_y.weight), \"\\nbias:\", tr2np(my_rnn.h_to_y.bias))\n",
        "\n",
        "# running the RNN on a sample input of size 2 and an initial hidden vector\n",
        "output = my_rnn.forward([FloatTensor([0,0,1]), FloatTensor([1,0,0])],\n",
        "                         FloatTensor([1,1]))\n",
        "\n",
        "print(\"output:\\n\", output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jcbrmViRL6e"
      },
      "source": [
        "In practice, we do not need to write our own functions for common RNN architectures.\n",
        "Torch already provides the [necessary abstractions](https://pytorch.org/docs/stable/nn.html#recurrent-layers).\n",
        "\n",
        "The [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN) wrapper implements highly optimized forward routines to compute the hidden representations of a full input sequence.\n",
        "\n",
        "Some pointers:\n",
        "* Unlike our naive implementation, RNN accepts a 3-dimensional tensor of shape (seq_len, batch_shape, input_dim) rather than a list of 2-dimensional tensors\n",
        "* If no initial hidden state is provided, it defaults to a zero tensor\n",
        "* The class produces just the RNN hidden states; it is up to us to define the `h_to_y` transformation on top of them\n",
        "* The non-linearity argument is a string; our only two choices are either `\"tanh\"` or `\"relu\"` (shorthands for `torch.nn.Tanh` and `torch.nn.ReLU` respectively)\n",
        "\n",
        "**Read the documentation (!) for further details.**\n",
        "\n",
        "A brief example is given below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rlIvkgA0RL6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 32, 48])\n"
          ]
        }
      ],
      "source": [
        "rnn = torch.nn.RNN(input_size=16, hidden_size=48, nonlinearity=\"tanh\")\n",
        "X = torch.rand(10, 32, 16)\n",
        "h, _ = rnn(X)\n",
        "print(h.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HJaVCK2RL6f"
      },
      "source": [
        "So, for a random input tensor of shape (seq_len, batch_size, input_dim), we get back an output tensor of shape (seq_len, batch_size, hidden_dim)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YBsmdoLERL6f"
      },
      "outputs": [],
      "source": [
        "#del MySRN, rnn, X, h, my_rnn, output, Uh_b, Wx, h1, y1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G7Ej81tRL6g"
      },
      "source": [
        "#### TASK 2\n",
        "Create a new class, FastSRN, which uses the `RNN` wrapper and the `h_to_y` transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HKZzVy7qRL6g",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# @title c2 [2pt]\n",
        "# faster RNN\n",
        "\n",
        "class FastSRN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    SRN module using RNN class in torch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int,\n",
        "        output_dim: int,\n",
        "        output_activation: Callable[[FloatTensor], FloatTensor],\n",
        "        hidden_activation: str = 'tanh',\n",
        "        num_layers: int = 1,\n",
        "        device: str = 'cpu',\n",
        "        seed: int = 42\n",
        "    ) -> None:\n",
        "        torch.manual_seed(seed)\n",
        "        super(FastSRN, self).__init__()\n",
        "        self.rnn = torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim,\n",
        "                                num_layers=num_layers, nonlinearity=hidden_activation, batch_first=False)\n",
        "        self.h_to_y = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        self.output_activation = output_activation\n",
        "        self.device = device\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, X: FloatTensor, hprev: Optional[FloatTensor] = None) -> FloatTensor:\n",
        "        h, _ = self.rnn(X, hprev)\n",
        "        y = self.h_to_y(h)\n",
        "        y = self.output_activation(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO-9GkJGRL6h"
      },
      "source": [
        "##### Testing the new implementation\n",
        "\n",
        "Let's see our new implementation in action.\n",
        "\n",
        "Initialize a random input tensor $X$ that would correspond to 32 sequences,  each of length 10, with each item having 16 features, and a `fastSRN` fit to process it, producing 42-dimensional hidden states and 2-dimensional output vectors for each sequence item.\n",
        "\n",
        "Run the SRN on the tensor and make sure the output shape is as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gJqR1U1DRL6h"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 32, 2])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TEST c2a\n",
        "fast_srn = FastSRN(input_dim=16, hidden_dim=42, output_dim=2,\n",
        "    output_activation=torch.nn.Softmax(dim=-1), device=\"cpu\"\n",
        ")\n",
        "X = torch.rand(10, 32, 16) # if device='cuda', this needs to be moved to 'cuda'\n",
        "y = fast_srn(X)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOh1zey2RL6h"
      },
      "source": [
        "Again you can verify correctness of your implementation here, and as before, check whether it really does the computations what equations are describing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dHezaxL-RL6i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X->H \n",
            "matrix:\n",
            " [[ 0.5406104   0.5869042  -0.16565567]\n",
            " [ 0.6495562  -0.15492964  0.14268756]] \n",
            "bias: [0.61461455 0.13234162]\n",
            "H->H \n",
            "matrix:\n",
            " [[-0.3442585   0.41527158]\n",
            " [ 0.62334496 -0.5187534 ]] \n",
            "bias: [0.5224168  0.09576386]\n",
            "H->Y \n",
            "matrix:\n",
            " [[ 0.34095842 -0.09983712]\n",
            " [ 0.5450986   0.10451669]] \n",
            "bias: [-0.33010566  0.18024033]\n",
            "output:\n",
            " [[[0.31336898 0.686631  ]]\n",
            "\n",
            " [[0.2535494  0.7464506 ]]]\n"
          ]
        }
      ],
      "source": [
        "# TEST c2b\n",
        "torch.manual_seed(10)\n",
        "# create our RNN with some short dimensions\n",
        "fast_srn = FastSRN(3, 2, 2, output_activation=torch.nn.Softmax(dim=-1), hidden_activation='relu', device='cpu')\n",
        "\n",
        "# printing initilized weights and biases\n",
        "print(\"X->H\", \"\\nmatrix:\\n\", tr2np(fast_srn.rnn.weight_ih_l0), \"\\nbias:\",  tr2np(fast_srn.rnn.bias_ih_l0))\n",
        "print(\"H->H\", \"\\nmatrix:\\n\", tr2np(fast_srn.rnn.weight_hh_l0), \"\\nbias:\", tr2np(fast_srn.rnn.bias_hh_l0))\n",
        "print(\"H->Y\", \"\\nmatrix:\\n\", tr2np(fast_srn.h_to_y.weight), \"\\nbias:\", tr2np(fast_srn.h_to_y.bias))\n",
        "\n",
        "\n",
        "# running the RNN on a sample input of size 2\n",
        "output = fast_srn.forward(torch.FloatTensor([[[0,0,1]], [[1,0,0]]]))\n",
        "\n",
        "print(\"output:\\n\", tr2np(output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ete9S87MRL6j"
      },
      "outputs": [],
      "source": [
        "del fast_srn, X, y, output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdZ-AeXRL6j"
      },
      "source": [
        "You may have noticed a minor complication: in order to utilize batching, we need our input sequences to be of the same length.\n",
        "\n",
        "This, however, is very rarely the case in practice. A common trick against this problem is _padding_; that is, appending zero tensors to all input sequences shorter than the maximum in-batch length to make them all equally long.\n",
        "\n",
        "As usual, torch already does the hard work for us via [pad_sequence](https://pytorch.org/docs/stable/nn.html?highlight=pad%20_sequence#torch.nn.utils.rnn.pad_sequence). Given a list of $N$ 2-dimensional tensors, each of shape (seq\\_len$_n$, input_dim), it will construct a 3-d tensor of shape ($max_{n \\in N}${seq\\_len$_n$}, N, input_dim).\n",
        "\n",
        "An example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Z77usk54RL6j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.rand(1, 3)  # a sequence of 1, 3-dimensional item\n",
        "x2 = torch.rand(4, 3)  # a sequence of 4, 3-dimensional items\n",
        "x3 = torch.rand(2, 3)  # a sequence of 2, 3-dimensional items\n",
        "\n",
        "X = torch.nn.utils.rnn.pad_sequence([x1, x2, x3])\n",
        "\n",
        "# Can you guess what the shape of X is?\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNt7fmQoRL6j"
      },
      "source": [
        "Now compare the contents for better understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1ZUADvl_RL6k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.26963168, 0.44136357, 0.29692084]])\n",
            "tensor([[0.83168548, 0.10531491, 0.26949483],\n",
            "        [0.35881263, 0.19936377, 0.54719156],\n",
            "        [0.00616044, 0.95155454, 0.07526588],\n",
            "        [0.88601369, 0.58320957, 0.33764774]])\n",
            "tensor([[0.80897498, 0.57792538, 0.90398169],\n",
            "        [0.55465984, 0.34231341, 0.63434184]])\n",
            "\n",
            "=================After combining==================\n",
            "\n",
            "tensor([[[0.26963168, 0.44136357, 0.29692084],\n",
            "         [0.83168548, 0.10531491, 0.26949483],\n",
            "         [0.80897498, 0.57792538, 0.90398169]],\n",
            "\n",
            "        [[0.00000000, 0.00000000, 0.00000000],\n",
            "         [0.35881263, 0.19936377, 0.54719156],\n",
            "         [0.55465984, 0.34231341, 0.63434184]],\n",
            "\n",
            "        [[0.00000000, 0.00000000, 0.00000000],\n",
            "         [0.00616044, 0.95155454, 0.07526588],\n",
            "         [0.00000000, 0.00000000, 0.00000000]],\n",
            "\n",
            "        [[0.00000000, 0.00000000, 0.00000000],\n",
            "         [0.88601369, 0.58320957, 0.33764774],\n",
            "         [0.00000000, 0.00000000, 0.00000000]]])\n"
          ]
        }
      ],
      "source": [
        "for i in [x1, x2, x3]: print(i)\n",
        "print(f\"\\n{'After combining':=^50}\\n\\n{X}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UhXM3lW6RL6k"
      },
      "outputs": [],
      "source": [
        "del x1, x2, x3, X, i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAAAEUELRL6k"
      },
      "source": [
        "## Pretrained Word Embeddings\n",
        "In the last assignment, we saw how to train our own word embeddings using a small toy corpus. Now, we will see how to easily get high-quality pretrained word vectors and how to utilize them for further downstream tasks.\n",
        "\n",
        "We are going to use [spaCy](https://spacy.io/). SpaCy is a high-level NLP library that provides a ton of useful functionalities, but we will only focus on its pretrained embeddings for this assignment.\n",
        "\n",
        "Before proceeding, [install spacy](https://spacy.io/usage) using your python package manager (e.g. `pip install spacy`), or it is already preinstalled if using the Colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALmvqUrKRL6l"
      },
      "source": [
        "SpaCy comes with a lot of different-size models for different languages.\n",
        "\n",
        "We will need to download the large English model for the exercises to follow. You can do it by simply running the magic command below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "l7kuR9J2RL6l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "                                              0.0/587.7 MB ? eta -:--:--\n",
            "                                            0.0/587.7 MB 667.8 kB/s eta 0:14:40\n",
            "                                              0.3/587.7 MB 3.0 MB/s eta 0:03:18\n",
            "                                              0.5/587.7 MB 4.2 MB/s eta 0:02:21\n",
            "                                              0.9/587.7 MB 5.0 MB/s eta 0:01:58\n",
            "                                              1.3/587.7 MB 5.5 MB/s eta 0:01:47\n",
            "                                              1.8/587.7 MB 6.3 MB/s eta 0:01:33\n",
            "                                              2.2/587.7 MB 6.8 MB/s eta 0:01:27\n",
            "                                              2.6/587.7 MB 7.0 MB/s eta 0:01:24\n",
            "                                              3.0/587.7 MB 7.0 MB/s eta 0:01:24\n",
            "                                              3.3/587.7 MB 7.0 MB/s eta 0:01:24\n",
            "                                              3.5/587.7 MB 6.8 MB/s eta 0:01:26\n",
            "                                              4.0/587.7 MB 7.1 MB/s eta 0:01:23\n",
            "                                              4.4/587.7 MB 7.4 MB/s eta 0:01:20\n",
            "                                              4.6/587.7 MB 7.1 MB/s eta 0:01:23\n",
            "                                              5.1/587.7 MB 7.2 MB/s eta 0:01:22\n",
            "                                              5.4/587.7 MB 7.3 MB/s eta 0:01:20\n",
            "                                              5.9/587.7 MB 7.5 MB/s eta 0:01:18\n",
            "                                              6.4/587.7 MB 7.6 MB/s eta 0:01:17\n",
            "                                              6.8/587.7 MB 7.6 MB/s eta 0:01:17\n",
            "                                              7.2/587.7 MB 7.6 MB/s eta 0:01:17\n",
            "                                              7.5/587.7 MB 7.8 MB/s eta 0:01:15\n",
            "                                              8.1/587.7 MB 7.8 MB/s eta 0:01:14\n",
            "                                              8.6/587.7 MB 8.0 MB/s eta 0:01:13\n",
            "                                              8.9/587.7 MB 8.0 MB/s eta 0:01:12\n",
            "                                              8.9/587.7 MB 7.7 MB/s eta 0:01:15\n",
            "                                              9.3/587.7 MB 7.7 MB/s eta 0:01:15\n",
            "                                              9.8/587.7 MB 7.8 MB/s eta 0:01:14\n",
            "                                             10.1/587.7 MB 7.8 MB/s eta 0:01:14\n",
            "                                             10.5/587.7 MB 8.3 MB/s eta 0:01:10\n",
            "                                             10.8/587.7 MB 8.4 MB/s eta 0:01:09\n",
            "                                             11.2/587.7 MB 8.3 MB/s eta 0:01:10\n",
            "                                             11.6/587.7 MB 8.3 MB/s eta 0:01:10\n",
            "                                             12.0/587.7 MB 8.2 MB/s eta 0:01:11\n",
            "                                             12.5/587.7 MB 8.3 MB/s eta 0:01:10\n",
            "                                             12.9/587.7 MB 8.2 MB/s eta 0:01:11\n",
            "                                             13.3/587.7 MB 8.3 MB/s eta 0:01:10\n",
            "                                             13.6/587.7 MB 8.3 MB/s eta 0:01:10\n",
            "                                             14.1/587.7 MB 8.4 MB/s eta 0:01:09\n",
            "                                             14.5/587.7 MB 8.4 MB/s eta 0:01:09\n",
            "                                             14.9/587.7 MB 8.6 MB/s eta 0:01:07\n",
            "     -                                       15.3/587.7 MB 8.6 MB/s eta 0:01:07\n",
            "     -                                       15.6/587.7 MB 8.5 MB/s eta 0:01:08\n",
            "     -                                       16.1/587.7 MB 8.4 MB/s eta 0:01:09\n",
            "     -                                       16.6/587.7 MB 8.5 MB/s eta 0:01:08\n",
            "     -                                       17.1/587.7 MB 8.6 MB/s eta 0:01:07\n",
            "     -                                       17.5/587.7 MB 8.5 MB/s eta 0:01:08\n",
            "     -                                       17.9/587.7 MB 8.5 MB/s eta 0:01:08\n",
            "     -                                       18.2/587.7 MB 8.5 MB/s eta 0:01:07\n",
            "     -                                       18.5/587.7 MB 8.4 MB/s eta 0:01:08\n",
            "     -                                       18.9/587.7 MB 8.4 MB/s eta 0:01:08\n",
            "     -                                       19.1/587.7 MB 8.2 MB/s eta 0:01:10\n",
            "     -                                       19.5/587.7 MB 8.5 MB/s eta 0:01:07\n",
            "     -                                       19.8/587.7 MB 8.5 MB/s eta 0:01:07\n",
            "     -                                       20.2/587.7 MB 8.3 MB/s eta 0:01:09\n",
            "     -                                       20.4/587.7 MB 8.3 MB/s eta 0:01:09\n",
            "     -                                       20.9/587.7 MB 8.4 MB/s eta 0:01:08\n",
            "     -                                       21.3/587.7 MB 8.4 MB/s eta 0:01:08\n",
            "     -                                       21.7/587.7 MB 8.4 MB/s eta 0:01:08\n",
            "     -                                       21.9/587.7 MB 8.4 MB/s eta 0:01:08\n",
            "     -                                       22.2/587.7 MB 8.3 MB/s eta 0:01:09\n",
            "     -                                       22.7/587.7 MB 8.2 MB/s eta 0:01:10\n",
            "     -                                       23.2/587.7 MB 8.3 MB/s eta 0:01:09\n",
            "     -                                       23.7/587.7 MB 8.4 MB/s eta 0:01:08\n",
            "     -                                       24.2/587.7 MB 8.4 MB/s eta 0:01:08\n",
            "     -                                       24.6/587.7 MB 8.4 MB/s eta 0:01:08\n",
            "     -                                       24.8/587.7 MB 8.3 MB/s eta 0:01:08\n",
            "     -                                       25.3/587.7 MB 8.3 MB/s eta 0:01:08\n",
            "     -                                       25.7/587.7 MB 8.5 MB/s eta 0:01:07\n",
            "     -                                       26.1/587.7 MB 8.3 MB/s eta 0:01:08\n",
            "     -                                       26.6/587.7 MB 8.3 MB/s eta 0:01:08\n",
            "     -                                       26.9/587.7 MB 8.2 MB/s eta 0:01:09\n",
            "     -                                       27.1/587.7 MB 8.3 MB/s eta 0:01:08\n",
            "     -                                       27.7/587.7 MB 8.2 MB/s eta 0:01:09\n",
            "     -                                       28.0/587.7 MB 8.2 MB/s eta 0:01:09\n",
            "     -                                       28.3/587.7 MB 8.2 MB/s eta 0:01:09\n",
            "     -                                       28.6/587.7 MB 8.1 MB/s eta 0:01:10\n",
            "     -                                       29.0/587.7 MB 8.1 MB/s eta 0:01:10\n",
            "     -                                       29.5/587.7 MB 8.3 MB/s eta 0:01:08\n",
            "     -                                       29.9/587.7 MB 8.4 MB/s eta 0:01:07\n",
            "     --                                      30.3/587.7 MB 8.5 MB/s eta 0:01:06\n",
            "     --                                      30.6/587.7 MB 8.5 MB/s eta 0:01:06\n",
            "     --                                      31.1/587.7 MB 8.5 MB/s eta 0:01:06\n",
            "     --                                      31.6/587.7 MB 8.6 MB/s eta 0:01:05\n",
            "     --                                      32.1/587.7 MB 8.6 MB/s eta 0:01:05\n",
            "     --                                      32.4/587.7 MB 8.8 MB/s eta 0:01:03\n",
            "     --                                      32.7/587.7 MB 8.7 MB/s eta 0:01:04\n",
            "     --                                      33.0/587.7 MB 8.5 MB/s eta 0:01:06\n",
            "     --                                      33.4/587.7 MB 8.4 MB/s eta 0:01:07\n",
            "     --                                      33.6/587.7 MB 8.4 MB/s eta 0:01:07\n",
            "     --                                      34.1/587.7 MB 8.3 MB/s eta 0:01:07\n",
            "     --                                      34.4/587.7 MB 8.3 MB/s eta 0:01:07\n",
            "     --                                      34.8/587.7 MB 8.3 MB/s eta 0:01:07\n",
            "     --                                      35.1/587.7 MB 8.3 MB/s eta 0:01:07\n",
            "     --                                      35.5/587.7 MB 8.2 MB/s eta 0:01:08\n",
            "     --                                      35.8/587.7 MB 8.1 MB/s eta 0:01:09\n",
            "     --                                      36.1/587.7 MB 8.1 MB/s eta 0:01:09\n",
            "     --                                      36.4/587.7 MB 8.0 MB/s eta 0:01:10\n",
            "     --                                      36.7/587.7 MB 7.9 MB/s eta 0:01:10\n",
            "     --                                      37.0/587.7 MB 7.9 MB/s eta 0:01:10\n",
            "     --                                      37.3/587.7 MB 7.8 MB/s eta 0:01:11\n",
            "     --                                      37.7/587.7 MB 7.8 MB/s eta 0:01:11\n",
            "     --                                      38.0/587.7 MB 7.8 MB/s eta 0:01:11\n",
            "     --                                      38.4/587.7 MB 7.8 MB/s eta 0:01:11\n",
            "     --                                      38.6/587.7 MB 7.7 MB/s eta 0:01:12\n",
            "     --                                      38.9/587.7 MB 7.7 MB/s eta 0:01:12\n",
            "     --                                      39.2/587.7 MB 7.7 MB/s eta 0:01:12\n",
            "     --                                      39.6/587.7 MB 7.7 MB/s eta 0:01:12\n",
            "     --                                      39.9/587.7 MB 7.4 MB/s eta 0:01:14\n",
            "     --                                      40.1/587.7 MB 7.4 MB/s eta 0:01:15\n",
            "     --                                      40.4/587.7 MB 7.4 MB/s eta 0:01:15\n",
            "     --                                      40.8/587.7 MB 7.3 MB/s eta 0:01:16\n",
            "     --                                      41.1/587.7 MB 7.3 MB/s eta 0:01:16\n",
            "     --                                      41.4/587.7 MB 7.1 MB/s eta 0:01:17\n",
            "     --                                      41.6/587.7 MB 7.1 MB/s eta 0:01:17\n",
            "     --                                      41.9/587.7 MB 7.0 MB/s eta 0:01:18\n",
            "     --                                      42.2/587.7 MB 7.0 MB/s eta 0:01:19\n",
            "     --                                      42.4/587.7 MB 6.8 MB/s eta 0:01:20\n",
            "     --                                      42.7/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     --                                      43.0/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     --                                      43.3/587.7 MB 6.8 MB/s eta 0:01:20\n",
            "     --                                      43.7/587.7 MB 6.9 MB/s eta 0:01:19\n",
            "     --                                      44.0/587.7 MB 6.8 MB/s eta 0:01:20\n",
            "     --                                      44.4/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     --                                      44.8/587.7 MB 6.8 MB/s eta 0:01:20\n",
            "     --                                      45.1/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     ---                                     45.4/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     ---                                     45.7/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     ---                                     45.9/587.7 MB 6.7 MB/s eta 0:01:22\n",
            "     ---                                     46.2/587.7 MB 6.7 MB/s eta 0:01:22\n",
            "     ---                                     46.6/587.7 MB 6.8 MB/s eta 0:01:21\n",
            "     ---                                     46.9/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     ---                                     47.3/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     ---                                     47.7/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     ---                                     48.1/587.7 MB 6.7 MB/s eta 0:01:20\n",
            "     ---                                     48.4/587.7 MB 6.7 MB/s eta 0:01:20\n",
            "     ---                                     48.7/587.7 MB 6.7 MB/s eta 0:01:21\n",
            "     ---                                     49.0/587.7 MB 6.8 MB/s eta 0:01:20\n",
            "     ---                                     49.3/587.7 MB 6.8 MB/s eta 0:01:19\n",
            "     ---                                     49.7/587.7 MB 6.8 MB/s eta 0:01:19\n",
            "     ---                                     50.1/587.7 MB 6.9 MB/s eta 0:01:18\n",
            "     ---                                     50.5/587.7 MB 6.9 MB/s eta 0:01:18\n",
            "     ---                                     50.8/587.7 MB 7.0 MB/s eta 0:01:17\n",
            "     ---                                     51.3/587.7 MB 7.1 MB/s eta 0:01:16\n",
            "     ---                                     51.6/587.7 MB 7.1 MB/s eta 0:01:16\n",
            "     ---                                     51.9/587.7 MB 7.2 MB/s eta 0:01:15\n",
            "     ---                                     52.1/587.7 MB 7.1 MB/s eta 0:01:16\n",
            "     ---                                     52.4/587.7 MB 7.1 MB/s eta 0:01:16\n",
            "     ---                                     52.7/587.7 MB 7.3 MB/s eta 0:01:14\n",
            "     ---                                     53.0/587.7 MB 7.2 MB/s eta 0:01:15\n",
            "     ---                                     53.4/587.7 MB 7.3 MB/s eta 0:01:14\n",
            "     ---                                     53.8/587.7 MB 7.2 MB/s eta 0:01:15\n",
            "     ---                                     54.1/587.7 MB 7.2 MB/s eta 0:01:15\n",
            "     ---                                     54.5/587.7 MB 7.3 MB/s eta 0:01:14\n",
            "     ---                                     54.9/587.7 MB 7.3 MB/s eta 0:01:14\n",
            "     ---                                     55.2/587.7 MB 7.3 MB/s eta 0:01:14\n",
            "     ---                                     55.7/587.7 MB 7.4 MB/s eta 0:01:13\n",
            "     ---                                     56.1/587.7 MB 7.5 MB/s eta 0:01:11\n",
            "     ---                                     56.5/587.7 MB 7.6 MB/s eta 0:01:10\n",
            "     ---                                     56.8/587.7 MB 7.6 MB/s eta 0:01:10\n",
            "     ---                                     57.2/587.7 MB 7.7 MB/s eta 0:01:09\n",
            "     ---                                     57.6/587.7 MB 7.7 MB/s eta 0:01:09\n",
            "     ---                                     58.1/587.7 MB 7.7 MB/s eta 0:01:09\n",
            "     ---                                     58.4/587.7 MB 7.7 MB/s eta 0:01:09\n",
            "     ---                                     58.8/587.7 MB 7.8 MB/s eta 0:01:08\n",
            "     ---                                     59.2/587.7 MB 7.9 MB/s eta 0:01:08\n",
            "     ---                                     59.6/587.7 MB 8.0 MB/s eta 0:01:07\n",
            "     ---                                     60.1/587.7 MB 8.0 MB/s eta 0:01:07\n",
            "     ----                                    60.5/587.7 MB 8.0 MB/s eta 0:01:07\n",
            "     ----                                    60.9/587.7 MB 8.1 MB/s eta 0:01:06\n",
            "     ----                                    61.2/587.7 MB 8.1 MB/s eta 0:01:06\n",
            "     ----                                    61.6/587.7 MB 8.0 MB/s eta 0:01:06\n",
            "     ----                                    61.9/587.7 MB 8.1 MB/s eta 0:01:06\n",
            "     ----                                    62.3/587.7 MB 8.3 MB/s eta 0:01:04\n",
            "     ----                                    62.8/587.7 MB 8.3 MB/s eta 0:01:04\n",
            "     ----                                    63.2/587.7 MB 8.4 MB/s eta 0:01:03\n",
            "     ----                                    63.6/587.7 MB 8.4 MB/s eta 0:01:03\n",
            "     ----                                    64.0/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    64.4/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    64.7/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    65.1/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    65.5/587.7 MB 8.6 MB/s eta 0:01:01\n",
            "     ----                                    65.9/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    66.3/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    66.7/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    67.1/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    67.4/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    67.8/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    68.1/587.7 MB 8.4 MB/s eta 0:01:02\n",
            "     ----                                    68.6/587.7 MB 8.5 MB/s eta 0:01:02\n",
            "     ----                                    68.9/587.7 MB 8.4 MB/s eta 0:01:02\n",
            "     ----                                    69.3/587.7 MB 8.4 MB/s eta 0:01:02\n",
            "     ----                                    69.6/587.7 MB 8.3 MB/s eta 0:01:03\n",
            "     ----                                    70.1/587.7 MB 8.3 MB/s eta 0:01:03\n",
            "     ----                                    70.3/587.7 MB 8.3 MB/s eta 0:01:03\n",
            "     ----                                    70.7/587.7 MB 8.2 MB/s eta 0:01:04\n",
            "     ----                                    71.2/587.7 MB 8.2 MB/s eta 0:01:04\n",
            "     ----                                    71.6/587.7 MB 8.3 MB/s eta 0:01:03\n",
            "     ----                                    72.0/587.7 MB 8.4 MB/s eta 0:01:02\n",
            "     ----                                    72.4/587.7 MB 8.4 MB/s eta 0:01:02\n",
            "     ----                                    72.8/587.7 MB 8.3 MB/s eta 0:01:03\n",
            "     ----                                    73.1/587.7 MB 8.3 MB/s eta 0:01:03\n",
            "     ----                                    73.4/587.7 MB 8.2 MB/s eta 0:01:03\n",
            "     ----                                    73.8/587.7 MB 8.2 MB/s eta 0:01:03\n",
            "     ----                                    74.2/587.7 MB 8.1 MB/s eta 0:01:04\n",
            "     ----                                    74.5/587.7 MB 8.2 MB/s eta 0:01:03\n",
            "     ----                                    74.8/587.7 MB 8.2 MB/s eta 0:01:03\n",
            "     ----                                    75.1/587.7 MB 8.0 MB/s eta 0:01:05\n",
            "     -----                                   75.4/587.7 MB 7.9 MB/s eta 0:01:05\n",
            "     -----                                   75.7/587.7 MB 7.9 MB/s eta 0:01:05\n",
            "     -----                                   76.1/587.7 MB 7.9 MB/s eta 0:01:05\n",
            "     -----                                   76.4/587.7 MB 7.8 MB/s eta 0:01:06\n",
            "     -----                                   76.9/587.7 MB 7.9 MB/s eta 0:01:05\n",
            "     -----                                   77.3/587.7 MB 7.9 MB/s eta 0:01:05\n",
            "     -----                                   77.5/587.7 MB 7.8 MB/s eta 0:01:06\n",
            "     -----                                   78.0/587.7 MB 7.9 MB/s eta 0:01:05\n",
            "     -----                                   78.3/587.7 MB 7.8 MB/s eta 0:01:06\n",
            "     -----                                   78.6/587.7 MB 7.8 MB/s eta 0:01:06\n",
            "     -----                                   79.1/587.7 MB 7.8 MB/s eta 0:01:06\n",
            "     -----                                   79.4/587.7 MB 7.8 MB/s eta 0:01:06\n",
            "     -----                                   79.7/587.7 MB 7.8 MB/s eta 0:01:06\n",
            "     -----                                   80.2/587.7 MB 7.9 MB/s eta 0:01:05\n",
            "     -----                                   80.7/587.7 MB 8.0 MB/s eta 0:01:04\n",
            "     -----                                   81.0/587.7 MB 7.9 MB/s eta 0:01:05\n",
            "     -----                                   81.3/587.7 MB 7.8 MB/s eta 0:01:05\n",
            "     -----                                   81.7/587.7 MB 7.8 MB/s eta 0:01:05\n",
            "     -----                                   82.0/587.7 MB 7.7 MB/s eta 0:01:06\n",
            "     -----                                   82.4/587.7 MB 7.7 MB/s eta 0:01:06\n",
            "     -----                                   82.6/587.7 MB 7.6 MB/s eta 0:01:07\n",
            "     -----                                   83.0/587.7 MB 7.6 MB/s eta 0:01:07\n",
            "     -----                                   83.5/587.7 MB 7.7 MB/s eta 0:01:06\n",
            "     -----                                   84.0/587.7 MB 7.9 MB/s eta 0:01:04\n",
            "     -----                                   84.4/587.7 MB 8.0 MB/s eta 0:01:04\n",
            "     -----                                   84.8/587.7 MB 8.0 MB/s eta 0:01:03\n",
            "     -----                                   85.3/587.7 MB 8.1 MB/s eta 0:01:03\n",
            "     -----                                   85.7/587.7 MB 8.2 MB/s eta 0:01:02\n",
            "     -----                                   86.1/587.7 MB 8.2 MB/s eta 0:01:02\n",
            "     -----                                   86.5/587.7 MB 8.2 MB/s eta 0:01:02\n",
            "     -----                                   86.7/587.7 MB 8.3 MB/s eta 0:01:01\n",
            "     -----                                   87.0/587.7 MB 8.2 MB/s eta 0:01:02\n",
            "     -----                                   87.3/587.7 MB 8.1 MB/s eta 0:01:02\n",
            "     -----                                   87.7/587.7 MB 8.1 MB/s eta 0:01:02\n",
            "     -----                                   88.1/587.7 MB 8.1 MB/s eta 0:01:02\n",
            "     -----                                   88.4/587.7 MB 8.0 MB/s eta 0:01:03\n",
            "     -----                                   88.6/587.7 MB 8.0 MB/s eta 0:01:03\n",
            "     -----                                   88.9/587.7 MB 8.0 MB/s eta 0:01:03\n",
            "     -----                                   89.1/587.7 MB 7.8 MB/s eta 0:01:04\n",
            "     -----                                   89.3/587.7 MB 7.7 MB/s eta 0:01:05\n",
            "     -----                                   89.6/587.7 MB 7.6 MB/s eta 0:01:06\n",
            "     -----                                   89.9/587.7 MB 7.5 MB/s eta 0:01:07\n",
            "     -----                                   90.1/587.7 MB 7.4 MB/s eta 0:01:07\n",
            "     -----                                   90.4/587.7 MB 7.3 MB/s eta 0:01:09\n",
            "     ------                                  90.6/587.7 MB 7.2 MB/s eta 0:01:10\n",
            "     ------                                  90.9/587.7 MB 7.0 MB/s eta 0:01:11\n",
            "     ------                                  91.2/587.7 MB 7.0 MB/s eta 0:01:11\n",
            "     ------                                  91.4/587.7 MB 7.0 MB/s eta 0:01:11\n",
            "     ------                                  91.6/587.7 MB 6.9 MB/s eta 0:01:13\n",
            "     ------                                  91.9/587.7 MB 6.9 MB/s eta 0:01:12\n",
            "     ------                                  92.1/587.7 MB 6.8 MB/s eta 0:01:13\n",
            "     ------                                  92.2/587.7 MB 6.7 MB/s eta 0:01:15\n",
            "     ------                                  92.4/587.7 MB 6.6 MB/s eta 0:01:15\n",
            "     ------                                  92.6/587.7 MB 6.5 MB/s eta 0:01:17\n",
            "     ------                                  92.9/587.7 MB 6.5 MB/s eta 0:01:17\n",
            "     ------                                  93.1/587.7 MB 6.4 MB/s eta 0:01:18\n",
            "     ------                                  93.4/587.7 MB 6.4 MB/s eta 0:01:18\n",
            "     ------                                  93.9/587.7 MB 6.4 MB/s eta 0:01:18\n",
            "     ------                                  94.2/587.7 MB 6.3 MB/s eta 0:01:19\n",
            "     ------                                  94.5/587.7 MB 6.2 MB/s eta 0:01:20\n",
            "     ------                                  94.9/587.7 MB 6.2 MB/s eta 0:01:20\n",
            "     ------                                  95.3/587.7 MB 6.2 MB/s eta 0:01:20\n",
            "     ------                                  95.5/587.7 MB 6.1 MB/s eta 0:01:21\n",
            "     ------                                  95.8/587.7 MB 6.1 MB/s eta 0:01:22\n",
            "     ------                                  96.2/587.7 MB 6.1 MB/s eta 0:01:22\n",
            "     ------                                  96.3/587.7 MB 6.0 MB/s eta 0:01:23\n",
            "     ------                                  96.6/587.7 MB 6.0 MB/s eta 0:01:23\n",
            "     ------                                  96.8/587.7 MB 5.9 MB/s eta 0:01:24\n",
            "     ------                                  97.0/587.7 MB 5.8 MB/s eta 0:01:24\n",
            "     ------                                  97.3/587.7 MB 5.8 MB/s eta 0:01:25\n",
            "     ------                                  97.5/587.7 MB 5.7 MB/s eta 0:01:26\n",
            "     ------                                  97.7/587.7 MB 5.7 MB/s eta 0:01:26\n",
            "     ------                                  98.0/587.7 MB 5.6 MB/s eta 0:01:27\n",
            "     ------                                  98.3/587.7 MB 5.6 MB/s eta 0:01:28\n",
            "     ------                                  98.5/587.7 MB 5.5 MB/s eta 0:01:29\n",
            "     ------                                  98.6/587.7 MB 5.5 MB/s eta 0:01:29\n",
            "     ------                                  98.9/587.7 MB 5.5 MB/s eta 0:01:29\n",
            "     ------                                  99.2/587.7 MB 5.6 MB/s eta 0:01:28\n",
            "     ------                                  99.6/587.7 MB 5.7 MB/s eta 0:01:26\n",
            "     ------                                  99.8/587.7 MB 5.6 MB/s eta 0:01:28\n",
            "     ------                                 100.0/587.7 MB 5.6 MB/s eta 0:01:27\n",
            "     ------                                 100.3/587.7 MB 5.6 MB/s eta 0:01:27\n",
            "     ------                                 100.6/587.7 MB 5.6 MB/s eta 0:01:27\n",
            "     ------                                 100.9/587.7 MB 5.7 MB/s eta 0:01:26\n",
            "     ------                                 101.2/587.7 MB 5.6 MB/s eta 0:01:27\n",
            "     ------                                 101.5/587.7 MB 5.7 MB/s eta 0:01:26\n",
            "     ------                                 101.7/587.7 MB 5.7 MB/s eta 0:01:25\n",
            "     ------                                 101.9/587.7 MB 5.7 MB/s eta 0:01:26\n",
            "     ------                                 102.2/587.7 MB 5.7 MB/s eta 0:01:26\n",
            "     ------                                 102.5/587.7 MB 5.8 MB/s eta 0:01:24\n",
            "     ------                                 102.8/587.7 MB 6.0 MB/s eta 0:01:21\n",
            "     ------                                 103.2/587.7 MB 6.1 MB/s eta 0:01:20\n",
            "     ------                                 103.5/587.7 MB 6.1 MB/s eta 0:01:20\n",
            "     ------                                 103.7/587.7 MB 6.0 MB/s eta 0:01:21\n",
            "     ------                                 104.0/587.7 MB 6.0 MB/s eta 0:01:22\n",
            "     ------                                 104.3/587.7 MB 5.9 MB/s eta 0:01:22\n",
            "     ------                                 104.5/587.7 MB 5.9 MB/s eta 0:01:22\n",
            "     ------                                 104.9/587.7 MB 5.8 MB/s eta 0:01:23\n",
            "     ------                                 105.2/587.7 MB 5.8 MB/s eta 0:01:23\n",
            "     ------                                 105.6/587.7 MB 5.8 MB/s eta 0:01:23\n",
            "     ------                                 106.0/587.7 MB 6.0 MB/s eta 0:01:21\n",
            "     ------                                 106.4/587.7 MB 6.0 MB/s eta 0:01:21\n",
            "     ------                                 106.8/587.7 MB 6.1 MB/s eta 0:01:20\n",
            "     ------                                 107.1/587.7 MB 6.2 MB/s eta 0:01:18\n",
            "     ------                                 107.5/587.7 MB 6.3 MB/s eta 0:01:17\n",
            "     ------                                 107.9/587.7 MB 6.4 MB/s eta 0:01:15\n",
            "     ------                                 108.3/587.7 MB 6.6 MB/s eta 0:01:13\n",
            "     -------                                108.6/587.7 MB 6.6 MB/s eta 0:01:13\n",
            "     -------                                109.0/587.7 MB 6.7 MB/s eta 0:01:11\n",
            "     -------                                109.3/587.7 MB 6.7 MB/s eta 0:01:11\n",
            "     -------                                109.7/587.7 MB 6.7 MB/s eta 0:01:11\n",
            "     -------                                110.0/587.7 MB 6.8 MB/s eta 0:01:11\n",
            "     -------                                110.2/587.7 MB 6.8 MB/s eta 0:01:11\n",
            "     -------                                110.6/587.7 MB 7.0 MB/s eta 0:01:08\n",
            "     -------                                111.0/587.7 MB 7.0 MB/s eta 0:01:09\n",
            "     -------                                111.4/587.7 MB 7.1 MB/s eta 0:01:07\n",
            "     -------                                111.6/587.7 MB 7.0 MB/s eta 0:01:08\n",
            "     -------                                112.2/587.7 MB 7.4 MB/s eta 0:01:05\n",
            "     -------                                112.5/587.7 MB 7.5 MB/s eta 0:01:04\n",
            "     -------                                112.7/587.7 MB 7.4 MB/s eta 0:01:05\n",
            "     -------                                113.1/587.7 MB 7.4 MB/s eta 0:01:04\n",
            "     -------                                113.4/587.7 MB 7.4 MB/s eta 0:01:05\n",
            "     -------                                113.8/587.7 MB 7.5 MB/s eta 0:01:03\n",
            "     -------                                114.3/587.7 MB 7.8 MB/s eta 0:01:01\n",
            "     -------                                114.7/587.7 MB 7.9 MB/s eta 0:01:00\n",
            "     -------                                115.0/587.7 MB 7.8 MB/s eta 0:01:01\n",
            "     -------                                115.3/587.7 MB 7.8 MB/s eta 0:01:01\n",
            "     -------                                115.7/587.7 MB 7.8 MB/s eta 0:01:01\n",
            "     -------                                116.2/587.7 MB 7.9 MB/s eta 0:01:00\n",
            "     -------                                116.6/587.7 MB 7.9 MB/s eta 0:01:00\n",
            "     -------                                117.0/587.7 MB 7.9 MB/s eta 0:01:00\n",
            "     -------                                117.4/587.7 MB 8.0 MB/s eta 0:00:59\n",
            "     -------                                117.6/587.7 MB 7.9 MB/s eta 0:01:00\n",
            "     -------                                117.9/587.7 MB 7.8 MB/s eta 0:01:01\n",
            "     -------                                118.4/587.7 MB 7.7 MB/s eta 0:01:01\n",
            "     -------                                118.8/587.7 MB 8.0 MB/s eta 0:00:59\n",
            "     -------                                119.2/587.7 MB 7.8 MB/s eta 0:01:01\n",
            "     -------                                119.5/587.7 MB 7.8 MB/s eta 0:01:01\n",
            "     -------                                119.8/587.7 MB 7.8 MB/s eta 0:01:01\n",
            "     -------                                120.0/587.7 MB 7.8 MB/s eta 0:01:01\n",
            "     -------                                120.4/587.7 MB 7.9 MB/s eta 0:01:00\n",
            "     -------                                120.6/587.7 MB 7.8 MB/s eta 0:01:00\n",
            "     -------                                120.9/587.7 MB 7.7 MB/s eta 0:01:01\n",
            "     -------                                121.3/587.7 MB 7.7 MB/s eta 0:01:01\n",
            "     -------                                121.7/587.7 MB 7.8 MB/s eta 0:01:00\n",
            "     -------                                122.2/587.7 MB 7.8 MB/s eta 0:01:00\n",
            "     -------                                122.7/587.7 MB 7.9 MB/s eta 0:00:59\n",
            "     -------                                123.1/587.7 MB 8.0 MB/s eta 0:00:59\n",
            "     -------                                123.4/587.7 MB 8.0 MB/s eta 0:00:59\n",
            "     --------                               123.8/587.7 MB 8.1 MB/s eta 0:00:58\n",
            "     --------                               124.4/587.7 MB 8.1 MB/s eta 0:00:58\n",
            "     --------                               124.9/587.7 MB 8.2 MB/s eta 0:00:57\n",
            "     --------                               125.3/587.7 MB 8.3 MB/s eta 0:00:56\n",
            "     --------                               125.7/587.7 MB 8.4 MB/s eta 0:00:56\n",
            "     --------                               126.1/587.7 MB 8.3 MB/s eta 0:00:56\n",
            "     --------                               126.5/587.7 MB 8.3 MB/s eta 0:00:56\n",
            "     --------                               127.0/587.7 MB 8.3 MB/s eta 0:00:56\n",
            "     --------                               127.4/587.7 MB 8.4 MB/s eta 0:00:55\n",
            "     --------                               128.0/587.7 MB 8.6 MB/s eta 0:00:54\n",
            "     --------                               128.5/587.7 MB 8.7 MB/s eta 0:00:53\n",
            "     --------                               128.8/587.7 MB 8.7 MB/s eta 0:00:53\n",
            "     --------                               129.2/587.7 MB 8.6 MB/s eta 0:00:54\n",
            "     --------                               129.6/587.7 MB 8.7 MB/s eta 0:00:53\n",
            "     --------                               129.8/587.7 MB 8.7 MB/s eta 0:00:53\n",
            "     --------                               130.1/587.7 MB 8.8 MB/s eta 0:00:52\n",
            "     --------                               130.4/587.7 MB 8.7 MB/s eta 0:00:53\n",
            "     --------                               130.7/587.7 MB 8.7 MB/s eta 0:00:53\n",
            "     --------                               131.1/587.7 MB 9.0 MB/s eta 0:00:51\n",
            "     --------                               131.6/587.7 MB 9.0 MB/s eta 0:00:51\n",
            "     --------                               131.9/587.7 MB 8.8 MB/s eta 0:00:52\n",
            "     --------                               132.4/587.7 MB 8.8 MB/s eta 0:00:52\n",
            "     --------                               132.8/587.7 MB 8.8 MB/s eta 0:00:52\n",
            "     --------                               133.3/587.7 MB 8.8 MB/s eta 0:00:52\n",
            "     --------                               133.7/587.7 MB 9.0 MB/s eta 0:00:51\n",
            "     --------                               134.1/587.7 MB 8.8 MB/s eta 0:00:52\n",
            "     --------                               134.5/587.7 MB 8.7 MB/s eta 0:00:52\n",
            "     --------                               135.0/587.7 MB 8.7 MB/s eta 0:00:52\n",
            "     --------                               135.2/587.7 MB 8.5 MB/s eta 0:00:54\n",
            "     --------                               135.6/587.7 MB 8.5 MB/s eta 0:00:54\n",
            "     --------                               135.9/587.7 MB 8.5 MB/s eta 0:00:54\n",
            "     --------                               136.4/587.7 MB 8.5 MB/s eta 0:00:54\n",
            "     --------                               137.0/587.7 MB 8.7 MB/s eta 0:00:52\n",
            "     --------                               137.5/587.7 MB 8.8 MB/s eta 0:00:51\n",
            "     --------                               137.8/587.7 MB 8.6 MB/s eta 0:00:53\n",
            "     --------                               138.2/587.7 MB 8.4 MB/s eta 0:00:54\n",
            "     --------                               138.5/587.7 MB 8.5 MB/s eta 0:00:53\n",
            "     --------                               138.9/587.7 MB 8.4 MB/s eta 0:00:54\n",
            "     ---------                              139.4/587.7 MB 8.5 MB/s eta 0:00:53\n",
            "     ---------                              139.7/587.7 MB 8.5 MB/s eta 0:00:53\n",
            "     ---------                              140.0/587.7 MB 8.5 MB/s eta 0:00:53\n",
            "     ---------                              140.4/587.7 MB 8.6 MB/s eta 0:00:52\n",
            "     ---------                              140.8/587.7 MB 8.7 MB/s eta 0:00:52\n",
            "     ---------                              141.2/587.7 MB 8.8 MB/s eta 0:00:51\n",
            "     ---------                              141.7/587.7 MB 8.7 MB/s eta 0:00:52\n",
            "     ---------                              142.0/587.7 MB 8.7 MB/s eta 0:00:52\n",
            "     ---------                              142.4/587.7 MB 8.7 MB/s eta 0:00:51\n",
            "     ---------                              142.8/587.7 MB 8.8 MB/s eta 0:00:51\n",
            "     ---------                              143.4/587.7 MB 8.7 MB/s eta 0:00:51\n",
            "     ---------                              143.9/587.7 MB 8.8 MB/s eta 0:00:51\n",
            "     ---------                              144.3/587.7 MB 8.8 MB/s eta 0:00:51\n",
            "     ---------                              144.6/587.7 MB 9.0 MB/s eta 0:00:50\n",
            "     ---------                              144.9/587.7 MB 8.6 MB/s eta 0:00:52\n",
            "     ---------                              145.4/587.7 MB 8.8 MB/s eta 0:00:51\n",
            "     ---------                              145.8/587.7 MB 8.8 MB/s eta 0:00:50\n",
            "     ---------                              146.3/587.7 MB 8.8 MB/s eta 0:00:50\n",
            "     ---------                              146.5/587.7 MB 8.6 MB/s eta 0:00:52\n",
            "     ---------                              146.7/587.7 MB 8.5 MB/s eta 0:00:52\n",
            "     ---------                              147.1/587.7 MB 8.5 MB/s eta 0:00:52\n",
            "     ---------                              147.5/587.7 MB 8.5 MB/s eta 0:00:52\n",
            "     ---------                              147.9/587.7 MB 8.5 MB/s eta 0:00:52\n",
            "     ---------                              148.4/587.7 MB 8.5 MB/s eta 0:00:52\n",
            "     ---------                              148.7/587.7 MB 8.5 MB/s eta 0:00:52\n",
            "     ---------                              149.0/587.7 MB 8.5 MB/s eta 0:00:52\n",
            "     ---------                              149.6/587.7 MB 8.5 MB/s eta 0:00:52\n",
            "     ---------                              150.1/587.7 MB 8.7 MB/s eta 0:00:51\n",
            "     ---------                              150.6/587.7 MB 8.8 MB/s eta 0:00:50\n",
            "     ---------                              151.1/587.7 MB 9.0 MB/s eta 0:00:49\n",
            "     ---------                              151.3/587.7 MB 8.8 MB/s eta 0:00:50\n",
            "     ---------                              151.8/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ---------                              152.1/587.7 MB 8.8 MB/s eta 0:00:50\n",
            "     ---------                              152.5/587.7 MB 8.8 MB/s eta 0:00:50\n",
            "     ---------                              152.9/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ---------                              153.5/587.7 MB 8.8 MB/s eta 0:00:50\n",
            "     ---------                              153.9/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ---------                              154.3/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ----------                             154.7/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ----------                             155.0/587.7 MB 8.6 MB/s eta 0:00:51\n",
            "     ----------                             155.5/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ----------                             156.0/587.7 MB 8.8 MB/s eta 0:00:49\n",
            "     ----------                             156.3/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ----------                             156.5/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ----------                             156.8/587.7 MB 8.8 MB/s eta 0:00:49\n",
            "     ----------                             157.2/587.7 MB 8.8 MB/s eta 0:00:49\n",
            "     ----------                             157.6/587.7 MB 8.8 MB/s eta 0:00:49\n",
            "     ----------                             157.9/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ----------                             158.3/587.7 MB 8.6 MB/s eta 0:00:50\n",
            "     ----------                             158.8/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ----------                             159.2/587.7 MB 8.8 MB/s eta 0:00:49\n",
            "     ----------                             159.5/587.7 MB 8.7 MB/s eta 0:00:50\n",
            "     ----------                             159.9/587.7 MB 8.6 MB/s eta 0:00:50\n",
            "     ----------                             160.2/587.7 MB 8.4 MB/s eta 0:00:51\n",
            "     ----------                             160.6/587.7 MB 8.4 MB/s eta 0:00:51\n",
            "     ----------                             161.0/587.7 MB 8.3 MB/s eta 0:00:52\n",
            "     ----------                             161.5/587.7 MB 8.5 MB/s eta 0:00:51\n",
            "     ----------                             161.9/587.7 MB 8.4 MB/s eta 0:00:51\n",
            "     ----------                             162.2/587.7 MB 8.4 MB/s eta 0:00:51\n",
            "     ----------                             162.6/587.7 MB 8.3 MB/s eta 0:00:52\n",
            "     ----------                             163.0/587.7 MB 8.4 MB/s eta 0:00:51\n",
            "     ----------                             163.5/587.7 MB 8.3 MB/s eta 0:00:52\n",
            "     ----------                             163.9/587.7 MB 8.3 MB/s eta 0:00:52\n",
            "     ----------                             164.3/587.7 MB 8.3 MB/s eta 0:00:52\n",
            "     ----------                             164.7/587.7 MB 8.3 MB/s eta 0:00:52\n",
            "     ----------                             165.0/587.7 MB 8.3 MB/s eta 0:00:51\n",
            "     ----------                             165.3/587.7 MB 8.3 MB/s eta 0:00:51\n",
            "     ----------                             165.7/587.7 MB 8.1 MB/s eta 0:00:53\n",
            "     ----------                             165.9/587.7 MB 8.0 MB/s eta 0:00:53\n",
            "     ----------                             166.3/587.7 MB 7.9 MB/s eta 0:00:54\n",
            "     ----------                             166.6/587.7 MB 8.0 MB/s eta 0:00:53\n",
            "     ----------                             166.9/587.7 MB 8.1 MB/s eta 0:00:53\n",
            "     ----------                             167.3/587.7 MB 8.1 MB/s eta 0:00:52\n",
            "     ----------                             167.7/587.7 MB 8.1 MB/s eta 0:00:52\n",
            "     ----------                             168.1/587.7 MB 8.2 MB/s eta 0:00:52\n",
            "     ----------                             168.3/587.7 MB 8.0 MB/s eta 0:00:53\n",
            "     ----------                             168.6/587.7 MB 8.0 MB/s eta 0:00:53\n",
            "     ----------                             169.0/587.7 MB 7.9 MB/s eta 0:00:54\n",
            "     ----------                             169.4/587.7 MB 8.0 MB/s eta 0:00:53\n",
            "     ----------                             169.9/587.7 MB 8.1 MB/s eta 0:00:52\n",
            "     -----------                            170.1/587.7 MB 8.0 MB/s eta 0:00:53\n",
            "     -----------                            170.6/587.7 MB 8.1 MB/s eta 0:00:52\n",
            "     -----------                            171.0/587.7 MB 8.1 MB/s eta 0:00:52\n",
            "     -----------                            171.4/587.7 MB 8.0 MB/s eta 0:00:53\n",
            "     -----------                            171.6/587.7 MB 7.9 MB/s eta 0:00:53\n",
            "     -----------                            172.0/587.7 MB 7.8 MB/s eta 0:00:54\n",
            "     -----------                            172.4/587.7 MB 7.8 MB/s eta 0:00:54\n",
            "     -----------                            172.9/587.7 MB 8.0 MB/s eta 0:00:52\n",
            "     -----------                            173.3/587.7 MB 8.0 MB/s eta 0:00:52\n",
            "     -----------                            173.6/587.7 MB 7.8 MB/s eta 0:00:54\n",
            "     -----------                            173.9/587.7 MB 7.9 MB/s eta 0:00:53\n",
            "     -----------                            174.2/587.7 MB 7.7 MB/s eta 0:00:54\n",
            "     -----------                            174.5/587.7 MB 7.6 MB/s eta 0:00:55\n",
            "     -----------                            174.8/587.7 MB 7.5 MB/s eta 0:00:55\n",
            "     -----------                            175.2/587.7 MB 7.6 MB/s eta 0:00:55\n",
            "     -----------                            175.6/587.7 MB 7.6 MB/s eta 0:00:55\n",
            "     -----------                            175.9/587.7 MB 7.6 MB/s eta 0:00:55\n",
            "     -----------                            176.3/587.7 MB 7.9 MB/s eta 0:00:53\n",
            "     -----------                            176.7/587.7 MB 7.9 MB/s eta 0:00:53\n",
            "     -----------                            177.2/587.7 MB 7.9 MB/s eta 0:00:53\n",
            "     -----------                            177.6/587.7 MB 7.9 MB/s eta 0:00:52\n",
            "     -----------                            178.0/587.7 MB 8.0 MB/s eta 0:00:52\n",
            "     -----------                            178.3/587.7 MB 8.0 MB/s eta 0:00:52\n",
            "     -----------                            178.7/587.7 MB 8.1 MB/s eta 0:00:51\n",
            "     -----------                            179.2/587.7 MB 8.2 MB/s eta 0:00:50\n",
            "     -----------                            179.6/587.7 MB 8.2 MB/s eta 0:00:50\n",
            "     -----------                            180.0/587.7 MB 8.2 MB/s eta 0:00:50\n",
            "     -----------                            180.4/587.7 MB 8.2 MB/s eta 0:00:50\n",
            "     -----------                            180.8/587.7 MB 8.2 MB/s eta 0:00:50\n",
            "     -----------                            181.2/587.7 MB 8.1 MB/s eta 0:00:51\n",
            "     -----------                            181.5/587.7 MB 8.1 MB/s eta 0:00:51\n",
            "     -----------                            181.7/587.7 MB 8.0 MB/s eta 0:00:51\n",
            "     -----------                            182.1/587.7 MB 8.2 MB/s eta 0:00:50\n",
            "     -----------                            182.5/587.7 MB 8.2 MB/s eta 0:00:50\n",
            "     -----------                            182.8/587.7 MB 8.0 MB/s eta 0:00:51\n",
            "     -----------                            183.2/587.7 MB 8.0 MB/s eta 0:00:51\n",
            "     -----------                            183.5/587.7 MB 7.9 MB/s eta 0:00:52\n",
            "     -----------                            184.0/587.7 MB 8.0 MB/s eta 0:00:51\n",
            "     -----------                            184.4/587.7 MB 8.2 MB/s eta 0:00:50\n",
            "     -----------                            184.8/587.7 MB 8.2 MB/s eta 0:00:50\n",
            "     -----------                            185.3/587.7 MB 8.5 MB/s eta 0:00:48\n",
            "     ------------                           185.7/587.7 MB 8.5 MB/s eta 0:00:48\n",
            "     ------------                           186.1/587.7 MB 8.6 MB/s eta 0:00:47\n",
            "     ------------                           186.4/587.7 MB 8.5 MB/s eta 0:00:48\n",
            "     ------------                           186.8/587.7 MB 8.4 MB/s eta 0:00:48\n",
            "     ------------                           187.0/587.7 MB 8.2 MB/s eta 0:00:49\n",
            "     ------------                           187.2/587.7 MB 8.2 MB/s eta 0:00:49\n",
            "     ------------                           187.7/587.7 MB 8.2 MB/s eta 0:00:49\n",
            "     ------------                           188.1/587.7 MB 8.1 MB/s eta 0:00:50\n",
            "     ------------                           188.6/587.7 MB 8.3 MB/s eta 0:00:49\n",
            "     ------------                           189.0/587.7 MB 8.3 MB/s eta 0:00:49\n",
            "     ------------                           189.5/587.7 MB 8.3 MB/s eta 0:00:49\n",
            "     ------------                           189.8/587.7 MB 8.2 MB/s eta 0:00:49\n",
            "     ------------                           190.1/587.7 MB 8.3 MB/s eta 0:00:48\n",
            "     ------------                           190.4/587.7 MB 8.0 MB/s eta 0:00:50\n",
            "     ------------                           190.8/587.7 MB 8.1 MB/s eta 0:00:50\n",
            "     ------------                           191.2/587.7 MB 8.1 MB/s eta 0:00:50\n",
            "     ------------                           191.6/587.7 MB 8.1 MB/s eta 0:00:49\n",
            "     ------------                           192.0/587.7 MB 8.2 MB/s eta 0:00:49\n",
            "     ------------                           192.3/587.7 MB 8.2 MB/s eta 0:00:49\n",
            "     ------------                           192.9/587.7 MB 8.3 MB/s eta 0:00:48\n",
            "     ------------                           193.4/587.7 MB 8.4 MB/s eta 0:00:47\n",
            "     ------------                           193.9/587.7 MB 8.6 MB/s eta 0:00:46\n",
            "     ------------                           194.3/587.7 MB 8.5 MB/s eta 0:00:47\n",
            "     ------------                           194.6/587.7 MB 8.6 MB/s eta 0:00:46\n",
            "     ------------                           194.9/587.7 MB 8.4 MB/s eta 0:00:47\n",
            "     ------------                           195.1/587.7 MB 8.2 MB/s eta 0:00:48\n",
            "     ------------                           195.5/587.7 MB 8.2 MB/s eta 0:00:48\n",
            "     ------------                           195.8/587.7 MB 8.1 MB/s eta 0:00:49\n",
            "     ------------                           196.1/587.7 MB 8.1 MB/s eta 0:00:49\n",
            "     ------------                           196.6/587.7 MB 8.0 MB/s eta 0:00:50\n",
            "     ------------                           196.9/587.7 MB 8.2 MB/s eta 0:00:48\n",
            "     ------------                           197.2/587.7 MB 8.3 MB/s eta 0:00:48\n",
            "     ------------                           197.5/587.7 MB 8.3 MB/s eta 0:00:48\n",
            "     ------------                           197.8/587.7 MB 8.2 MB/s eta 0:00:48\n",
            "     ------------                           198.2/587.7 MB 8.2 MB/s eta 0:00:48\n",
            "     ------------                           198.6/587.7 MB 8.1 MB/s eta 0:00:49\n",
            "     ------------                           198.9/587.7 MB 8.0 MB/s eta 0:00:49\n",
            "     ------------                           199.1/587.7 MB 7.8 MB/s eta 0:00:50\n",
            "     ------------                           199.4/587.7 MB 7.8 MB/s eta 0:00:50\n",
            "     ------------                           199.8/587.7 MB 7.7 MB/s eta 0:00:51\n",
            "     ------------                           200.3/587.7 MB 7.8 MB/s eta 0:00:50\n",
            "     ------------                           200.6/587.7 MB 7.9 MB/s eta 0:00:50\n",
            "     ------------                           201.0/587.7 MB 8.0 MB/s eta 0:00:49\n",
            "     -------------                          201.2/587.7 MB 7.8 MB/s eta 0:00:50\n",
            "     -------------                          201.5/587.7 MB 7.6 MB/s eta 0:00:51\n",
            "     -------------                          201.9/587.7 MB 7.6 MB/s eta 0:00:51\n",
            "     -------------                          202.3/587.7 MB 7.7 MB/s eta 0:00:51\n",
            "     -------------                          202.7/587.7 MB 7.6 MB/s eta 0:00:51\n",
            "     -------------                          203.0/587.7 MB 7.6 MB/s eta 0:00:51\n",
            "     -------------                          203.4/587.7 MB 7.6 MB/s eta 0:00:51\n",
            "     -------------                          203.7/587.7 MB 7.4 MB/s eta 0:00:52\n",
            "     -------------                          204.1/587.7 MB 7.4 MB/s eta 0:00:52\n",
            "     -------------                          204.5/587.7 MB 7.4 MB/s eta 0:00:52\n",
            "     -------------                          204.9/587.7 MB 7.4 MB/s eta 0:00:52\n",
            "     -------------                          205.3/587.7 MB 7.7 MB/s eta 0:00:50\n",
            "     -------------                          205.6/587.7 MB 7.5 MB/s eta 0:00:51\n",
            "     -------------                          205.9/587.7 MB 7.5 MB/s eta 0:00:51\n",
            "     -------------                          206.4/587.7 MB 7.8 MB/s eta 0:00:49\n",
            "     -------------                          206.9/587.7 MB 7.7 MB/s eta 0:00:50\n",
            "     -------------                          207.2/587.7 MB 7.7 MB/s eta 0:00:50\n",
            "     -------------                          207.5/587.7 MB 7.7 MB/s eta 0:00:50\n",
            "     -------------                          207.7/587.7 MB 7.7 MB/s eta 0:00:50\n",
            "     -------------                          208.0/587.7 MB 7.6 MB/s eta 0:00:50\n",
            "     -------------                          208.3/587.7 MB 7.5 MB/s eta 0:00:51\n",
            "     -------------                          208.5/587.7 MB 7.4 MB/s eta 0:00:51\n",
            "     -------------                          208.7/587.7 MB 7.3 MB/s eta 0:00:53\n",
            "     -------------                          209.1/587.7 MB 7.4 MB/s eta 0:00:52\n",
            "     -------------                          209.5/587.7 MB 7.5 MB/s eta 0:00:51\n",
            "     -------------                          209.8/587.7 MB 7.4 MB/s eta 0:00:51\n",
            "     -------------                          210.3/587.7 MB 7.5 MB/s eta 0:00:51\n",
            "     -------------                          210.8/587.7 MB 7.6 MB/s eta 0:00:50\n",
            "     -------------                          211.2/587.7 MB 7.5 MB/s eta 0:00:51\n",
            "     -------------                          211.6/587.7 MB 7.7 MB/s eta 0:00:49\n",
            "     -------------                          211.8/587.7 MB 7.7 MB/s eta 0:00:49\n",
            "     -------------                          212.1/587.7 MB 7.6 MB/s eta 0:00:50\n",
            "     -------------                          212.4/587.7 MB 7.7 MB/s eta 0:00:49\n",
            "     -------------                          212.9/587.7 MB 7.6 MB/s eta 0:00:50\n",
            "     -------------                          213.2/587.7 MB 7.6 MB/s eta 0:00:50\n",
            "     -------------                          213.6/587.7 MB 7.5 MB/s eta 0:00:50\n",
            "     -------------                          213.8/587.7 MB 7.6 MB/s eta 0:00:50\n",
            "     -------------                          214.1/587.7 MB 7.4 MB/s eta 0:00:51\n",
            "     -------------                          214.3/587.7 MB 7.4 MB/s eta 0:00:51\n",
            "     -------------                          214.6/587.7 MB 7.3 MB/s eta 0:00:52\n",
            "     -------------                          214.9/587.7 MB 7.3 MB/s eta 0:00:52\n",
            "     -------------                          215.3/587.7 MB 7.2 MB/s eta 0:00:52\n",
            "     -------------                          215.7/587.7 MB 7.3 MB/s eta 0:00:52\n",
            "     -------------                          216.0/587.7 MB 7.4 MB/s eta 0:00:51\n",
            "     -------------                          216.4/587.7 MB 7.3 MB/s eta 0:00:52\n",
            "     --------------                         216.7/587.7 MB 7.2 MB/s eta 0:00:52\n",
            "     --------------                         217.1/587.7 MB 7.1 MB/s eta 0:00:53\n",
            "     --------------                         217.5/587.7 MB 7.3 MB/s eta 0:00:51\n",
            "     --------------                         217.9/587.7 MB 7.3 MB/s eta 0:00:51\n",
            "     --------------                         218.2/587.7 MB 7.4 MB/s eta 0:00:51\n",
            "     --------------                         218.5/587.7 MB 7.4 MB/s eta 0:00:50\n",
            "     --------------                         218.8/587.7 MB 7.5 MB/s eta 0:00:50\n",
            "     --------------                         219.2/587.7 MB 7.5 MB/s eta 0:00:49\n",
            "     --------------                         219.7/587.7 MB 7.6 MB/s eta 0:00:49\n",
            "     --------------                         220.1/587.7 MB 7.6 MB/s eta 0:00:49\n",
            "     --------------                         220.4/587.7 MB 7.6 MB/s eta 0:00:49\n",
            "     --------------                         220.9/587.7 MB 7.5 MB/s eta 0:00:49\n",
            "     --------------                         221.3/587.7 MB 7.4 MB/s eta 0:00:50\n",
            "     --------------                         221.5/587.7 MB 7.4 MB/s eta 0:00:50\n",
            "     --------------                         221.9/587.7 MB 7.5 MB/s eta 0:00:49\n",
            "     --------------                         222.3/587.7 MB 7.7 MB/s eta 0:00:48\n",
            "     --------------                         222.7/587.7 MB 7.6 MB/s eta 0:00:48\n",
            "     --------------                         222.9/587.7 MB 7.6 MB/s eta 0:00:48\n",
            "     --------------                         223.4/587.7 MB 7.6 MB/s eta 0:00:48\n",
            "     --------------                         223.7/587.7 MB 7.6 MB/s eta 0:00:48\n",
            "     --------------                         224.0/587.7 MB 7.6 MB/s eta 0:00:48\n",
            "     --------------                         224.3/587.7 MB 7.6 MB/s eta 0:00:48\n",
            "     --------------                         224.5/587.7 MB 7.5 MB/s eta 0:00:49\n",
            "     --------------                         224.9/587.7 MB 7.8 MB/s eta 0:00:47\n",
            "     --------------                         225.4/587.7 MB 7.8 MB/s eta 0:00:47\n",
            "     --------------                         225.7/587.7 MB 7.7 MB/s eta 0:00:47\n",
            "     --------------                         226.1/587.7 MB 7.8 MB/s eta 0:00:47\n",
            "     --------------                         226.6/587.7 MB 7.9 MB/s eta 0:00:46\n",
            "     --------------                         226.9/587.7 MB 7.9 MB/s eta 0:00:46\n",
            "     --------------                         227.4/587.7 MB 8.0 MB/s eta 0:00:46\n",
            "     --------------                         227.9/587.7 MB 8.0 MB/s eta 0:00:46\n",
            "     --------------                         228.3/587.7 MB 8.0 MB/s eta 0:00:46\n",
            "     --------------                         228.7/587.7 MB 8.1 MB/s eta 0:00:45\n",
            "     --------------                         229.0/587.7 MB 8.2 MB/s eta 0:00:44\n",
            "     --------------                         229.5/587.7 MB 8.3 MB/s eta 0:00:44\n",
            "     --------------                         229.9/587.7 MB 8.2 MB/s eta 0:00:44\n",
            "     --------------                         230.3/587.7 MB 8.1 MB/s eta 0:00:45\n",
            "     --------------                         230.7/587.7 MB 8.3 MB/s eta 0:00:44\n",
            "     --------------                         231.1/587.7 MB 8.3 MB/s eta 0:00:44\n",
            "     --------------                         231.4/587.7 MB 8.2 MB/s eta 0:00:44\n",
            "     --------------                         231.8/587.7 MB 8.3 MB/s eta 0:00:43\n",
            "     ---------------                        232.1/587.7 MB 8.3 MB/s eta 0:00:43\n",
            "     ---------------                        232.5/587.7 MB 8.2 MB/s eta 0:00:44\n",
            "     ---------------                        232.9/587.7 MB 8.3 MB/s eta 0:00:43\n",
            "     ---------------                        233.2/587.7 MB 8.3 MB/s eta 0:00:43\n",
            "     ---------------                        233.6/587.7 MB 8.2 MB/s eta 0:00:44\n",
            "     ---------------                        233.9/587.7 MB 8.2 MB/s eta 0:00:44\n",
            "     ---------------                        234.2/587.7 MB 8.1 MB/s eta 0:00:44\n",
            "     ---------------                        234.5/587.7 MB 8.4 MB/s eta 0:00:43\n",
            "     ---------------                        234.7/587.7 MB 8.3 MB/s eta 0:00:43\n",
            "     ---------------                        235.0/587.7 MB 8.1 MB/s eta 0:00:44\n",
            "     ---------------                        235.3/587.7 MB 8.1 MB/s eta 0:00:44\n",
            "     ---------------                        235.7/587.7 MB 8.1 MB/s eta 0:00:44\n",
            "     ---------------                        235.9/587.7 MB 7.9 MB/s eta 0:00:45\n",
            "     ---------------                        236.3/587.7 MB 7.9 MB/s eta 0:00:45\n",
            "     ---------------                        236.7/587.7 MB 7.8 MB/s eta 0:00:46\n",
            "     ---------------                        237.1/587.7 MB 7.9 MB/s eta 0:00:45\n",
            "     ---------------                        237.5/587.7 MB 7.8 MB/s eta 0:00:45\n",
            "     ---------------                        237.7/587.7 MB 7.6 MB/s eta 0:00:46\n",
            "     ---------------                        238.0/587.7 MB 7.6 MB/s eta 0:00:46\n",
            "     ---------------                        238.3/587.7 MB 7.6 MB/s eta 0:00:46\n",
            "     ---------------                        238.7/587.7 MB 7.5 MB/s eta 0:00:47\n",
            "     ---------------                        239.1/587.7 MB 7.4 MB/s eta 0:00:47\n",
            "     ---------------                        239.4/587.7 MB 7.4 MB/s eta 0:00:47\n",
            "     ---------------                        239.8/587.7 MB 7.4 MB/s eta 0:00:47\n",
            "     ---------------                        240.1/587.7 MB 7.4 MB/s eta 0:00:47\n",
            "     ---------------                        240.4/587.7 MB 7.3 MB/s eta 0:00:48\n",
            "     ---------------                        240.6/587.7 MB 7.2 MB/s eta 0:00:49\n",
            "     ---------------                        240.9/587.7 MB 7.1 MB/s eta 0:00:49\n",
            "     ---------------                        241.3/587.7 MB 7.1 MB/s eta 0:00:49\n",
            "     ---------------                        241.6/587.7 MB 7.1 MB/s eta 0:00:49\n",
            "     ---------------                        242.0/587.7 MB 7.1 MB/s eta 0:00:49\n",
            "     ---------------                        242.3/587.7 MB 7.1 MB/s eta 0:00:49\n",
            "     ---------------                        242.7/587.7 MB 7.1 MB/s eta 0:00:49\n",
            "     ---------------                        243.1/587.7 MB 7.0 MB/s eta 0:00:49\n",
            "     ---------------                        243.3/587.7 MB 7.0 MB/s eta 0:00:49\n",
            "     ---------------                        243.8/587.7 MB 7.1 MB/s eta 0:00:49\n",
            "     ---------------                        244.1/587.7 MB 7.1 MB/s eta 0:00:49\n",
            "     ---------------                        244.6/587.7 MB 7.3 MB/s eta 0:00:48\n",
            "     ---------------                        245.0/587.7 MB 7.4 MB/s eta 0:00:47\n",
            "     ---------------                        245.3/587.7 MB 7.5 MB/s eta 0:00:46\n",
            "     ---------------                        245.6/587.7 MB 7.4 MB/s eta 0:00:46\n",
            "     ---------------                        245.9/587.7 MB 7.4 MB/s eta 0:00:46\n",
            "     ---------------                        246.2/587.7 MB 7.5 MB/s eta 0:00:46\n",
            "     ---------------                        246.5/587.7 MB 7.4 MB/s eta 0:00:46\n",
            "     ---------------                        246.9/587.7 MB 7.4 MB/s eta 0:00:46\n",
            "     ---------------                        247.2/587.7 MB 7.4 MB/s eta 0:00:47\n",
            "     ----------------                       247.6/587.7 MB 7.3 MB/s eta 0:00:47\n",
            "     ----------------                       247.9/587.7 MB 7.4 MB/s eta 0:00:46\n",
            "     ----------------                       248.2/587.7 MB 7.4 MB/s eta 0:00:46\n",
            "     ----------------                       248.5/587.7 MB 7.4 MB/s eta 0:00:47\n",
            "     ----------------                       248.8/587.7 MB 7.4 MB/s eta 0:00:47\n",
            "     ----------------                       249.1/587.7 MB 7.4 MB/s eta 0:00:47\n",
            "     ----------------                       249.5/587.7 MB 7.4 MB/s eta 0:00:46\n",
            "     ----------------                       249.7/587.7 MB 7.2 MB/s eta 0:00:47\n",
            "     ----------------                       250.0/587.7 MB 7.2 MB/s eta 0:00:47\n",
            "     ----------------                       250.3/587.7 MB 7.2 MB/s eta 0:00:47\n",
            "     ----------------                       250.7/587.7 MB 7.2 MB/s eta 0:00:47\n",
            "     ----------------                       250.9/587.7 MB 7.3 MB/s eta 0:00:47\n",
            "     ----------------                       251.3/587.7 MB 7.2 MB/s eta 0:00:47\n",
            "     ----------------                       251.6/587.7 MB 7.3 MB/s eta 0:00:47\n",
            "     ----------------                       252.0/587.7 MB 7.2 MB/s eta 0:00:47\n",
            "     ----------------                       252.4/587.7 MB 7.3 MB/s eta 0:00:47\n",
            "     ----------------                       252.7/587.7 MB 7.3 MB/s eta 0:00:47\n",
            "     ----------------                       253.0/587.7 MB 7.2 MB/s eta 0:00:47\n",
            "     ----------------                       253.4/587.7 MB 7.3 MB/s eta 0:00:46\n",
            "     ----------------                       253.6/587.7 MB 7.2 MB/s eta 0:00:47\n",
            "     ----------------                       253.9/587.7 MB 7.0 MB/s eta 0:00:48\n",
            "     ----------------                       254.2/587.7 MB 7.1 MB/s eta 0:00:47\n",
            "     ----------------                       254.4/587.7 MB 7.0 MB/s eta 0:00:48\n",
            "     ----------------                       254.8/587.7 MB 6.9 MB/s eta 0:00:49\n",
            "     ----------------                       255.0/587.7 MB 6.8 MB/s eta 0:00:50\n",
            "     ----------------                       255.3/587.7 MB 6.8 MB/s eta 0:00:49\n",
            "     ----------------                       255.6/587.7 MB 6.7 MB/s eta 0:00:50\n",
            "     ----------------                       256.0/587.7 MB 6.8 MB/s eta 0:00:49\n",
            "     ----------------                       256.3/587.7 MB 6.8 MB/s eta 0:00:49\n",
            "     ----------------                       256.7/587.7 MB 6.8 MB/s eta 0:00:49\n",
            "     ----------------                       257.0/587.7 MB 6.9 MB/s eta 0:00:49\n",
            "     ----------------                       257.3/587.7 MB 6.9 MB/s eta 0:00:48\n",
            "     ----------------                       257.8/587.7 MB 6.9 MB/s eta 0:00:48\n",
            "     ----------------                       258.0/587.7 MB 6.8 MB/s eta 0:00:49\n",
            "     ----------------                       258.4/587.7 MB 6.9 MB/s eta 0:00:48\n",
            "     ----------------                       258.7/587.7 MB 6.9 MB/s eta 0:00:48\n",
            "     ----------------                       259.1/587.7 MB 7.0 MB/s eta 0:00:48\n",
            "     ----------------                       259.5/587.7 MB 7.0 MB/s eta 0:00:48\n",
            "     ----------------                       259.8/587.7 MB 7.0 MB/s eta 0:00:47\n",
            "     ----------------                       260.1/587.7 MB 7.1 MB/s eta 0:00:47\n",
            "     ----------------                       260.3/587.7 MB 7.0 MB/s eta 0:00:47\n",
            "     ----------------                       260.7/587.7 MB 7.0 MB/s eta 0:00:47\n",
            "     ----------------                       261.0/587.7 MB 7.0 MB/s eta 0:00:47\n",
            "     ----------------                       261.3/587.7 MB 7.0 MB/s eta 0:00:47\n",
            "     ----------------                       261.6/587.7 MB 7.0 MB/s eta 0:00:47\n",
            "     ----------------                       262.0/587.7 MB 7.0 MB/s eta 0:00:47\n",
            "     ----------------                       262.3/587.7 MB 6.9 MB/s eta 0:00:48\n",
            "     ----------------                       262.6/587.7 MB 7.0 MB/s eta 0:00:47\n",
            "     ----------------                       262.9/587.7 MB 6.8 MB/s eta 0:00:48\n",
            "     -----------------                      263.2/587.7 MB 6.9 MB/s eta 0:00:48\n",
            "     -----------------                      263.4/587.7 MB 6.8 MB/s eta 0:00:48\n",
            "     -----------------                      263.8/587.7 MB 6.8 MB/s eta 0:00:48\n",
            "     -----------------                      264.2/587.7 MB 7.0 MB/s eta 0:00:47\n",
            "     -----------------                      264.6/587.7 MB 7.2 MB/s eta 0:00:45\n",
            "     -----------------                      265.0/587.7 MB 7.1 MB/s eta 0:00:46\n",
            "     -----------------                      265.3/587.7 MB 7.3 MB/s eta 0:00:45\n",
            "     -----------------                      265.6/587.7 MB 7.3 MB/s eta 0:00:45\n",
            "     -----------------                      266.0/587.7 MB 7.3 MB/s eta 0:00:45\n",
            "     -----------------                      266.4/587.7 MB 7.4 MB/s eta 0:00:44\n",
            "     -----------------                      266.8/587.7 MB 7.4 MB/s eta 0:00:44\n",
            "     -----------------                      267.2/587.7 MB 7.4 MB/s eta 0:00:44\n",
            "     -----------------                      267.6/587.7 MB 7.4 MB/s eta 0:00:44\n",
            "     -----------------                      267.9/587.7 MB 7.3 MB/s eta 0:00:44\n",
            "     -----------------                      268.2/587.7 MB 7.4 MB/s eta 0:00:44\n",
            "     -----------------                      268.3/587.7 MB 7.3 MB/s eta 0:00:44\n",
            "     -----------------                      268.7/587.7 MB 7.1 MB/s eta 0:00:45\n",
            "     -----------------                      269.2/587.7 MB 7.3 MB/s eta 0:00:44\n",
            "     -----------------                      269.5/587.7 MB 7.2 MB/s eta 0:00:45\n",
            "     -----------------                      269.8/587.7 MB 7.2 MB/s eta 0:00:45\n",
            "     -----------------                      270.1/587.7 MB 7.1 MB/s eta 0:00:45\n",
            "     -----------------                      270.4/587.7 MB 7.1 MB/s eta 0:00:45\n",
            "     -----------------                      270.8/587.7 MB 7.3 MB/s eta 0:00:44\n",
            "     -----------------                      271.0/587.7 MB 7.2 MB/s eta 0:00:45\n",
            "     -----------------                      271.4/587.7 MB 7.3 MB/s eta 0:00:44\n",
            "     -----------------                      271.8/587.7 MB 7.3 MB/s eta 0:00:44\n",
            "     -----------------                      272.3/587.7 MB 7.4 MB/s eta 0:00:43\n",
            "     -----------------                      272.8/587.7 MB 7.5 MB/s eta 0:00:42\n",
            "     -----------------                      273.2/587.7 MB 7.7 MB/s eta 0:00:41\n",
            "     -----------------                      273.6/587.7 MB 7.8 MB/s eta 0:00:41\n",
            "     -----------------                      273.9/587.7 MB 7.8 MB/s eta 0:00:41\n",
            "     -----------------                      274.3/587.7 MB 7.8 MB/s eta 0:00:41\n",
            "     -----------------                      274.7/587.7 MB 7.8 MB/s eta 0:00:41\n",
            "     -----------------                      275.1/587.7 MB 7.8 MB/s eta 0:00:41\n",
            "     -----------------                      275.4/587.7 MB 7.9 MB/s eta 0:00:40\n",
            "     -----------------                      275.8/587.7 MB 7.9 MB/s eta 0:00:40\n",
            "     -----------------                      276.0/587.7 MB 7.7 MB/s eta 0:00:41\n",
            "     -----------------                      276.4/587.7 MB 7.7 MB/s eta 0:00:41\n",
            "     -----------------                      276.8/587.7 MB 7.7 MB/s eta 0:00:41\n",
            "     -----------------                      277.2/587.7 MB 7.7 MB/s eta 0:00:41\n",
            "     -----------------                      277.6/587.7 MB 7.7 MB/s eta 0:00:41\n",
            "     -----------------                      277.7/587.7 MB 7.7 MB/s eta 0:00:41\n",
            "     -----------------                      278.0/587.7 MB 7.4 MB/s eta 0:00:42\n",
            "     -----------------                      278.3/587.7 MB 7.5 MB/s eta 0:00:42\n",
            "     ------------------                     278.6/587.7 MB 7.6 MB/s eta 0:00:41\n",
            "     ------------------                     279.0/587.7 MB 7.8 MB/s eta 0:00:40\n",
            "     ------------------                     279.4/587.7 MB 7.7 MB/s eta 0:00:41\n",
            "     ------------------                     279.7/587.7 MB 7.7 MB/s eta 0:00:40\n",
            "     ------------------                     280.0/587.7 MB 7.7 MB/s eta 0:00:40\n",
            "     ------------------                     280.6/587.7 MB 7.9 MB/s eta 0:00:39\n",
            "     ------------------                     281.0/587.7 MB 7.9 MB/s eta 0:00:39\n",
            "     ------------------                     281.3/587.7 MB 8.0 MB/s eta 0:00:39\n",
            "     ------------------                     281.8/587.7 MB 8.0 MB/s eta 0:00:39\n",
            "     ------------------                     282.1/587.7 MB 8.0 MB/s eta 0:00:39\n",
            "     ------------------                     282.3/587.7 MB 7.9 MB/s eta 0:00:39\n",
            "     ------------------                     282.6/587.7 MB 7.7 MB/s eta 0:00:40\n",
            "     ------------------                     283.0/587.7 MB 7.6 MB/s eta 0:00:41\n",
            "     ------------------                     283.4/587.7 MB 7.7 MB/s eta 0:00:40\n",
            "     ------------------                     283.8/587.7 MB 7.6 MB/s eta 0:00:40\n",
            "     ------------------                     284.2/587.7 MB 7.6 MB/s eta 0:00:40\n",
            "     ------------------                     284.5/587.7 MB 7.7 MB/s eta 0:00:40\n",
            "     ------------------                     284.7/587.7 MB 7.6 MB/s eta 0:00:40\n",
            "     ------------------                     285.1/587.7 MB 7.5 MB/s eta 0:00:41\n",
            "     ------------------                     285.6/587.7 MB 7.6 MB/s eta 0:00:40\n",
            "     ------------------                     286.0/587.7 MB 7.6 MB/s eta 0:00:40\n",
            "     ------------------                     286.4/587.7 MB 7.8 MB/s eta 0:00:39\n",
            "     ------------------                     286.8/587.7 MB 7.8 MB/s eta 0:00:39\n",
            "     ------------------                     287.1/587.7 MB 7.7 MB/s eta 0:00:40\n",
            "     ------------------                     287.5/587.7 MB 7.8 MB/s eta 0:00:39\n",
            "     ------------------                     287.8/587.7 MB 7.6 MB/s eta 0:00:40\n",
            "     ------------------                     288.0/587.7 MB 7.8 MB/s eta 0:00:39\n",
            "     ------------------                     288.4/587.7 MB 7.9 MB/s eta 0:00:38\n",
            "     ------------------                     288.8/587.7 MB 7.8 MB/s eta 0:00:39\n",
            "     ------------------                     289.2/587.7 MB 7.9 MB/s eta 0:00:38\n",
            "     ------------------                     289.6/587.7 MB 7.9 MB/s eta 0:00:38\n",
            "     ------------------                     290.0/587.7 MB 8.1 MB/s eta 0:00:37\n",
            "     ------------------                     290.3/587.7 MB 8.0 MB/s eta 0:00:38\n",
            "     ------------------                     290.7/587.7 MB 7.9 MB/s eta 0:00:38\n",
            "     ------------------                     291.2/587.7 MB 7.9 MB/s eta 0:00:38\n",
            "     ------------------                     291.7/587.7 MB 8.0 MB/s eta 0:00:38\n",
            "     ------------------                     292.1/587.7 MB 8.1 MB/s eta 0:00:37\n",
            "     ------------------                     292.4/587.7 MB 8.1 MB/s eta 0:00:37\n",
            "     ------------------                     292.8/587.7 MB 8.2 MB/s eta 0:00:37\n",
            "     ------------------                     293.2/587.7 MB 8.3 MB/s eta 0:00:36\n",
            "     ------------------                     293.6/587.7 MB 8.2 MB/s eta 0:00:36\n",
            "     -------------------                    293.8/587.7 MB 8.1 MB/s eta 0:00:37\n",
            "     -------------------                    294.1/587.7 MB 7.9 MB/s eta 0:00:38\n",
            "     -------------------                    294.4/587.7 MB 7.9 MB/s eta 0:00:38\n",
            "     -------------------                    294.6/587.7 MB 7.8 MB/s eta 0:00:38\n",
            "     -------------------                    294.9/587.7 MB 7.8 MB/s eta 0:00:38\n",
            "     -------------------                    295.3/587.7 MB 7.8 MB/s eta 0:00:38\n",
            "     -------------------                    295.7/587.7 MB 7.8 MB/s eta 0:00:38\n",
            "     -------------------                    296.1/587.7 MB 7.8 MB/s eta 0:00:38\n",
            "     -------------------                    296.4/587.7 MB 7.8 MB/s eta 0:00:38\n",
            "     -------------------                    296.9/587.7 MB 7.7 MB/s eta 0:00:38\n",
            "     -------------------                    297.3/587.7 MB 7.8 MB/s eta 0:00:38\n",
            "     -------------------                    297.6/587.7 MB 7.8 MB/s eta 0:00:38\n",
            "     -------------------                    298.0/587.7 MB 7.8 MB/s eta 0:00:38\n",
            "     -------------------                    298.4/587.7 MB 8.0 MB/s eta 0:00:37\n",
            "     -------------------                    298.7/587.7 MB 7.9 MB/s eta 0:00:37\n",
            "     -------------------                    299.1/587.7 MB 7.9 MB/s eta 0:00:37\n",
            "     -------------------                    299.6/587.7 MB 8.0 MB/s eta 0:00:37\n",
            "     -------------------                    300.0/587.7 MB 8.0 MB/s eta 0:00:37\n",
            "     -------------------                    300.4/587.7 MB 7.9 MB/s eta 0:00:37\n",
            "     -------------------                    300.8/587.7 MB 8.0 MB/s eta 0:00:36\n",
            "     -------------------                    301.1/587.7 MB 8.0 MB/s eta 0:00:36\n",
            "     -------------------                    301.4/587.7 MB 8.0 MB/s eta 0:00:36\n",
            "     -------------------                    301.7/587.7 MB 7.8 MB/s eta 0:00:37\n",
            "     -------------------                    302.2/587.7 MB 7.7 MB/s eta 0:00:38\n",
            "     -------------------                    302.6/587.7 MB 7.9 MB/s eta 0:00:37\n",
            "     -------------------                    302.8/587.7 MB 7.8 MB/s eta 0:00:37\n",
            "     -------------------                    303.2/587.7 MB 7.7 MB/s eta 0:00:37\n",
            "     -------------------                    303.4/587.7 MB 7.6 MB/s eta 0:00:38\n",
            "     -------------------                    303.8/587.7 MB 7.6 MB/s eta 0:00:38\n",
            "     -------------------                    304.0/587.7 MB 7.6 MB/s eta 0:00:38\n",
            "     -------------------                    304.4/587.7 MB 7.6 MB/s eta 0:00:38\n",
            "     -------------------                    304.7/587.7 MB 7.8 MB/s eta 0:00:37\n",
            "     -------------------                    305.2/587.7 MB 7.9 MB/s eta 0:00:36\n",
            "     -------------------                    305.5/587.7 MB 8.0 MB/s eta 0:00:36\n",
            "     -------------------                    305.8/587.7 MB 7.8 MB/s eta 0:00:37\n",
            "     -------------------                    306.2/587.7 MB 7.8 MB/s eta 0:00:37\n",
            "     -------------------                    306.5/587.7 MB 7.7 MB/s eta 0:00:37\n",
            "     -------------------                    306.9/587.7 MB 7.9 MB/s eta 0:00:36\n",
            "     -------------------                    307.2/587.7 MB 7.6 MB/s eta 0:00:37\n",
            "     -------------------                    307.5/587.7 MB 7.6 MB/s eta 0:00:37\n",
            "     -------------------                    307.9/587.7 MB 7.6 MB/s eta 0:00:37\n",
            "     -------------------                    308.1/587.7 MB 7.7 MB/s eta 0:00:37\n",
            "     -------------------                    308.6/587.7 MB 7.6 MB/s eta 0:00:37\n",
            "     -------------------                    309.0/587.7 MB 7.6 MB/s eta 0:00:37\n",
            "     -------------------                    309.3/587.7 MB 7.5 MB/s eta 0:00:37\n",
            "     --------------------                   309.7/587.7 MB 7.6 MB/s eta 0:00:37\n",
            "     --------------------                   310.0/587.7 MB 7.6 MB/s eta 0:00:37\n",
            "     --------------------                   310.2/587.7 MB 7.4 MB/s eta 0:00:38\n",
            "     --------------------                   310.5/587.7 MB 7.4 MB/s eta 0:00:38\n",
            "     --------------------                   310.8/587.7 MB 7.3 MB/s eta 0:00:39\n",
            "     --------------------                   311.1/587.7 MB 7.2 MB/s eta 0:00:39\n",
            "     --------------------                   311.5/587.7 MB 7.3 MB/s eta 0:00:38\n",
            "     --------------------                   311.8/587.7 MB 7.3 MB/s eta 0:00:38\n",
            "     --------------------                   312.0/587.7 MB 7.3 MB/s eta 0:00:38\n",
            "     --------------------                   312.4/587.7 MB 7.2 MB/s eta 0:00:39\n",
            "     --------------------                   312.8/587.7 MB 7.1 MB/s eta 0:00:39\n",
            "     --------------------                   313.3/587.7 MB 7.3 MB/s eta 0:00:38\n",
            "     --------------------                   313.6/587.7 MB 7.4 MB/s eta 0:00:38\n",
            "     --------------------                   314.0/587.7 MB 7.4 MB/s eta 0:00:38\n",
            "     --------------------                   314.4/587.7 MB 7.4 MB/s eta 0:00:37\n",
            "     --------------------                   314.7/587.7 MB 7.4 MB/s eta 0:00:37\n",
            "     --------------------                   315.0/587.7 MB 7.4 MB/s eta 0:00:37\n",
            "     --------------------                   315.4/587.7 MB 7.4 MB/s eta 0:00:38\n",
            "     --------------------                   315.9/587.7 MB 7.5 MB/s eta 0:00:37\n",
            "     --------------------                   316.3/587.7 MB 7.5 MB/s eta 0:00:37\n",
            "     --------------------                   316.8/587.7 MB 7.6 MB/s eta 0:00:36\n",
            "     --------------------                   317.2/587.7 MB 7.7 MB/s eta 0:00:36\n",
            "     --------------------                   317.5/587.7 MB 7.7 MB/s eta 0:00:36\n",
            "     --------------------                   317.8/587.7 MB 7.6 MB/s eta 0:00:36\n",
            "     --------------------                   318.3/587.7 MB 7.8 MB/s eta 0:00:35\n",
            "     --------------------                   318.7/587.7 MB 7.7 MB/s eta 0:00:35\n",
            "     --------------------                   319.1/587.7 MB 7.8 MB/s eta 0:00:35\n",
            "     --------------------                   319.3/587.7 MB 7.8 MB/s eta 0:00:35\n",
            "     --------------------                   319.7/587.7 MB 7.8 MB/s eta 0:00:35\n",
            "     --------------------                   320.0/587.7 MB 7.7 MB/s eta 0:00:35\n",
            "     --------------------                   320.3/587.7 MB 7.7 MB/s eta 0:00:35\n",
            "     --------------------                   320.7/587.7 MB 7.9 MB/s eta 0:00:34\n",
            "     --------------------                   321.1/587.7 MB 8.0 MB/s eta 0:00:34\n",
            "     --------------------                   321.4/587.7 MB 8.1 MB/s eta 0:00:33\n",
            "     --------------------                   321.9/587.7 MB 8.1 MB/s eta 0:00:33\n",
            "     --------------------                   322.2/587.7 MB 8.1 MB/s eta 0:00:33\n",
            "     --------------------                   322.6/587.7 MB 8.2 MB/s eta 0:00:33\n",
            "     --------------------                   322.9/587.7 MB 8.1 MB/s eta 0:00:33\n",
            "     --------------------                   323.4/587.7 MB 8.2 MB/s eta 0:00:33\n",
            "     --------------------                   323.7/587.7 MB 8.2 MB/s eta 0:00:33\n",
            "     --------------------                   324.1/587.7 MB 8.1 MB/s eta 0:00:33\n",
            "     --------------------                   324.4/587.7 MB 8.1 MB/s eta 0:00:33\n",
            "     ---------------------                  324.8/587.7 MB 8.0 MB/s eta 0:00:33\n",
            "     ---------------------                  325.0/587.7 MB 8.0 MB/s eta 0:00:33\n",
            "     ---------------------                  325.4/587.7 MB 7.9 MB/s eta 0:00:34\n",
            "     ---------------------                  325.7/587.7 MB 7.9 MB/s eta 0:00:34\n",
            "     ---------------------                  326.0/587.7 MB 7.7 MB/s eta 0:00:34\n",
            "     ---------------------                  326.4/587.7 MB 7.7 MB/s eta 0:00:34\n",
            "     ---------------------                  326.7/587.7 MB 7.7 MB/s eta 0:00:34\n",
            "     ---------------------                  327.0/587.7 MB 7.6 MB/s eta 0:00:35\n",
            "     ---------------------                  327.4/587.7 MB 7.4 MB/s eta 0:00:35\n",
            "     ---------------------                  327.7/587.7 MB 7.4 MB/s eta 0:00:35\n",
            "     ---------------------                  328.0/587.7 MB 7.6 MB/s eta 0:00:35\n",
            "     ---------------------                  328.3/587.7 MB 7.4 MB/s eta 0:00:35\n",
            "     ---------------------                  328.5/587.7 MB 7.3 MB/s eta 0:00:36\n",
            "     ---------------------                  328.7/587.7 MB 7.2 MB/s eta 0:00:37\n",
            "     ---------------------                  329.0/587.7 MB 7.2 MB/s eta 0:00:36\n",
            "     ---------------------                  329.4/587.7 MB 7.2 MB/s eta 0:00:36\n",
            "     ---------------------                  329.8/587.7 MB 7.2 MB/s eta 0:00:36\n",
            "     ---------------------                  330.2/587.7 MB 7.3 MB/s eta 0:00:36\n",
            "     ---------------------                  330.6/587.7 MB 7.4 MB/s eta 0:00:35\n",
            "     ---------------------                  330.9/587.7 MB 7.3 MB/s eta 0:00:36\n",
            "     ---------------------                  331.2/587.7 MB 7.3 MB/s eta 0:00:36\n",
            "     ---------------------                  331.4/587.7 MB 7.2 MB/s eta 0:00:36\n",
            "     ---------------------                  331.7/587.7 MB 7.3 MB/s eta 0:00:36\n",
            "     ---------------------                  332.0/587.7 MB 7.0 MB/s eta 0:00:37\n",
            "     ---------------------                  332.4/587.7 MB 7.0 MB/s eta 0:00:37\n",
            "     ---------------------                  332.7/587.7 MB 7.0 MB/s eta 0:00:37\n",
            "     ---------------------                  333.0/587.7 MB 7.0 MB/s eta 0:00:37\n",
            "     ---------------------                  333.3/587.7 MB 7.0 MB/s eta 0:00:37\n",
            "     ---------------------                  333.7/587.7 MB 6.8 MB/s eta 0:00:38\n",
            "     ---------------------                  334.0/587.7 MB 6.9 MB/s eta 0:00:37\n",
            "     ---------------------                  334.2/587.7 MB 6.8 MB/s eta 0:00:38\n",
            "     ---------------------                  334.5/587.7 MB 6.8 MB/s eta 0:00:38\n",
            "     ---------------------                  334.7/587.7 MB 6.7 MB/s eta 0:00:38\n",
            "     ---------------------                  335.1/587.7 MB 6.7 MB/s eta 0:00:38\n",
            "     ---------------------                  335.4/587.7 MB 6.8 MB/s eta 0:00:37\n",
            "     ---------------------                  335.7/587.7 MB 6.8 MB/s eta 0:00:38\n",
            "     ---------------------                  336.0/587.7 MB 6.8 MB/s eta 0:00:37\n",
            "     ---------------------                  336.4/587.7 MB 6.8 MB/s eta 0:00:37\n",
            "     ---------------------                  336.7/587.7 MB 6.7 MB/s eta 0:00:38\n",
            "     ---------------------                  336.9/587.7 MB 6.7 MB/s eta 0:00:38\n",
            "     ---------------------                  337.3/587.7 MB 6.7 MB/s eta 0:00:38\n",
            "     ---------------------                  337.7/587.7 MB 6.7 MB/s eta 0:00:38\n",
            "     ---------------------                  338.1/587.7 MB 6.8 MB/s eta 0:00:37\n",
            "     ---------------------                  338.5/587.7 MB 6.9 MB/s eta 0:00:37\n",
            "     ---------------------                  338.8/587.7 MB 7.0 MB/s eta 0:00:36\n",
            "     ---------------------                  339.2/587.7 MB 7.1 MB/s eta 0:00:35\n",
            "     ---------------------                  339.5/587.7 MB 7.0 MB/s eta 0:00:36\n",
            "     ---------------------                  339.9/587.7 MB 7.0 MB/s eta 0:00:36\n",
            "     ----------------------                 340.3/587.7 MB 7.0 MB/s eta 0:00:36\n",
            "     ----------------------                 340.6/587.7 MB 7.0 MB/s eta 0:00:36\n",
            "     ----------------------                 340.9/587.7 MB 7.0 MB/s eta 0:00:36\n",
            "     ----------------------                 341.2/587.7 MB 7.0 MB/s eta 0:00:36\n",
            "     ----------------------                 341.5/587.7 MB 6.9 MB/s eta 0:00:36\n",
            "     ----------------------                 341.8/587.7 MB 7.0 MB/s eta 0:00:36\n",
            "     ----------------------                 342.2/587.7 MB 7.1 MB/s eta 0:00:35\n",
            "     ----------------------                 342.6/587.7 MB 7.0 MB/s eta 0:00:35\n",
            "     ----------------------                 343.0/587.7 MB 7.0 MB/s eta 0:00:35\n",
            "     ----------------------                 343.4/587.7 MB 7.4 MB/s eta 0:00:34\n",
            "     ----------------------                 343.7/587.7 MB 7.4 MB/s eta 0:00:34\n",
            "     ----------------------                 344.0/587.7 MB 7.3 MB/s eta 0:00:34\n",
            "     ----------------------                 344.3/587.7 MB 7.2 MB/s eta 0:00:34\n",
            "     ----------------------                 344.6/587.7 MB 7.3 MB/s eta 0:00:34\n",
            "     ----------------------                 345.0/587.7 MB 7.4 MB/s eta 0:00:33\n",
            "     ----------------------                 345.4/587.7 MB 7.4 MB/s eta 0:00:33\n",
            "     ----------------------                 345.7/587.7 MB 7.5 MB/s eta 0:00:33\n",
            "     ----------------------                 346.1/587.7 MB 7.5 MB/s eta 0:00:33\n",
            "     ----------------------                 346.5/587.7 MB 7.6 MB/s eta 0:00:32\n",
            "     ----------------------                 346.9/587.7 MB 7.6 MB/s eta 0:00:32\n",
            "     ----------------------                 347.1/587.7 MB 7.6 MB/s eta 0:00:32\n",
            "     ----------------------                 347.5/587.7 MB 7.6 MB/s eta 0:00:32\n",
            "     ----------------------                 347.9/587.7 MB 7.5 MB/s eta 0:00:32\n",
            "     ----------------------                 348.2/587.7 MB 7.5 MB/s eta 0:00:32\n",
            "     ----------------------                 348.5/587.7 MB 7.4 MB/s eta 0:00:33\n",
            "     ----------------------                 348.8/587.7 MB 7.4 MB/s eta 0:00:33\n",
            "     ----------------------                 349.2/587.7 MB 7.4 MB/s eta 0:00:33\n",
            "     ----------------------                 349.6/587.7 MB 7.4 MB/s eta 0:00:33\n",
            "     ----------------------                 349.9/587.7 MB 7.4 MB/s eta 0:00:32\n",
            "     ----------------------                 350.2/587.7 MB 7.4 MB/s eta 0:00:32\n",
            "     ----------------------                 350.5/587.7 MB 7.4 MB/s eta 0:00:32\n",
            "     ----------------------                 350.9/587.7 MB 7.4 MB/s eta 0:00:32\n",
            "     ----------------------                 351.2/587.7 MB 7.4 MB/s eta 0:00:32\n",
            "     ----------------------                 351.6/587.7 MB 7.5 MB/s eta 0:00:32\n",
            "     ----------------------                 351.9/587.7 MB 7.4 MB/s eta 0:00:32\n",
            "     ----------------------                 352.2/587.7 MB 7.4 MB/s eta 0:00:32\n",
            "     ----------------------                 352.6/587.7 MB 7.4 MB/s eta 0:00:32\n",
            "     ----------------------                 353.1/587.7 MB 7.5 MB/s eta 0:00:32\n",
            "     ----------------------                 353.5/587.7 MB 7.5 MB/s eta 0:00:32\n",
            "     ----------------------                 354.0/587.7 MB 7.5 MB/s eta 0:00:32\n",
            "     ----------------------                 354.4/587.7 MB 7.6 MB/s eta 0:00:31\n",
            "     ----------------------                 354.7/587.7 MB 7.7 MB/s eta 0:00:31\n",
            "     ----------------------                 355.2/587.7 MB 7.9 MB/s eta 0:00:30\n",
            "     ----------------------                 355.6/587.7 MB 7.8 MB/s eta 0:00:30\n",
            "     -----------------------                355.9/587.7 MB 7.7 MB/s eta 0:00:31\n",
            "     -----------------------                356.2/587.7 MB 7.8 MB/s eta 0:00:30\n",
            "     -----------------------                356.5/587.7 MB 7.8 MB/s eta 0:00:30\n",
            "     -----------------------                356.9/587.7 MB 7.8 MB/s eta 0:00:30\n",
            "     -----------------------                357.3/587.7 MB 7.9 MB/s eta 0:00:30\n",
            "     -----------------------                357.6/587.7 MB 7.8 MB/s eta 0:00:30\n",
            "     -----------------------                358.0/587.7 MB 7.8 MB/s eta 0:00:30\n",
            "     -----------------------                358.3/587.7 MB 7.8 MB/s eta 0:00:30\n",
            "     -----------------------                358.7/587.7 MB 7.9 MB/s eta 0:00:30\n",
            "     -----------------------                359.0/587.7 MB 7.8 MB/s eta 0:00:30\n",
            "     -----------------------                359.4/587.7 MB 7.9 MB/s eta 0:00:29\n",
            "     -----------------------                359.8/587.7 MB 7.9 MB/s eta 0:00:29\n",
            "     -----------------------                360.1/587.7 MB 7.9 MB/s eta 0:00:29\n",
            "     -----------------------                360.5/587.7 MB 7.8 MB/s eta 0:00:30\n",
            "     -----------------------                360.8/587.7 MB 7.9 MB/s eta 0:00:29\n",
            "     -----------------------                361.2/587.7 MB 7.9 MB/s eta 0:00:29\n",
            "     -----------------------                361.5/587.7 MB 7.9 MB/s eta 0:00:29\n",
            "     -----------------------                362.0/587.7 MB 8.0 MB/s eta 0:00:29\n",
            "     -----------------------                362.4/587.7 MB 8.1 MB/s eta 0:00:28\n",
            "     -----------------------                362.7/587.7 MB 8.0 MB/s eta 0:00:29\n",
            "     -----------------------                363.0/587.7 MB 8.1 MB/s eta 0:00:28\n",
            "     -----------------------                363.3/587.7 MB 7.9 MB/s eta 0:00:29\n",
            "     -----------------------                363.7/587.7 MB 7.8 MB/s eta 0:00:29\n",
            "     -----------------------                364.1/587.7 MB 7.8 MB/s eta 0:00:29\n",
            "     -----------------------                364.4/587.7 MB 7.8 MB/s eta 0:00:29\n",
            "     -----------------------                364.8/587.7 MB 7.9 MB/s eta 0:00:29\n",
            "     -----------------------                365.2/587.7 MB 7.7 MB/s eta 0:00:29\n",
            "     -----------------------                365.4/587.7 MB 7.6 MB/s eta 0:00:30\n",
            "     -----------------------                365.7/587.7 MB 7.6 MB/s eta 0:00:30\n",
            "     -----------------------                365.9/587.7 MB 7.5 MB/s eta 0:00:30\n",
            "     -----------------------                366.2/587.7 MB 7.4 MB/s eta 0:00:30\n",
            "     -----------------------                366.6/587.7 MB 7.5 MB/s eta 0:00:30\n",
            "     -----------------------                366.9/587.7 MB 7.5 MB/s eta 0:00:30\n",
            "     -----------------------                367.2/587.7 MB 7.4 MB/s eta 0:00:30\n",
            "     -----------------------                367.5/587.7 MB 7.4 MB/s eta 0:00:30\n",
            "     -----------------------                367.8/587.7 MB 7.4 MB/s eta 0:00:30\n",
            "     -----------------------                368.2/587.7 MB 7.4 MB/s eta 0:00:30\n",
            "     -----------------------                368.5/587.7 MB 7.4 MB/s eta 0:00:30\n",
            "     -----------------------                368.9/587.7 MB 7.4 MB/s eta 0:00:30\n",
            "     -----------------------                369.1/587.7 MB 7.4 MB/s eta 0:00:30\n",
            "     -----------------------                369.3/587.7 MB 7.4 MB/s eta 0:00:30\n",
            "     -----------------------                369.7/587.7 MB 7.2 MB/s eta 0:00:31\n",
            "     -----------------------                370.0/587.7 MB 7.2 MB/s eta 0:00:31\n",
            "     -----------------------                370.4/587.7 MB 7.2 MB/s eta 0:00:31\n",
            "     -----------------------                370.7/587.7 MB 7.2 MB/s eta 0:00:31\n",
            "     -----------------------                371.0/587.7 MB 7.1 MB/s eta 0:00:31\n",
            "     ------------------------               371.3/587.7 MB 7.1 MB/s eta 0:00:31\n",
            "     ------------------------               371.6/587.7 MB 7.1 MB/s eta 0:00:31\n",
            "     ------------------------               371.9/587.7 MB 7.1 MB/s eta 0:00:31\n",
            "     ------------------------               372.2/587.7 MB 7.0 MB/s eta 0:00:31\n",
            "     ------------------------               372.4/587.7 MB 6.9 MB/s eta 0:00:32\n",
            "     ------------------------               372.7/587.7 MB 6.8 MB/s eta 0:00:32\n",
            "     ------------------------               373.0/587.7 MB 6.8 MB/s eta 0:00:32\n",
            "     ------------------------               373.2/587.7 MB 6.7 MB/s eta 0:00:33\n",
            "     ------------------------               373.5/587.7 MB 6.7 MB/s eta 0:00:32\n",
            "     ------------------------               373.8/587.7 MB 6.7 MB/s eta 0:00:33\n",
            "     ------------------------               374.2/587.7 MB 6.7 MB/s eta 0:00:32\n",
            "     ------------------------               374.6/587.7 MB 6.7 MB/s eta 0:00:32\n",
            "     ------------------------               374.9/587.7 MB 6.6 MB/s eta 0:00:33\n",
            "     ------------------------               375.2/587.7 MB 6.5 MB/s eta 0:00:33\n",
            "     ------------------------               375.5/587.7 MB 6.5 MB/s eta 0:00:33\n",
            "     ------------------------               375.9/587.7 MB 6.7 MB/s eta 0:00:32\n",
            "     ------------------------               376.2/587.7 MB 6.7 MB/s eta 0:00:32\n",
            "     ------------------------               376.5/587.7 MB 6.7 MB/s eta 0:00:32\n",
            "     ------------------------               377.0/587.7 MB 6.8 MB/s eta 0:00:31\n",
            "     ------------------------               377.3/587.7 MB 6.8 MB/s eta 0:00:31\n",
            "     ------------------------               377.6/587.7 MB 6.9 MB/s eta 0:00:31\n",
            "     ------------------------               378.0/587.7 MB 6.9 MB/s eta 0:00:31\n",
            "     ------------------------               378.3/587.7 MB 6.9 MB/s eta 0:00:31\n",
            "     ------------------------               378.6/587.7 MB 6.9 MB/s eta 0:00:31\n",
            "     ------------------------               379.0/587.7 MB 6.9 MB/s eta 0:00:31\n",
            "     ------------------------               379.4/587.7 MB 6.9 MB/s eta 0:00:31\n",
            "     ------------------------               379.7/587.7 MB 7.1 MB/s eta 0:00:30\n",
            "     ------------------------               380.0/587.7 MB 7.0 MB/s eta 0:00:30\n",
            "     ------------------------               380.3/587.7 MB 7.0 MB/s eta 0:00:30\n",
            "     ------------------------               380.5/587.7 MB 6.9 MB/s eta 0:00:31\n",
            "     ------------------------               380.8/587.7 MB 6.8 MB/s eta 0:00:31\n",
            "     ------------------------               381.2/587.7 MB 7.0 MB/s eta 0:00:30\n",
            "     ------------------------               381.5/587.7 MB 6.9 MB/s eta 0:00:30\n",
            "     ------------------------               381.8/587.7 MB 6.9 MB/s eta 0:00:30\n",
            "     ------------------------               382.2/587.7 MB 7.0 MB/s eta 0:00:30\n",
            "     ------------------------               382.6/587.7 MB 7.1 MB/s eta 0:00:29\n",
            "     ------------------------               383.0/587.7 MB 7.3 MB/s eta 0:00:29\n",
            "     ------------------------               383.4/587.7 MB 7.4 MB/s eta 0:00:28\n",
            "     ------------------------               383.8/587.7 MB 7.4 MB/s eta 0:00:28\n",
            "     ------------------------               384.2/587.7 MB 7.4 MB/s eta 0:00:28\n",
            "     ------------------------               384.5/587.7 MB 7.4 MB/s eta 0:00:28\n",
            "     ------------------------               385.0/587.7 MB 7.5 MB/s eta 0:00:27\n",
            "     ------------------------               385.5/587.7 MB 7.8 MB/s eta 0:00:26\n",
            "     ------------------------               385.9/587.7 MB 7.8 MB/s eta 0:00:26\n",
            "     ------------------------               386.3/587.7 MB 7.8 MB/s eta 0:00:26\n",
            "     -------------------------              386.7/587.7 MB 7.8 MB/s eta 0:00:26\n",
            "     -------------------------              387.2/587.7 MB 7.9 MB/s eta 0:00:26\n",
            "     -------------------------              387.6/587.7 MB 7.9 MB/s eta 0:00:26\n",
            "     -------------------------              387.9/587.7 MB 7.9 MB/s eta 0:00:26\n",
            "     -------------------------              388.3/587.7 MB 7.9 MB/s eta 0:00:26\n",
            "     -------------------------              388.6/587.7 MB 7.9 MB/s eta 0:00:26\n",
            "     -------------------------              388.9/587.7 MB 7.9 MB/s eta 0:00:26\n",
            "     -------------------------              389.3/587.7 MB 7.9 MB/s eta 0:00:26\n",
            "     -------------------------              389.5/587.7 MB 7.8 MB/s eta 0:00:26\n",
            "     -------------------------              390.0/587.7 MB 8.0 MB/s eta 0:00:25\n",
            "     -------------------------              390.2/587.7 MB 7.8 MB/s eta 0:00:26\n",
            "     -------------------------              390.5/587.7 MB 7.9 MB/s eta 0:00:25\n",
            "     -------------------------              391.0/587.7 MB 8.1 MB/s eta 0:00:25\n",
            "     -------------------------              391.3/587.7 MB 8.2 MB/s eta 0:00:24\n",
            "     -------------------------              391.5/587.7 MB 8.1 MB/s eta 0:00:25\n",
            "     -------------------------              392.0/587.7 MB 8.1 MB/s eta 0:00:25\n",
            "     -------------------------              392.4/587.7 MB 8.2 MB/s eta 0:00:24\n",
            "     -------------------------              392.7/587.7 MB 8.1 MB/s eta 0:00:25\n",
            "     -------------------------              393.1/587.7 MB 8.1 MB/s eta 0:00:25\n",
            "     -------------------------              393.6/587.7 MB 8.2 MB/s eta 0:00:24\n",
            "     -------------------------              393.9/587.7 MB 8.1 MB/s eta 0:00:24\n",
            "     -------------------------              394.2/587.7 MB 8.1 MB/s eta 0:00:24\n",
            "     -------------------------              394.6/587.7 MB 8.1 MB/s eta 0:00:24\n",
            "     -------------------------              395.0/587.7 MB 8.0 MB/s eta 0:00:25\n",
            "     -------------------------              395.4/587.7 MB 8.1 MB/s eta 0:00:24\n",
            "     -------------------------              395.7/587.7 MB 8.0 MB/s eta 0:00:25\n",
            "     -------------------------              395.9/587.7 MB 7.8 MB/s eta 0:00:25\n",
            "     -------------------------              396.2/587.7 MB 7.7 MB/s eta 0:00:25\n",
            "     -------------------------              396.6/587.7 MB 7.6 MB/s eta 0:00:26\n",
            "     -------------------------              397.0/587.7 MB 7.7 MB/s eta 0:00:25\n",
            "     -------------------------              397.3/587.7 MB 7.6 MB/s eta 0:00:26\n",
            "     -------------------------              397.6/587.7 MB 7.5 MB/s eta 0:00:26\n",
            "     -------------------------              397.9/587.7 MB 7.4 MB/s eta 0:00:26\n",
            "     -------------------------              398.1/587.7 MB 7.4 MB/s eta 0:00:26\n",
            "     -------------------------              398.4/587.7 MB 7.4 MB/s eta 0:00:26\n",
            "     -------------------------              398.7/587.7 MB 7.3 MB/s eta 0:00:26\n",
            "     -------------------------              399.0/587.7 MB 7.2 MB/s eta 0:00:27\n",
            "     -------------------------              399.4/587.7 MB 7.4 MB/s eta 0:00:26\n",
            "     -------------------------              399.9/587.7 MB 7.4 MB/s eta 0:00:26\n",
            "     -------------------------              400.3/587.7 MB 7.4 MB/s eta 0:00:26\n",
            "     -------------------------              400.6/587.7 MB 7.6 MB/s eta 0:00:25\n",
            "     -------------------------              401.1/587.7 MB 7.6 MB/s eta 0:00:25\n",
            "     -------------------------              401.6/587.7 MB 7.7 MB/s eta 0:00:25\n",
            "     -------------------------              402.0/587.7 MB 7.8 MB/s eta 0:00:24\n",
            "     --------------------------             402.4/587.7 MB 7.8 MB/s eta 0:00:24\n",
            "     --------------------------             402.9/587.7 MB 7.9 MB/s eta 0:00:24\n",
            "     --------------------------             403.2/587.7 MB 7.8 MB/s eta 0:00:24\n",
            "     --------------------------             403.5/587.7 MB 7.7 MB/s eta 0:00:24\n",
            "     --------------------------             403.8/587.7 MB 7.6 MB/s eta 0:00:25\n",
            "     --------------------------             404.0/587.7 MB 7.6 MB/s eta 0:00:25\n",
            "     --------------------------             404.4/587.7 MB 7.5 MB/s eta 0:00:25\n",
            "     --------------------------             404.8/587.7 MB 7.7 MB/s eta 0:00:24\n",
            "     --------------------------             405.2/587.7 MB 7.6 MB/s eta 0:00:24\n",
            "     --------------------------             405.5/587.7 MB 7.6 MB/s eta 0:00:24\n",
            "     --------------------------             405.8/587.7 MB 7.5 MB/s eta 0:00:25\n",
            "     --------------------------             406.1/587.7 MB 7.7 MB/s eta 0:00:24\n",
            "     --------------------------             406.4/587.7 MB 7.7 MB/s eta 0:00:24\n",
            "     --------------------------             406.7/587.7 MB 7.6 MB/s eta 0:00:24\n",
            "     --------------------------             407.0/587.7 MB 7.5 MB/s eta 0:00:25\n",
            "     --------------------------             407.3/587.7 MB 7.4 MB/s eta 0:00:25\n",
            "     --------------------------             407.6/587.7 MB 7.4 MB/s eta 0:00:25\n",
            "     --------------------------             407.8/587.7 MB 7.4 MB/s eta 0:00:25\n",
            "     --------------------------             408.1/587.7 MB 7.4 MB/s eta 0:00:25\n",
            "     --------------------------             408.5/587.7 MB 7.5 MB/s eta 0:00:24\n",
            "     --------------------------             409.1/587.7 MB 7.9 MB/s eta 0:00:23\n",
            "     --------------------------             409.5/587.7 MB 7.9 MB/s eta 0:00:23\n",
            "     --------------------------             409.9/587.7 MB 7.8 MB/s eta 0:00:23\n",
            "     --------------------------             410.1/587.7 MB 7.6 MB/s eta 0:00:24\n",
            "     --------------------------             410.3/587.7 MB 7.5 MB/s eta 0:00:24\n",
            "     --------------------------             410.8/587.7 MB 7.6 MB/s eta 0:00:24\n",
            "     --------------------------             411.2/587.7 MB 7.5 MB/s eta 0:00:24\n",
            "     --------------------------             411.5/587.7 MB 7.5 MB/s eta 0:00:24\n",
            "     --------------------------             411.6/587.7 MB 7.4 MB/s eta 0:00:24\n",
            "     --------------------------             412.0/587.7 MB 7.4 MB/s eta 0:00:24\n",
            "     --------------------------             412.3/587.7 MB 7.2 MB/s eta 0:00:25\n",
            "     --------------------------             412.6/587.7 MB 7.2 MB/s eta 0:00:25\n",
            "     --------------------------             413.0/587.7 MB 7.2 MB/s eta 0:00:25\n",
            "     --------------------------             413.3/587.7 MB 7.0 MB/s eta 0:00:25\n",
            "     --------------------------             413.5/587.7 MB 7.0 MB/s eta 0:00:25\n",
            "     --------------------------             413.8/587.7 MB 7.0 MB/s eta 0:00:25\n",
            "     --------------------------             414.1/587.7 MB 7.0 MB/s eta 0:00:25\n",
            "     --------------------------             414.5/587.7 MB 7.1 MB/s eta 0:00:25\n",
            "     --------------------------             414.9/587.7 MB 7.0 MB/s eta 0:00:25\n",
            "     --------------------------             415.4/587.7 MB 7.2 MB/s eta 0:00:24\n",
            "     --------------------------             415.6/587.7 MB 7.0 MB/s eta 0:00:25\n",
            "     --------------------------             416.2/587.7 MB 7.3 MB/s eta 0:00:24\n",
            "     --------------------------             416.7/587.7 MB 7.4 MB/s eta 0:00:23\n",
            "     --------------------------             417.1/587.7 MB 7.5 MB/s eta 0:00:23\n",
            "     --------------------------             417.4/587.7 MB 7.6 MB/s eta 0:00:23\n",
            "     ---------------------------            417.8/587.7 MB 7.7 MB/s eta 0:00:23\n",
            "     ---------------------------            418.2/587.7 MB 7.8 MB/s eta 0:00:22\n",
            "     ---------------------------            418.5/587.7 MB 7.8 MB/s eta 0:00:22\n",
            "     ---------------------------            418.8/587.7 MB 7.7 MB/s eta 0:00:22\n",
            "     ---------------------------            419.2/587.7 MB 7.6 MB/s eta 0:00:23\n",
            "     ---------------------------            419.6/587.7 MB 7.5 MB/s eta 0:00:23\n",
            "     ---------------------------            419.9/587.7 MB 7.5 MB/s eta 0:00:23\n",
            "     ---------------------------            420.3/587.7 MB 7.6 MB/s eta 0:00:22\n",
            "     ---------------------------            420.5/587.7 MB 7.6 MB/s eta 0:00:22\n",
            "     ---------------------------            420.7/587.7 MB 7.4 MB/s eta 0:00:23\n",
            "     ---------------------------            421.0/587.7 MB 7.4 MB/s eta 0:00:23\n",
            "     ---------------------------            421.4/587.7 MB 7.4 MB/s eta 0:00:23\n",
            "     ---------------------------            421.7/587.7 MB 7.4 MB/s eta 0:00:23\n",
            "     ---------------------------            422.1/587.7 MB 7.6 MB/s eta 0:00:22\n",
            "     ---------------------------            422.5/587.7 MB 7.6 MB/s eta 0:00:22\n",
            "     ---------------------------            422.8/587.7 MB 7.6 MB/s eta 0:00:22\n",
            "     ---------------------------            423.3/587.7 MB 7.7 MB/s eta 0:00:22\n",
            "     ---------------------------            423.5/587.7 MB 7.8 MB/s eta 0:00:22\n",
            "     ---------------------------            423.9/587.7 MB 7.8 MB/s eta 0:00:22\n",
            "     ---------------------------            424.2/587.7 MB 7.8 MB/s eta 0:00:21\n",
            "     ---------------------------            424.6/587.7 MB 7.8 MB/s eta 0:00:21\n",
            "     ---------------------------            424.9/587.7 MB 7.7 MB/s eta 0:00:22\n",
            "     ---------------------------            425.2/587.7 MB 7.7 MB/s eta 0:00:22\n",
            "     ---------------------------            425.5/587.7 MB 7.5 MB/s eta 0:00:22\n",
            "     ---------------------------            425.7/587.7 MB 7.5 MB/s eta 0:00:22\n",
            "     ---------------------------            426.0/587.7 MB 7.4 MB/s eta 0:00:22\n",
            "     ---------------------------            426.4/587.7 MB 7.4 MB/s eta 0:00:22\n",
            "     ---------------------------            426.7/587.7 MB 7.3 MB/s eta 0:00:23\n",
            "     ---------------------------            427.1/587.7 MB 7.3 MB/s eta 0:00:23\n",
            "     ---------------------------            427.4/587.7 MB 7.3 MB/s eta 0:00:23\n",
            "     ---------------------------            427.8/587.7 MB 7.2 MB/s eta 0:00:23\n",
            "     ---------------------------            428.2/587.7 MB 7.3 MB/s eta 0:00:22\n",
            "     ---------------------------            428.7/587.7 MB 7.4 MB/s eta 0:00:22\n",
            "     ---------------------------            429.1/587.7 MB 7.4 MB/s eta 0:00:22\n",
            "     ---------------------------            429.5/587.7 MB 7.4 MB/s eta 0:00:22\n",
            "     ---------------------------            429.8/587.7 MB 7.4 MB/s eta 0:00:22\n",
            "     ---------------------------            430.1/587.7 MB 7.4 MB/s eta 0:00:22\n",
            "     ---------------------------            430.3/587.7 MB 7.3 MB/s eta 0:00:22\n",
            "     ---------------------------            430.6/587.7 MB 7.3 MB/s eta 0:00:22\n",
            "     ---------------------------            430.9/587.7 MB 7.4 MB/s eta 0:00:22\n",
            "     ---------------------------            431.3/587.7 MB 7.4 MB/s eta 0:00:22\n",
            "     ---------------------------            431.7/587.7 MB 7.4 MB/s eta 0:00:21\n",
            "     ---------------------------            432.1/587.7 MB 7.5 MB/s eta 0:00:21\n",
            "     ---------------------------            432.4/587.7 MB 7.4 MB/s eta 0:00:21\n",
            "     ---------------------------            432.8/587.7 MB 7.4 MB/s eta 0:00:21\n",
            "     ----------------------------           433.3/587.7 MB 7.5 MB/s eta 0:00:21\n",
            "     ----------------------------           433.8/587.7 MB 7.7 MB/s eta 0:00:20\n",
            "     ----------------------------           434.3/587.7 MB 7.8 MB/s eta 0:00:20\n",
            "     ----------------------------           434.7/587.7 MB 7.8 MB/s eta 0:00:20\n",
            "     ----------------------------           435.1/587.7 MB 8.0 MB/s eta 0:00:20\n",
            "     ----------------------------           435.5/587.7 MB 8.0 MB/s eta 0:00:20\n",
            "     ----------------------------           435.9/587.7 MB 8.1 MB/s eta 0:00:19\n",
            "     ----------------------------           436.2/587.7 MB 8.2 MB/s eta 0:00:19\n",
            "     ----------------------------           436.4/587.7 MB 8.1 MB/s eta 0:00:19\n",
            "     ----------------------------           436.7/587.7 MB 8.1 MB/s eta 0:00:19\n",
            "     ----------------------------           437.0/587.7 MB 8.1 MB/s eta 0:00:19\n",
            "     ----------------------------           437.4/587.7 MB 8.0 MB/s eta 0:00:19\n",
            "     ----------------------------           437.7/587.7 MB 8.0 MB/s eta 0:00:19\n",
            "     ----------------------------           438.0/587.7 MB 7.9 MB/s eta 0:00:19\n",
            "     ----------------------------           438.3/587.7 MB 7.9 MB/s eta 0:00:19\n",
            "     ----------------------------           438.7/587.7 MB 7.9 MB/s eta 0:00:19\n",
            "     ----------------------------           439.2/587.7 MB 7.8 MB/s eta 0:00:20\n",
            "     ----------------------------           439.5/587.7 MB 7.7 MB/s eta 0:00:20\n",
            "     ----------------------------           439.7/587.7 MB 7.7 MB/s eta 0:00:20\n",
            "     ----------------------------           440.1/587.7 MB 7.7 MB/s eta 0:00:20\n",
            "     ----------------------------           440.5/587.7 MB 7.9 MB/s eta 0:00:19\n",
            "     ----------------------------           441.1/587.7 MB 8.2 MB/s eta 0:00:18\n",
            "     ----------------------------           441.3/587.7 MB 8.1 MB/s eta 0:00:19\n",
            "     ----------------------------           441.8/587.7 MB 8.1 MB/s eta 0:00:19\n",
            "     ----------------------------           442.3/587.7 MB 8.1 MB/s eta 0:00:18\n",
            "     ----------------------------           442.9/587.7 MB 8.3 MB/s eta 0:00:18\n",
            "     ----------------------------           443.5/587.7 MB 8.5 MB/s eta 0:00:17\n",
            "     ----------------------------           443.9/587.7 MB 8.3 MB/s eta 0:00:18\n",
            "     ----------------------------           444.2/587.7 MB 8.2 MB/s eta 0:00:18\n",
            "     ----------------------------           444.6/587.7 MB 8.1 MB/s eta 0:00:18\n",
            "     ----------------------------           444.8/587.7 MB 8.0 MB/s eta 0:00:18\n",
            "     ----------------------------           445.2/587.7 MB 8.0 MB/s eta 0:00:18\n",
            "     ----------------------------           445.6/587.7 MB 8.0 MB/s eta 0:00:18\n",
            "     ----------------------------           446.0/587.7 MB 8.0 MB/s eta 0:00:18\n",
            "     ----------------------------           446.6/587.7 MB 8.3 MB/s eta 0:00:18\n",
            "     ----------------------------           447.0/587.7 MB 8.3 MB/s eta 0:00:17\n",
            "     ----------------------------           447.1/587.7 MB 8.2 MB/s eta 0:00:18\n",
            "     ----------------------------           447.4/587.7 MB 8.2 MB/s eta 0:00:18\n",
            "     ----------------------------           447.7/587.7 MB 8.1 MB/s eta 0:00:18\n",
            "     ----------------------------           447.9/587.7 MB 8.0 MB/s eta 0:00:18\n",
            "     ----------------------------           448.3/587.7 MB 8.1 MB/s eta 0:00:18\n",
            "     -----------------------------          448.6/587.7 MB 8.1 MB/s eta 0:00:18\n",
            "     -----------------------------          449.0/587.7 MB 8.0 MB/s eta 0:00:18\n",
            "     -----------------------------          449.4/587.7 MB 8.0 MB/s eta 0:00:18\n",
            "     -----------------------------          449.8/587.7 MB 8.1 MB/s eta 0:00:18\n",
            "     -----------------------------          450.3/587.7 MB 8.3 MB/s eta 0:00:17\n",
            "     -----------------------------          450.7/587.7 MB 8.3 MB/s eta 0:00:17\n",
            "     -----------------------------          451.1/587.7 MB 8.3 MB/s eta 0:00:17\n",
            "     -----------------------------          451.4/587.7 MB 8.2 MB/s eta 0:00:17\n",
            "     -----------------------------          451.9/587.7 MB 8.2 MB/s eta 0:00:17\n",
            "     -----------------------------          452.2/587.7 MB 8.3 MB/s eta 0:00:17\n",
            "     -----------------------------          452.5/587.7 MB 8.2 MB/s eta 0:00:17\n",
            "     -----------------------------          452.9/587.7 MB 8.0 MB/s eta 0:00:17\n",
            "     -----------------------------          453.3/587.7 MB 8.0 MB/s eta 0:00:17\n",
            "     -----------------------------          453.6/587.7 MB 7.8 MB/s eta 0:00:18\n",
            "     -----------------------------          453.8/587.7 MB 7.7 MB/s eta 0:00:18\n",
            "     -----------------------------          454.1/587.7 MB 7.6 MB/s eta 0:00:18\n",
            "     -----------------------------          454.5/587.7 MB 7.6 MB/s eta 0:00:18\n",
            "     -----------------------------          454.8/587.7 MB 7.7 MB/s eta 0:00:18\n",
            "     -----------------------------          455.1/587.7 MB 7.6 MB/s eta 0:00:18\n",
            "     -----------------------------          455.6/587.7 MB 7.7 MB/s eta 0:00:18\n",
            "     -----------------------------          456.0/587.7 MB 7.7 MB/s eta 0:00:18\n",
            "     -----------------------------          456.4/587.7 MB 7.8 MB/s eta 0:00:17\n",
            "     -----------------------------          456.8/587.7 MB 7.6 MB/s eta 0:00:18\n",
            "     -----------------------------          457.1/587.7 MB 7.7 MB/s eta 0:00:17\n",
            "     -----------------------------          457.5/587.7 MB 7.9 MB/s eta 0:00:17\n",
            "     -----------------------------          457.9/587.7 MB 8.0 MB/s eta 0:00:17\n",
            "     -----------------------------          458.2/587.7 MB 8.0 MB/s eta 0:00:17\n",
            "     -----------------------------          458.6/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     -----------------------------          459.2/587.7 MB 8.2 MB/s eta 0:00:16\n",
            "     -----------------------------          459.6/587.7 MB 8.3 MB/s eta 0:00:16\n",
            "     -----------------------------          460.0/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     -----------------------------          460.2/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     -----------------------------          460.5/587.7 MB 8.0 MB/s eta 0:00:16\n",
            "     -----------------------------          461.0/587.7 MB 8.0 MB/s eta 0:00:16\n",
            "     -----------------------------          461.5/587.7 MB 8.2 MB/s eta 0:00:16\n",
            "     -----------------------------          461.8/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     -----------------------------          462.2/587.7 MB 8.0 MB/s eta 0:00:16\n",
            "     -----------------------------          462.6/587.7 MB 8.0 MB/s eta 0:00:16\n",
            "     -----------------------------          462.9/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     -----------------------------          463.3/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     -----------------------------          463.7/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     -----------------------------          463.9/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     ------------------------------         464.2/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     ------------------------------         464.4/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     ------------------------------         464.7/587.7 MB 8.0 MB/s eta 0:00:16\n",
            "     ------------------------------         465.2/587.7 MB 8.0 MB/s eta 0:00:16\n",
            "     ------------------------------         465.6/587.7 MB 8.1 MB/s eta 0:00:16\n",
            "     ------------------------------         466.1/587.7 MB 8.2 MB/s eta 0:00:15\n",
            "     ------------------------------         466.6/587.7 MB 8.2 MB/s eta 0:00:15\n",
            "     ------------------------------         467.0/587.7 MB 8.3 MB/s eta 0:00:15\n",
            "     ------------------------------         467.4/587.7 MB 8.3 MB/s eta 0:00:15\n",
            "     ------------------------------         467.8/587.7 MB 8.3 MB/s eta 0:00:15\n",
            "     ------------------------------         468.2/587.7 MB 8.3 MB/s eta 0:00:15\n",
            "     ------------------------------         468.6/587.7 MB 8.3 MB/s eta 0:00:15\n",
            "     ------------------------------         468.8/587.7 MB 8.2 MB/s eta 0:00:15\n",
            "     ------------------------------         469.2/587.7 MB 8.2 MB/s eta 0:00:15\n",
            "     ------------------------------         469.6/587.7 MB 8.1 MB/s eta 0:00:15\n",
            "     ------------------------------         470.0/587.7 MB 8.1 MB/s eta 0:00:15\n",
            "     ------------------------------         470.4/587.7 MB 8.2 MB/s eta 0:00:15\n",
            "     ------------------------------         470.7/587.7 MB 8.2 MB/s eta 0:00:15\n",
            "     ------------------------------         471.0/587.7 MB 8.1 MB/s eta 0:00:15\n",
            "     ------------------------------         471.3/587.7 MB 8.0 MB/s eta 0:00:15\n",
            "     ------------------------------         471.5/587.7 MB 7.9 MB/s eta 0:00:15\n",
            "     ------------------------------         471.9/587.7 MB 7.8 MB/s eta 0:00:15\n",
            "     ------------------------------         472.2/587.7 MB 7.8 MB/s eta 0:00:15\n",
            "     ------------------------------         472.5/587.7 MB 7.8 MB/s eta 0:00:15\n",
            "     ------------------------------         473.0/587.7 MB 7.8 MB/s eta 0:00:15\n",
            "     ------------------------------         473.5/587.7 MB 7.9 MB/s eta 0:00:15\n",
            "     ------------------------------         473.9/587.7 MB 8.0 MB/s eta 0:00:15\n",
            "     ------------------------------         474.2/587.7 MB 8.1 MB/s eta 0:00:15\n",
            "     ------------------------------         474.6/587.7 MB 8.3 MB/s eta 0:00:14\n",
            "     ------------------------------         475.1/587.7 MB 8.4 MB/s eta 0:00:14\n",
            "     ------------------------------         475.4/587.7 MB 8.3 MB/s eta 0:00:14\n",
            "     ------------------------------         475.6/587.7 MB 8.1 MB/s eta 0:00:14\n",
            "     ------------------------------         476.0/587.7 MB 8.0 MB/s eta 0:00:14\n",
            "     ------------------------------         476.3/587.7 MB 7.9 MB/s eta 0:00:15\n",
            "     ------------------------------         476.5/587.7 MB 7.8 MB/s eta 0:00:15\n",
            "     ------------------------------         476.9/587.7 MB 7.7 MB/s eta 0:00:15\n",
            "     ------------------------------         477.3/587.7 MB 7.7 MB/s eta 0:00:15\n",
            "     ------------------------------         477.5/587.7 MB 7.6 MB/s eta 0:00:15\n",
            "     ------------------------------         477.7/587.7 MB 7.5 MB/s eta 0:00:15\n",
            "     ------------------------------         478.0/587.7 MB 7.4 MB/s eta 0:00:15\n",
            "     ------------------------------         478.2/587.7 MB 7.3 MB/s eta 0:00:16\n",
            "     ------------------------------         478.6/587.7 MB 7.2 MB/s eta 0:00:16\n",
            "     ------------------------------         479.0/587.7 MB 7.4 MB/s eta 0:00:15\n",
            "     ------------------------------         479.4/587.7 MB 7.4 MB/s eta 0:00:15\n",
            "     -------------------------------        479.6/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        479.9/587.7 MB 7.2 MB/s eta 0:00:15\n",
            "     -------------------------------        480.3/587.7 MB 7.2 MB/s eta 0:00:15\n",
            "     -------------------------------        480.7/587.7 MB 7.2 MB/s eta 0:00:15\n",
            "     -------------------------------        481.0/587.7 MB 7.2 MB/s eta 0:00:15\n",
            "     -------------------------------        481.3/587.7 MB 7.1 MB/s eta 0:00:15\n",
            "     -------------------------------        481.6/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        481.9/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        482.3/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        482.7/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        483.1/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        483.5/587.7 MB 7.4 MB/s eta 0:00:15\n",
            "     -------------------------------        484.0/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        484.4/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        484.8/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        485.2/587.7 MB 7.3 MB/s eta 0:00:15\n",
            "     -------------------------------        485.7/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        486.0/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        486.3/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        486.6/587.7 MB 7.5 MB/s eta 0:00:14\n",
            "     -------------------------------        486.9/587.7 MB 7.5 MB/s eta 0:00:14\n",
            "     -------------------------------        487.2/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        487.5/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        487.8/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        488.1/587.7 MB 7.5 MB/s eta 0:00:14\n",
            "     -------------------------------        488.5/587.7 MB 7.6 MB/s eta 0:00:14\n",
            "     -------------------------------        488.7/587.7 MB 7.5 MB/s eta 0:00:14\n",
            "     -------------------------------        489.0/587.7 MB 7.5 MB/s eta 0:00:14\n",
            "     -------------------------------        489.3/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        489.7/587.7 MB 7.5 MB/s eta 0:00:14\n",
            "     -------------------------------        490.0/587.7 MB 7.5 MB/s eta 0:00:13\n",
            "     -------------------------------        490.2/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        490.4/587.7 MB 7.3 MB/s eta 0:00:14\n",
            "     -------------------------------        490.7/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        491.0/587.7 MB 7.3 MB/s eta 0:00:14\n",
            "     -------------------------------        491.3/587.7 MB 7.2 MB/s eta 0:00:14\n",
            "     -------------------------------        491.7/587.7 MB 7.3 MB/s eta 0:00:14\n",
            "     -------------------------------        492.0/587.7 MB 7.4 MB/s eta 0:00:14\n",
            "     -------------------------------        492.3/587.7 MB 7.3 MB/s eta 0:00:14\n",
            "     -------------------------------        492.7/587.7 MB 7.4 MB/s eta 0:00:13\n",
            "     -------------------------------        493.1/587.7 MB 7.4 MB/s eta 0:00:13\n",
            "     -------------------------------        493.4/587.7 MB 7.3 MB/s eta 0:00:13\n",
            "     -------------------------------        493.8/587.7 MB 7.2 MB/s eta 0:00:14\n",
            "     -------------------------------        494.1/587.7 MB 7.1 MB/s eta 0:00:14\n",
            "     -------------------------------        494.4/587.7 MB 7.0 MB/s eta 0:00:14\n",
            "     -------------------------------        494.7/587.7 MB 7.0 MB/s eta 0:00:14\n",
            "     --------------------------------       495.0/587.7 MB 7.0 MB/s eta 0:00:14\n",
            "     --------------------------------       495.5/587.7 MB 7.0 MB/s eta 0:00:14\n",
            "     --------------------------------       495.8/587.7 MB 6.9 MB/s eta 0:00:14\n",
            "     --------------------------------       496.2/587.7 MB 7.0 MB/s eta 0:00:14\n",
            "     --------------------------------       496.6/587.7 MB 7.0 MB/s eta 0:00:13\n",
            "     --------------------------------       497.0/587.7 MB 7.0 MB/s eta 0:00:13\n",
            "     --------------------------------       497.4/587.7 MB 7.1 MB/s eta 0:00:13\n",
            "     --------------------------------       497.7/587.7 MB 7.2 MB/s eta 0:00:13\n",
            "     --------------------------------       498.1/587.7 MB 7.2 MB/s eta 0:00:13\n",
            "     --------------------------------       498.4/587.7 MB 7.2 MB/s eta 0:00:13\n",
            "     --------------------------------       498.8/587.7 MB 7.3 MB/s eta 0:00:13\n",
            "     --------------------------------       499.1/587.7 MB 7.3 MB/s eta 0:00:13\n",
            "     --------------------------------       499.4/587.7 MB 7.2 MB/s eta 0:00:13\n",
            "     --------------------------------       499.8/587.7 MB 7.3 MB/s eta 0:00:13\n",
            "     --------------------------------       500.2/587.7 MB 7.3 MB/s eta 0:00:13\n",
            "     --------------------------------       500.6/587.7 MB 7.5 MB/s eta 0:00:12\n",
            "     --------------------------------       501.0/587.7 MB 7.7 MB/s eta 0:00:12\n",
            "     --------------------------------       501.4/587.7 MB 7.8 MB/s eta 0:00:12\n",
            "     --------------------------------       501.9/587.7 MB 7.9 MB/s eta 0:00:11\n",
            "     --------------------------------       502.2/587.7 MB 7.9 MB/s eta 0:00:11\n",
            "     --------------------------------       502.6/587.7 MB 8.0 MB/s eta 0:00:11\n",
            "     --------------------------------       502.8/587.7 MB 7.8 MB/s eta 0:00:11\n",
            "     --------------------------------       503.1/587.7 MB 7.7 MB/s eta 0:00:11\n",
            "     --------------------------------       503.4/587.7 MB 7.7 MB/s eta 0:00:11\n",
            "     --------------------------------       503.7/587.7 MB 7.6 MB/s eta 0:00:12\n",
            "     --------------------------------       504.0/587.7 MB 7.5 MB/s eta 0:00:12\n",
            "     --------------------------------       504.4/587.7 MB 7.8 MB/s eta 0:00:11\n",
            "     --------------------------------       504.9/587.7 MB 7.9 MB/s eta 0:00:11\n",
            "     --------------------------------       505.1/587.7 MB 7.8 MB/s eta 0:00:11\n",
            "     --------------------------------       505.4/587.7 MB 7.7 MB/s eta 0:00:11\n",
            "     --------------------------------       505.9/587.7 MB 7.8 MB/s eta 0:00:11\n",
            "     --------------------------------       506.2/587.7 MB 7.7 MB/s eta 0:00:11\n",
            "     --------------------------------       506.4/587.7 MB 7.6 MB/s eta 0:00:11\n",
            "     --------------------------------       507.0/587.7 MB 7.7 MB/s eta 0:00:11\n",
            "     --------------------------------       507.3/587.7 MB 7.7 MB/s eta 0:00:11\n",
            "     --------------------------------       507.6/587.7 MB 7.6 MB/s eta 0:00:11\n",
            "     --------------------------------       508.0/587.7 MB 7.7 MB/s eta 0:00:11\n",
            "     --------------------------------       508.3/587.7 MB 7.6 MB/s eta 0:00:11\n",
            "     --------------------------------       508.8/587.7 MB 7.8 MB/s eta 0:00:11\n",
            "     --------------------------------       509.2/587.7 MB 7.8 MB/s eta 0:00:11\n",
            "     --------------------------------       509.4/587.7 MB 7.8 MB/s eta 0:00:11\n",
            "     --------------------------------       509.8/587.7 MB 7.7 MB/s eta 0:00:11\n",
            "     --------------------------------       510.2/587.7 MB 7.8 MB/s eta 0:00:10\n",
            "     ---------------------------------      510.7/587.7 MB 7.8 MB/s eta 0:00:10\n",
            "     ---------------------------------      511.2/587.7 MB 7.8 MB/s eta 0:00:10\n",
            "     ---------------------------------      511.5/587.7 MB 7.8 MB/s eta 0:00:10\n",
            "     ---------------------------------      511.8/587.7 MB 7.7 MB/s eta 0:00:10\n",
            "     ---------------------------------      512.2/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      512.4/587.7 MB 7.7 MB/s eta 0:00:10\n",
            "     ---------------------------------      512.7/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      513.0/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      513.3/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      513.7/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      514.0/587.7 MB 7.7 MB/s eta 0:00:10\n",
            "     ---------------------------------      514.3/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      514.7/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      515.0/587.7 MB 7.5 MB/s eta 0:00:10\n",
            "     ---------------------------------      515.4/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      515.8/587.7 MB 7.7 MB/s eta 0:00:10\n",
            "     ---------------------------------      516.1/587.7 MB 7.5 MB/s eta 0:00:10\n",
            "     ---------------------------------      516.4/587.7 MB 7.5 MB/s eta 0:00:10\n",
            "     ---------------------------------      516.9/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      517.3/587.7 MB 7.7 MB/s eta 0:00:10\n",
            "     ---------------------------------      517.6/587.7 MB 7.6 MB/s eta 0:00:10\n",
            "     ---------------------------------      517.9/587.7 MB 7.7 MB/s eta 0:00:10\n",
            "     ---------------------------------      518.4/587.7 MB 7.7 MB/s eta 0:00:10\n",
            "     ---------------------------------      518.6/587.7 MB 7.7 MB/s eta 0:00:09\n",
            "     ---------------------------------      519.0/587.7 MB 7.5 MB/s eta 0:00:10\n",
            "     ---------------------------------      519.4/587.7 MB 7.6 MB/s eta 0:00:09\n",
            "     ---------------------------------      519.6/587.7 MB 7.5 MB/s eta 0:00:10\n",
            "     ---------------------------------      520.0/587.7 MB 7.6 MB/s eta 0:00:09\n",
            "     ---------------------------------      520.3/587.7 MB 7.5 MB/s eta 0:00:09\n",
            "     ---------------------------------      520.6/587.7 MB 7.4 MB/s eta 0:00:10\n",
            "     ---------------------------------      520.9/587.7 MB 7.4 MB/s eta 0:00:10\n",
            "     ---------------------------------      521.3/587.7 MB 7.3 MB/s eta 0:00:10\n",
            "     ---------------------------------      521.8/587.7 MB 7.4 MB/s eta 0:00:09\n",
            "     ---------------------------------      522.2/587.7 MB 7.5 MB/s eta 0:00:09\n",
            "     ---------------------------------      522.6/587.7 MB 7.5 MB/s eta 0:00:09\n",
            "     ---------------------------------      523.0/587.7 MB 7.7 MB/s eta 0:00:09\n",
            "     ---------------------------------      523.4/587.7 MB 7.7 MB/s eta 0:00:09\n",
            "     ---------------------------------      523.8/587.7 MB 7.8 MB/s eta 0:00:09\n",
            "     ---------------------------------      524.2/587.7 MB 7.8 MB/s eta 0:00:09\n",
            "     ---------------------------------      524.4/587.7 MB 7.8 MB/s eta 0:00:09\n",
            "     ---------------------------------      525.0/587.7 MB 7.9 MB/s eta 0:00:08\n",
            "     ---------------------------------      525.5/587.7 MB 8.1 MB/s eta 0:00:08\n",
            "     ----------------------------------     525.9/587.7 MB 8.1 MB/s eta 0:00:08\n",
            "     ----------------------------------     526.3/587.7 MB 8.2 MB/s eta 0:00:08\n",
            "     ----------------------------------     526.6/587.7 MB 8.2 MB/s eta 0:00:08\n",
            "     ----------------------------------     527.0/587.7 MB 8.2 MB/s eta 0:00:08\n",
            "     ----------------------------------     527.4/587.7 MB 8.2 MB/s eta 0:00:08\n",
            "     ----------------------------------     527.7/587.7 MB 8.2 MB/s eta 0:00:08\n",
            "     ----------------------------------     528.0/587.7 MB 8.2 MB/s eta 0:00:08\n",
            "     ----------------------------------     528.3/587.7 MB 8.1 MB/s eta 0:00:08\n",
            "     ----------------------------------     528.7/587.7 MB 8.0 MB/s eta 0:00:08\n",
            "     ----------------------------------     529.0/587.7 MB 8.1 MB/s eta 0:00:08\n",
            "     ----------------------------------     529.3/587.7 MB 8.0 MB/s eta 0:00:08\n",
            "     ----------------------------------     529.7/587.7 MB 8.1 MB/s eta 0:00:08\n",
            "     ----------------------------------     530.0/587.7 MB 8.1 MB/s eta 0:00:08\n",
            "     ----------------------------------     530.2/587.7 MB 7.9 MB/s eta 0:00:08\n",
            "     ----------------------------------     530.4/587.7 MB 7.8 MB/s eta 0:00:08\n",
            "     ----------------------------------     530.7/587.7 MB 7.7 MB/s eta 0:00:08\n",
            "     ----------------------------------     530.9/587.7 MB 7.7 MB/s eta 0:00:08\n",
            "     ----------------------------------     531.2/587.7 MB 7.8 MB/s eta 0:00:08\n",
            "     ----------------------------------     531.5/587.7 MB 7.6 MB/s eta 0:00:08\n",
            "     ----------------------------------     531.7/587.7 MB 7.5 MB/s eta 0:00:08\n",
            "     ----------------------------------     532.0/587.7 MB 7.4 MB/s eta 0:00:08\n",
            "     ----------------------------------     532.3/587.7 MB 7.4 MB/s eta 0:00:08\n",
            "     ----------------------------------     532.5/587.7 MB 7.2 MB/s eta 0:00:08\n",
            "     ----------------------------------     532.8/587.7 MB 7.2 MB/s eta 0:00:08\n",
            "     ----------------------------------     533.0/587.7 MB 7.1 MB/s eta 0:00:08\n",
            "     ----------------------------------     533.2/587.7 MB 7.0 MB/s eta 0:00:08\n",
            "     ----------------------------------     533.4/587.7 MB 6.9 MB/s eta 0:00:08\n",
            "     ----------------------------------     533.7/587.7 MB 6.8 MB/s eta 0:00:08\n",
            "     ----------------------------------     534.0/587.7 MB 6.8 MB/s eta 0:00:08\n",
            "     ----------------------------------     534.4/587.7 MB 6.7 MB/s eta 0:00:08\n",
            "     ----------------------------------     534.8/587.7 MB 6.7 MB/s eta 0:00:08\n",
            "     ----------------------------------     535.2/587.7 MB 6.7 MB/s eta 0:00:08\n",
            "     ----------------------------------     535.5/587.7 MB 6.7 MB/s eta 0:00:08\n",
            "     ----------------------------------     535.8/587.7 MB 6.6 MB/s eta 0:00:08\n",
            "     ----------------------------------     536.2/587.7 MB 6.5 MB/s eta 0:00:08\n",
            "     ----------------------------------     536.5/587.7 MB 6.5 MB/s eta 0:00:08\n",
            "     ----------------------------------     536.7/587.7 MB 6.4 MB/s eta 0:00:08\n",
            "     ----------------------------------     536.8/587.7 MB 6.4 MB/s eta 0:00:08\n",
            "     ----------------------------------     537.0/587.7 MB 6.3 MB/s eta 0:00:09\n",
            "     ----------------------------------     537.2/587.7 MB 6.2 MB/s eta 0:00:09\n",
            "     ----------------------------------     537.4/587.7 MB 6.1 MB/s eta 0:00:09\n",
            "     ----------------------------------     537.6/587.7 MB 6.0 MB/s eta 0:00:09\n",
            "     ----------------------------------     537.9/587.7 MB 5.9 MB/s eta 0:00:09\n",
            "     ----------------------------------     538.1/587.7 MB 6.0 MB/s eta 0:00:09\n",
            "     ----------------------------------     538.3/587.7 MB 5.8 MB/s eta 0:00:09\n",
            "     ----------------------------------     538.6/587.7 MB 5.8 MB/s eta 0:00:09\n",
            "     ----------------------------------     539.0/587.7 MB 5.8 MB/s eta 0:00:09\n",
            "     ----------------------------------     539.3/587.7 MB 5.8 MB/s eta 0:00:09\n",
            "     ----------------------------------     539.7/587.7 MB 5.9 MB/s eta 0:00:09\n",
            "     ----------------------------------     540.0/587.7 MB 5.8 MB/s eta 0:00:09\n",
            "     ----------------------------------     540.1/587.7 MB 5.8 MB/s eta 0:00:09\n",
            "     ----------------------------------     540.4/587.7 MB 5.8 MB/s eta 0:00:09\n",
            "     ----------------------------------     540.5/587.7 MB 5.8 MB/s eta 0:00:09\n",
            "     ----------------------------------     540.8/587.7 MB 5.7 MB/s eta 0:00:09\n",
            "     ----------------------------------     541.2/587.7 MB 5.8 MB/s eta 0:00:08\n",
            "     -----------------------------------    541.5/587.7 MB 5.9 MB/s eta 0:00:08\n",
            "     -----------------------------------    541.9/587.7 MB 6.0 MB/s eta 0:00:08\n",
            "     -----------------------------------    542.3/587.7 MB 6.0 MB/s eta 0:00:08\n",
            "     -----------------------------------    542.5/587.7 MB 6.0 MB/s eta 0:00:08\n",
            "     -----------------------------------    542.6/587.7 MB 5.9 MB/s eta 0:00:08\n",
            "     -----------------------------------    542.8/587.7 MB 5.8 MB/s eta 0:00:08\n",
            "     -----------------------------------    542.9/587.7 MB 5.8 MB/s eta 0:00:08\n",
            "     -----------------------------------    543.1/587.7 MB 5.7 MB/s eta 0:00:08\n",
            "     -----------------------------------    543.2/587.7 MB 5.7 MB/s eta 0:00:08\n",
            "     -----------------------------------    543.4/587.7 MB 5.7 MB/s eta 0:00:08\n",
            "     -----------------------------------    543.6/587.7 MB 5.7 MB/s eta 0:00:08\n",
            "     -----------------------------------    543.7/587.7 MB 5.5 MB/s eta 0:00:09\n",
            "     -----------------------------------    543.8/587.7 MB 5.5 MB/s eta 0:00:09\n",
            "     -----------------------------------    543.9/587.7 MB 5.5 MB/s eta 0:00:08\n",
            "     -----------------------------------    544.1/587.7 MB 5.4 MB/s eta 0:00:09\n",
            "     -----------------------------------    544.3/587.7 MB 5.3 MB/s eta 0:00:09\n",
            "     -----------------------------------    544.5/587.7 MB 5.2 MB/s eta 0:00:09\n",
            "     -----------------------------------    544.8/587.7 MB 5.2 MB/s eta 0:00:09\n",
            "     -----------------------------------    545.1/587.7 MB 5.2 MB/s eta 0:00:09\n",
            "     -----------------------------------    545.5/587.7 MB 5.2 MB/s eta 0:00:09\n",
            "     -----------------------------------    545.8/587.7 MB 5.2 MB/s eta 0:00:09\n",
            "     -----------------------------------    546.1/587.7 MB 5.2 MB/s eta 0:00:09\n",
            "     -----------------------------------    546.3/587.7 MB 5.2 MB/s eta 0:00:09\n",
            "     -----------------------------------    546.5/587.7 MB 5.1 MB/s eta 0:00:09\n",
            "     -----------------------------------    546.7/587.7 MB 5.0 MB/s eta 0:00:09\n",
            "     -----------------------------------    546.9/587.7 MB 5.0 MB/s eta 0:00:09\n",
            "     -----------------------------------    547.1/587.7 MB 5.0 MB/s eta 0:00:09\n",
            "     -----------------------------------    547.3/587.7 MB 5.1 MB/s eta 0:00:08\n",
            "     -----------------------------------    547.6/587.7 MB 5.2 MB/s eta 0:00:08\n",
            "     -----------------------------------    547.7/587.7 MB 5.2 MB/s eta 0:00:08\n",
            "     -----------------------------------    547.7/587.7 MB 5.2 MB/s eta 0:00:08\n",
            "     -----------------------------------    547.7/587.7 MB 4.9 MB/s eta 0:00:09\n",
            "     -----------------------------------    548.3/587.7 MB 5.0 MB/s eta 0:00:08\n",
            "     -----------------------------------    548.5/587.7 MB 5.1 MB/s eta 0:00:08\n",
            "     -----------------------------------    548.9/587.7 MB 5.0 MB/s eta 0:00:08\n",
            "     -----------------------------------    549.4/587.7 MB 5.1 MB/s eta 0:00:08\n",
            "     -----------------------------------    549.8/587.7 MB 5.2 MB/s eta 0:00:08\n",
            "     -----------------------------------    549.8/587.7 MB 5.2 MB/s eta 0:00:08\n",
            "     -----------------------------------    550.3/587.7 MB 5.1 MB/s eta 0:00:08\n",
            "     -----------------------------------    550.6/587.7 MB 5.2 MB/s eta 0:00:08\n",
            "     -----------------------------------    551.0/587.7 MB 5.3 MB/s eta 0:00:07\n",
            "     -----------------------------------    551.2/587.7 MB 5.2 MB/s eta 0:00:07\n",
            "     -----------------------------------    551.5/587.7 MB 5.2 MB/s eta 0:00:07\n",
            "     -----------------------------------    551.9/587.7 MB 5.2 MB/s eta 0:00:07\n",
            "     -----------------------------------    552.2/587.7 MB 5.2 MB/s eta 0:00:07\n",
            "     -----------------------------------    552.5/587.7 MB 5.1 MB/s eta 0:00:07\n",
            "     -----------------------------------    552.8/587.7 MB 5.2 MB/s eta 0:00:07\n",
            "     -----------------------------------    553.1/587.7 MB 5.3 MB/s eta 0:00:07\n",
            "     -----------------------------------    553.4/587.7 MB 5.5 MB/s eta 0:00:07\n",
            "     -----------------------------------    553.7/587.7 MB 5.6 MB/s eta 0:00:07\n",
            "     -----------------------------------    554.1/587.7 MB 5.8 MB/s eta 0:00:06\n",
            "     -----------------------------------    554.4/587.7 MB 6.1 MB/s eta 0:00:06\n",
            "     -----------------------------------    554.7/587.7 MB 6.1 MB/s eta 0:00:06\n",
            "     -----------------------------------    555.1/587.7 MB 6.2 MB/s eta 0:00:06\n",
            "     -----------------------------------    555.5/587.7 MB 6.2 MB/s eta 0:00:06\n",
            "     -----------------------------------    555.8/587.7 MB 6.2 MB/s eta 0:00:06\n",
            "     -----------------------------------    556.1/587.7 MB 6.2 MB/s eta 0:00:06\n",
            "     -----------------------------------    556.5/587.7 MB 6.2 MB/s eta 0:00:06\n",
            "     ------------------------------------   556.9/587.7 MB 6.5 MB/s eta 0:00:05\n",
            "     ------------------------------------   557.3/587.7 MB 6.6 MB/s eta 0:00:05\n",
            "     ------------------------------------   557.7/587.7 MB 6.8 MB/s eta 0:00:05\n",
            "     ------------------------------------   558.0/587.7 MB 7.5 MB/s eta 0:00:04\n",
            "     ------------------------------------   558.4/587.7 MB 7.3 MB/s eta 0:00:05\n",
            "     ------------------------------------   558.7/587.7 MB 7.4 MB/s eta 0:00:04\n",
            "     ------------------------------------   559.0/587.7 MB 7.4 MB/s eta 0:00:04\n",
            "     ------------------------------------   559.4/587.7 MB 7.4 MB/s eta 0:00:04\n",
            "     ------------------------------------   559.7/587.7 MB 7.2 MB/s eta 0:00:04\n",
            "     ------------------------------------   560.1/587.7 MB 7.4 MB/s eta 0:00:04\n",
            "     ------------------------------------   560.6/587.7 MB 7.4 MB/s eta 0:00:04\n",
            "     ------------------------------------   560.9/587.7 MB 7.4 MB/s eta 0:00:04\n",
            "     ------------------------------------   561.2/587.7 MB 7.4 MB/s eta 0:00:04\n",
            "     ------------------------------------   561.6/587.7 MB 7.4 MB/s eta 0:00:04\n",
            "     ------------------------------------   561.9/587.7 MB 7.4 MB/s eta 0:00:04\n",
            "     ------------------------------------   562.3/587.7 MB 7.5 MB/s eta 0:00:04\n",
            "     ------------------------------------   562.6/587.7 MB 7.6 MB/s eta 0:00:04\n",
            "     ------------------------------------   563.1/587.7 MB 7.7 MB/s eta 0:00:04\n",
            "     ------------------------------------   563.4/587.7 MB 7.7 MB/s eta 0:00:04\n",
            "     ------------------------------------   563.8/587.7 MB 7.8 MB/s eta 0:00:04\n",
            "     ------------------------------------   564.1/587.7 MB 7.8 MB/s eta 0:00:04\n",
            "     ------------------------------------   564.4/587.7 MB 7.7 MB/s eta 0:00:04\n",
            "     ------------------------------------   564.7/587.7 MB 7.7 MB/s eta 0:00:03\n",
            "     ------------------------------------   565.0/587.7 MB 7.8 MB/s eta 0:00:03\n",
            "     ------------------------------------   565.4/587.7 MB 7.7 MB/s eta 0:00:03\n",
            "     ------------------------------------   565.7/587.7 MB 7.6 MB/s eta 0:00:03\n",
            "     ------------------------------------   565.9/587.7 MB 7.5 MB/s eta 0:00:03\n",
            "     ------------------------------------   566.3/587.7 MB 7.6 MB/s eta 0:00:03\n",
            "     ------------------------------------   566.8/587.7 MB 7.6 MB/s eta 0:00:03\n",
            "     ------------------------------------   567.1/587.7 MB 7.7 MB/s eta 0:00:03\n",
            "     ------------------------------------   567.5/587.7 MB 7.7 MB/s eta 0:00:03\n",
            "     ------------------------------------   567.7/587.7 MB 7.5 MB/s eta 0:00:03\n",
            "     ------------------------------------   568.0/587.7 MB 7.4 MB/s eta 0:00:03\n",
            "     ------------------------------------   568.3/587.7 MB 7.4 MB/s eta 0:00:03\n",
            "     ------------------------------------   568.5/587.7 MB 7.4 MB/s eta 0:00:03\n",
            "     ------------------------------------   568.9/587.7 MB 7.4 MB/s eta 0:00:03\n",
            "     ------------------------------------   569.3/587.7 MB 7.4 MB/s eta 0:00:03\n",
            "     ------------------------------------   569.8/587.7 MB 7.5 MB/s eta 0:00:03\n",
            "     ------------------------------------   570.1/587.7 MB 7.5 MB/s eta 0:00:03\n",
            "     ------------------------------------   570.5/587.7 MB 7.4 MB/s eta 0:00:03\n",
            "     ------------------------------------   571.0/587.7 MB 7.4 MB/s eta 0:00:03\n",
            "     ------------------------------------   571.3/587.7 MB 7.5 MB/s eta 0:00:03\n",
            "     ------------------------------------   571.8/587.7 MB 7.6 MB/s eta 0:00:03\n",
            "     ------------------------------------   572.1/587.7 MB 7.8 MB/s eta 0:00:02\n",
            "     -------------------------------------  572.6/587.7 MB 7.7 MB/s eta 0:00:02\n",
            "     -------------------------------------  572.9/587.7 MB 7.7 MB/s eta 0:00:02\n",
            "     -------------------------------------  573.2/587.7 MB 7.6 MB/s eta 0:00:02\n",
            "     -------------------------------------  573.6/587.7 MB 7.6 MB/s eta 0:00:02\n",
            "     -------------------------------------  574.1/587.7 MB 7.7 MB/s eta 0:00:02\n",
            "     -------------------------------------  574.5/587.7 MB 7.7 MB/s eta 0:00:02\n",
            "     -------------------------------------  574.8/587.7 MB 7.8 MB/s eta 0:00:02\n",
            "     -------------------------------------  575.2/587.7 MB 7.9 MB/s eta 0:00:02\n",
            "     -------------------------------------  575.6/587.7 MB 7.9 MB/s eta 0:00:02\n",
            "     -------------------------------------  575.8/587.7 MB 7.8 MB/s eta 0:00:02\n",
            "     -------------------------------------  576.2/587.7 MB 7.9 MB/s eta 0:00:02\n",
            "     -------------------------------------  576.5/587.7 MB 8.0 MB/s eta 0:00:02\n",
            "     -------------------------------------  576.8/587.7 MB 7.8 MB/s eta 0:00:02\n",
            "     -------------------------------------  577.3/587.7 MB 7.8 MB/s eta 0:00:02\n",
            "     -------------------------------------  577.6/587.7 MB 7.9 MB/s eta 0:00:02\n",
            "     -------------------------------------  578.1/587.7 MB 8.1 MB/s eta 0:00:02\n",
            "     -------------------------------------  578.5/587.7 MB 8.2 MB/s eta 0:00:02\n",
            "     -------------------------------------  578.9/587.7 MB 8.4 MB/s eta 0:00:02\n",
            "     -------------------------------------  579.2/587.7 MB 8.3 MB/s eta 0:00:02\n",
            "     -------------------------------------  579.5/587.7 MB 8.3 MB/s eta 0:00:01\n",
            "     -------------------------------------  579.8/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  580.1/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  580.5/587.7 MB 8.0 MB/s eta 0:00:01\n",
            "     -------------------------------------  581.0/587.7 MB 8.0 MB/s eta 0:00:01\n",
            "     -------------------------------------  581.3/587.7 MB 8.0 MB/s eta 0:00:01\n",
            "     -------------------------------------  581.6/587.7 MB 7.9 MB/s eta 0:00:01\n",
            "     -------------------------------------  582.0/587.7 MB 7.9 MB/s eta 0:00:01\n",
            "     -------------------------------------  582.4/587.7 MB 7.8 MB/s eta 0:00:01\n",
            "     -------------------------------------  582.7/587.7 MB 7.8 MB/s eta 0:00:01\n",
            "     -------------------------------------  583.2/587.7 MB 7.9 MB/s eta 0:00:01\n",
            "     -------------------------------------  583.6/587.7 MB 8.0 MB/s eta 0:00:01\n",
            "     -------------------------------------  584.0/587.7 MB 7.9 MB/s eta 0:00:01\n",
            "     -------------------------------------  584.4/587.7 MB 7.9 MB/s eta 0:00:01\n",
            "     -------------------------------------  584.8/587.7 MB 7.9 MB/s eta 0:00:01\n",
            "     -------------------------------------  585.1/587.7 MB 7.9 MB/s eta 0:00:01\n",
            "     -------------------------------------  585.2/587.7 MB 7.8 MB/s eta 0:00:01\n",
            "     -------------------------------------  585.5/587.7 MB 7.7 MB/s eta 0:00:01\n",
            "     -------------------------------------  585.8/587.7 MB 7.6 MB/s eta 0:00:01\n",
            "     -------------------------------------  586.3/587.7 MB 7.8 MB/s eta 0:00:01\n",
            "     -------------------------------------  586.8/587.7 MB 7.9 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.3/587.7 MB 8.0 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  587.7/587.7 MB 8.1 MB/s eta 0:00:01\n",
            "     -------------------------------------- 587.7/587.7 MB 4.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from en-core-web-lg==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.6)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.2)\n",
            "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\home_torch\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "âœ” Download and installation successful\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th7D5H7nRL6l"
      },
      "source": [
        "After having downloaded the model, we can load it as follows (you may need to restart your notebook after the download is complete):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QXRNdoKPRL6l"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mtryqohRL6m"
      },
      "source": [
        "We can then use the loaded model to process a sentence and obtain its word vectors, a List of 300-dimensional numpy arrays. [More info](https://spacy.io/models/en#en_core_web_lg) about vectors coming with `en_core_web_lg`.  \n",
        "We can also check similarities between the vectors, e.g., `words` is more similar to `sentence` than to `this`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mlrz38KrRL6m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We have 7 vectors, each of shape (300,) and of type <class 'numpy.ndarray'>\n",
            "'words' is 0.51 similar to 'sentence' and 0.36 similar to 'this'\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"this is a sentence of 7 words\")  # the processed sentence\n",
        "vectors = list(map(lambda x: x.vector, doc))  # its vectors\n",
        "# vectors = [ t.vector for t in doc ] # or the same with list comprehension\n",
        "\n",
        "print(f\"We have {len(vectors)} vectors\", end=\", \")\n",
        "print(f\"each of shape {vectors[0].shape} and of type {type(vectors[0])}\")\n",
        "\n",
        "print(f\"'{doc[6]}' is {doc[6].similarity(doc[3]):.2f} similar to '{doc[3]}' and {doc[6].similarity(doc[0]):.2f} similar to '{doc[0]}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzWqTHErRL6n"
      },
      "source": [
        "And then finally convert them into torch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "t01KiV3-RL6n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([7, 300])\n"
          ]
        }
      ],
      "source": [
        "torch_vectors = torch.tensor(np.array(vectors))\n",
        "# torch_vectors = torch.tensor(vectors) # this is also fine but might get an efficiency warning from torch\n",
        "print(torch_vectors.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH00drXzRL6n"
      },
      "source": [
        "Or, in the case of multiple sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jMEDL92hRL6o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 300])\n"
          ]
        }
      ],
      "source": [
        "# Example sentences.\n",
        "sentences = [\"This is a sentence\", \"This is another sentence.\"]\n",
        "\n",
        "# Parallel processing with spacy.\n",
        "docs = list(map(nlp, sentences))\n",
        "\n",
        "# Convert each processed sentence into a list of vectors.\n",
        "vectors = map(lambda doc: [word.vector for word in doc], docs)\n",
        "\n",
        "# Convert each list of vectors into a 2-d torch tensor.\n",
        "tensors = list(map(lambda sentence_vectors: torch.tensor(np.array(sentence_vectors)), vectors))\n",
        "print(tensors[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KneP-DJARL6o"
      },
      "source": [
        "Given our pretrained embeddings, we may represent sentences as _sequences of pretrained vectors_, which is exactly the format expected by an RNN. (That is, to be clear, our pretrained embeddings will be used as input vectors for our RNN.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HaOBUqRRL6o"
      },
      "source": [
        "### Examining the data\n",
        "First, let's load and inspect our data files.\n",
        "\n",
        "The pickle file contains three items:\n",
        "1. `sentences`: a List of strings (sentences)\n",
        "2. `postags`: a List of Lists of strings (POS tags)\n",
        "3. `pos_to_int`: a Dictionary from strings to ints (mapping each POS tag to a unique identifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4f4p4mjkRL6p"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Download files on the fly with the below two lines\n",
        "!wget -nv https://naturallogic.pro/_files_/download/MLHVL/pos-rnn-data.zip\n",
        "!unzip -n pos-rnn-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KmKZN9v_RL6p"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"TRAIN.p\", \"rb\") as f:\n",
        "    sentences, postags, pos_to_int = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zyPpw07RL6p"
      },
      "source": [
        "Let's sanity check that we have the same number of sentences as pos tag annotations and for each sentence and annotation pair, the number of tokens and tags are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "eUIHuXiHRL6p"
      },
      "outputs": [],
      "source": [
        "assert all(list(map(lambda s, p: len(s.split()) == len(p), sentences, postags)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k98ihwYRL6q"
      },
      "source": [
        "Now, let us take a moment to understand the data a bit more.\n",
        "Run the cell below with different values of `i` to get an idea of how the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VBHb9eImRL6q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The/DT luxury/NN auto/NN maker/NN last/JJ year/NN sold/VBD 1,214/CD cars/NNS in/IN the/DT U.S./NNP "
          ]
        }
      ],
      "source": [
        "i = 2\n",
        "for tok, tag in zip(sentences[i].split(), postags[i]):\n",
        "    print(f\"{tok}/{tag}\", end=' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "CALfFyxgCz6v"
      },
      "outputs": [],
      "source": [
        "del i, tok, tag, torch_vectors, vectors, f, doc, docs, tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3q4FEHERL6q"
      },
      "source": [
        "#### TASK 3\n",
        "\n",
        "The POS tags in this dataset are in the style of the Penn Treebank. Find the top 20 most common tags and summarise by plotting their frequencies, e.g., the histogram of the top 20 most frequent POS tags sitting on the x axis and y axis marking their raw counts. Find what these tags mean linguistically and state what the top 6 POS tags represent. See https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html for details.  \n",
        "<font color=\"red\">_Hint_: you can use pandas; the 7th and 8th most frequent tags are punctuation marks.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9YreOuYkRL6r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title c3.1 [1pt]\n",
        "\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Flatten the list of lists\n",
        "all_tags = [tag for sublist in postags for tag in sublist]\n",
        "\n",
        "# Count the tags\n",
        "tag_counts = Counter(all_tags)\n",
        "\n",
        "# Get the top 20 most common tags\n",
        "top20 = tag_counts.most_common(20)\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "df = pd.DataFrame(top20, columns=['POS Tag', 'Count'])\n",
        "\n",
        "# Plot the frequencies\n",
        "plt.figure(figsize=(12,6))\n",
        "df.plot(kind='bar', x='POS Tag', y='Count', legend=False)\n",
        "plt.xlabel('POS Tag')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 20 POS Tags')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekTGBBzWRL6r"
      },
      "source": [
        "We will explore the data some more, which will lead us to two baseline models on predicting POS tags. The first model would simply predicting the most frequent POS tag regardless of the input word sequence. We call such a model the most frequent tag (MFT) model.\n",
        "\n",
        "Write a function that takes training and test sets of POS tags and returns (i) the score of the MFT model on the test set, and (ii) the MFT based on the training set.    \n",
        "Note that the function doesn't take training and test sets of sentences as the MFT model doesn't make use of word sequences.  \n",
        "<font color=\"red\">_Hint_: you might want to use `Counter` from `collections` that facilitates counting itmes.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "dLcWvvSKRL6r"
      },
      "outputs": [],
      "source": [
        "# @title c3.2 [1pt]\n",
        "\n",
        "def mft_baseline(pos_train: List[List[str]], pos_test: List[List[str]]) -> Tuple[float, str]:\n",
        "    \"\"\"\n",
        "    Takes training and test sets of POS tags and returns\n",
        "    (i) the score of the MFT model on the test set, and (ii) the MFT on the training set.\n",
        "    \"\"\"\n",
        "    # Flatten the training POS tags\n",
        "    train_tags = [tag for seq in pos_train for tag in seq]\n",
        "    # Find the most frequent tag in training data\n",
        "    tag_counts = Counter(train_tags)\n",
        "    mft = tag_counts.most_common(1)[0][0]\n",
        "    # Predict the MFT for all test data\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for seq in pos_test:\n",
        "        total += len(seq)\n",
        "        correct += sum(1 for tag in seq if tag == mft)\n",
        "    score = correct / total\n",
        "    return score, mft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "B-FKsDNhCAWa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mft_score = 0.1408964685014757, where mft = NN\n"
          ]
        }
      ],
      "source": [
        "# TEST c3.2\n",
        "# testing the function on the sample input\n",
        "mft_score, mft = mft_baseline(postags[:24_000], postags[24_000:])\n",
        "print(f\"mft_score = {mft_score}, where mft = {mft}\")\n",
        "\n",
        "assert mft_score > 0.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKDz6MTDRL6s"
      },
      "source": [
        "Another baseline model to predict POS tag would assign the most frequent POS tag given the single previous word. This baseline is called the unigram baseline. We will explore how much data would be accounted for this way.  \n",
        "\n",
        "Complete the function `unigram_baseline` below. It takes usual input: training and test sets, each represented with list of sentences and list of the corresonding POS tags. Note that unlike the MFT baseline, the unigram baseline takes words into account. The function returns (i) the score that the unigram model trained on the training set obtains on the test set, and (ii) the unigram model that is represented as a [`defaultdict`](https://docs.python.org/3/library/collections.html#collections.defaultdict), where he default value is the most frequent tag that is predicted for the words unseen in the training set, but seen in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "v0kw8UdvE3EF"
      },
      "outputs": [],
      "source": [
        "# @title c3.3 [2pt]\n",
        "\n",
        "def unigram_baseline(sen_train: List[str], pos_train: List[List[str]],\n",
        "                     sen_test: List[str], pos_test: List[List[str]]) -> Tuple[float, defaultdict]:\n",
        "    \"\"\"\n",
        "    Takes training and test sets, each represented with list of sentences and list of the corresonding POS tags.\n",
        "    Note that unlike the MFT baseline, the unigram baseline takes words into account.\n",
        "    \"\"\"\n",
        "    # Get the most frequent tag\n",
        "    mft_score, mft = mft_baseline(pos_train, pos_test)\n",
        "\n",
        "    # Build a mapping from word to most frequent tag in training data\n",
        "    word_tag_counts = defaultdict(Counter)\n",
        "    for sentence, tags in zip(sen_train, pos_train):\n",
        "        words = sentence.split()\n",
        "        for word, tag in zip(words, tags):\n",
        "            word_tag_counts[word][tag] +=1\n",
        "\n",
        "    # For each word, get the most frequent tag\n",
        "    unigram = defaultdict(lambda: mft)\n",
        "    for word, tag_counter in word_tag_counts.items():\n",
        "        unigram[word] = tag_counter.most_common(1)[0][0]\n",
        "\n",
        "    # Now, compute the score on test data\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for sentence, tags in zip(sen_test, pos_test):\n",
        "        words = sentence.split()\n",
        "        for word, tag in zip(words, tags):\n",
        "            pred_tag = unigram[word]\n",
        "            total +=1\n",
        "            if pred_tag == tag:\n",
        "                correct +=1\n",
        "    score = correct / total\n",
        "    return score, unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "HYVlekyJJu9u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unigram_score = 0.9060423663511725\n"
          ]
        }
      ],
      "source": [
        "# TEST c3.3\n",
        "# testing the function on the sample input\n",
        "unigram_score, unigram = unigram_baseline(sentences[:24_000], postags[:24_000], sentences[24_000:], postags[24_000:])\n",
        "print(f\"unigram_score = {unigram_score}\")\n",
        "\n",
        "assert unigram_score > 0.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "6Tu7VQ0tEYCc"
      },
      "outputs": [],
      "source": [
        "del mft_score, mft, unigram_score, unigram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z2zHSseRL6t"
      },
      "source": [
        "### Tensorizing sentences\n",
        "Next, we need to convert our data to numeric form. We will convert sentences to their tensor format, as done earlier.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Important!</b>\n",
        "Since the sentences are pre-tokenized with whitespace (e.g., <code>One , two , and three .</code> instead of <code>One, two, and three.</code>), we need to change the processing call to ensure the output vectors are aligned with our tokenization (otherwise SpaCy will tokenize it in its own way and might break the correspondence between tokens and POS tags).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6dvDLY0-RL6u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 300])\n"
          ]
        }
      ],
      "source": [
        "docs = [ spacy.tokens.doc.Doc(nlp.vocab, words=sentence.split()) for sentence in sentences ]\n",
        "\n",
        "doc_vectors = [ np.array([word.vector for word in doc]) for doc in docs ]\n",
        "doc_tensors = [ torch.tensor(sentence_vectors) for sentence_vectors in doc_vectors ]\n",
        "\n",
        "print(doc_tensors[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpryqcr0RL6u"
      },
      "source": [
        "Similarly, we will use pos_to_int to convert the POS sequences into tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kk6HyaPnRL6u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5])\n",
            "tensor([12, 12, 26, 12, 14], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "pos_numeric = [ np.array([pos_to_int[pos] for pos in pos_sequence]) for pos_sequence in postags ]\n",
        "pos_tensors =  [ torch.tensor(pos_num_sequence) for pos_num_sequence in pos_numeric ]\n",
        "\n",
        "print(pos_tensors[1].shape)\n",
        "print(pos_tensors[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "o4aSD7AHRL6u"
      },
      "outputs": [],
      "source": [
        "del doc_vectors, docs, pos_numeric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqT06ZfZRL6v"
      },
      "source": [
        "Finally, we also need to prepare for our task, which is **predicting** the POS tag. Right now, each element in doc\\_tensors is a 2-dimensional tensor with rows corresponding to the vectors of the words in a sentence, and each element in pos\\_tensors is a one-dimensional tensor with components representing the indices of the POS tag of the words. If we used these data for our model as it is, the model would not predict a tag based on the preceding words, but it would do a simple sequence POS-tag labelling (see Jurafsky and Martin [Chapter 8](https://web.stanford.edu/~jurafsky/slp3/8.pdf) for sequence labelling).\n",
        "\n",
        "What we need instead is that the tensor elements of `doc_tensors` start their rows at the first word but ends at the last but one word (because the last word triggers no prediction). Conversely, the output tensor elements of `pos_tensors` should only start at the tag of the second word and go to the end (the first word will create the first context for predictions about the POS tag of the second word, words 1 and 2 will be the context to predict the POS tag of the third word etc.).\n",
        "\n",
        "In a nutshell, to model POS tagging of upcoming words, we will use sequence labeling (like the standard POS tagging does), but the left-hand side context needs to exclude the upcoming word $w_t$ when predicting a POS tag $p_t$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am5KBVgrRL6v"
      },
      "source": [
        "#### TASK 4\n",
        "\n",
        "Create new lists, doc\\_tensors\\_predict and pos\\_tensors\\_predict, which will have the information as is described in the paragraph above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "yZmN3HpBRL6v"
      },
      "outputs": [],
      "source": [
        "# @title c4.1 [1pt]\n",
        "\n",
        "# Modifying vectors for the prediction task.\n",
        "doc_tensors_predict = [dt[:-1] for dt in doc_tensors]\n",
        "pos_tensors_predict = [pt[1:] for pt in pos_tensors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "R84X_zwoRL6v"
      },
      "outputs": [],
      "source": [
        "# TEST c4.1\n",
        "# the following tests establish that doc_tensor and doc_tensors_predict are related\n",
        "assert np.all(np.array(doc_tensors[0][43] == doc_tensors_predict[0][43]))\n",
        "assert doc_tensors[3].shape[0] == doc_tensors_predict[3].shape[0] + 1\n",
        "assert doc_tensors[3].shape[1] == doc_tensors_predict[3].shape[1]\n",
        "assert np.array(pos_tensors[2][-1] == pos_tensors_predict[2][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euD_sRqSRL6w"
      },
      "source": [
        "In the tutorial, we saw how to split our dataset into a training and a validation set.\n",
        "\n",
        "We will do the same here, splitting the sentences, POS tags and their corresponding tensors into a training and a validation set.  \n",
        "For the sake of determinism of the training, while splitting data, we set shuffling `random_state` to 42 and select 0.2 of the data for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "6ceVTdneRL6w"
      },
      "outputs": [],
      "source": [
        "sentences_train, sentences_val, postags_train, postags_val, X_train, X_val, Y_train, Y_val \\\n",
        "    = train_test_split(sentences, postags, doc_tensors_predict, pos_tensors_predict, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckrQqjFNHkCt"
      },
      "source": [
        "After we have defined the training and validation sets, we can use the defined functions to calculate the scores of MFT and unigram baseline models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8vsM2XKFRL6x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mft_score = 0.14045150489117786, where mft = NN\n"
          ]
        }
      ],
      "source": [
        "# MFT baseline\n",
        "mft_score, mft = mft_baseline(postags_train, postags_val)\n",
        "print(f\"mft_score = {mft_score}, where mft = {mft}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "uM0lK9qaIX-S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unigram_score = 0.9154272929976952\n"
          ]
        }
      ],
      "source": [
        "# Unigram baseline\n",
        "unigram_score, unigram = unigram_baseline(sentences_train, postags_train, sentences_val, postags_val)\n",
        "print(f\"unigram_score = {unigram_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0oV9FuRRL6x"
      },
      "source": [
        "### Datasets and Padding\n",
        "\n",
        "Following along the tutorial, we will wrap our tensors into a `Dataset` ([link](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)) and a `DataLoader` ([link](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)).\n",
        "\n",
        "Since our data are not Tensors but rather Lists of Tensors of uneven lengths, we need to write our own Dataset wrapper.\n",
        "The wrapper only needs to implement two functions; `__len__`, which expects no arguments and returns the number of samples in the dataset, and `__getitem__`, which accepts an index `idx` and returns the input-output pair `X[idx]`, `Y[idx]`.\n",
        "\n",
        "Similarly, the Dataloader needs to process the list of input-output pairs produced by the Dataset using `pad_sequence`, as seen earlier.\n",
        "\n",
        "We will fill in the code for `UnevenLengthDataset` class, implementing its two core functions.\n",
        "\n",
        "Then, we complete the function `pad_batch` which takes a list of (x$_i$, y$_i$) pairs and produces the pair of their paddings: (X, Y).\n",
        "\n",
        "Given the two, the `DataLoader` object can iterate over the Dataset yielding uniform batches ready to be consumed by an RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ygvKphINRL6x",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "class UnevenLengthDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X: List[FloatTensor], Y: List[LongTensor]) -> None:\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        assert len(X) == len(Y), f\"different size of X {len(X)} and Y {len(Y)}\"\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[FloatTensor, LongTensor]:\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "def pad_batch(batch: List[Tuple[FloatTensor, LongTensor]]) -> Tuple[FloatTensor, LongTensor]:\n",
        "    first_item_padded = pad_sequence([item[0] for item in batch])\n",
        "    second_item_padded = pad_sequence([item[1] for item in batch])\n",
        "    return first_item_padded, second_item_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "PvFF3Cg_RL6y"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32 # don't change this value\n",
        "\n",
        "train_dataset = UnevenLengthDataset(X_train, Y_train)\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    collate_fn=pad_batch,\n",
        "    shuffle=True, # data will be reshuffled at every epoch\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_dataset = UnevenLengthDataset(X_val, Y_val)\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    collate_fn=pad_batch,\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iUk215PRL6y"
      },
      "source": [
        "What does a batch look like, shape-wise? Get the first element of `train_dataloader` to find out.  \n",
        "Try to understand what each number in the shape means.  \n",
        "<font color=\"red\">_Hint_: 41 is the length of a sequence in the batch, but why 41?</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "gbcfD_35RL6y",
        "lines_to_next_cell": 1
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([41, 32, 300])\n",
            "torch.Size([41, 32])\n"
          ]
        }
      ],
      "source": [
        "# without the seed, every time you run this cell, it will give a random batch\n",
        "torch.manual_seed(0)\n",
        "for batch_x, batch_y in train_dataloader:\n",
        "    print(batch_x.shape)\n",
        "    print(batch_y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "v4T9Mkh-Ezp3"
      },
      "outputs": [],
      "source": [
        "del batch_x, batch_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMrgbE4zRL6y"
      },
      "source": [
        "### Utility functions\n",
        "\n",
        "Remember how we defined our training and validation functions in the torch intro notebook?\n",
        "\n",
        "You will need to do the same here.\n",
        "Note that while you can use the code from the tutorial for guidance, just copying it won't do the trick; unlike a feedforward net, a recurrent network produces a 3rd order output tensor of shape (max_seq_len, batch_size, num_output_classes).\n",
        "\n",
        "Similarly, our target Y is a 2nd order tensor of shape (max_seq_len, batch_size).\n",
        "\n",
        "You will need to properly treat the extra dimension of both the output and the target, since loss functions expect an order 2 output tensor and an order 1 target tensor.\n",
        "\n",
        "The functions `accuracy` and `measure_accurace`, which will be needed during evaluation, are already provided to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "MFlBSgJCRL6z",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def accuracy(predictions: LongTensor, truth: LongTensor, ignore_idx: int) -> Tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Compute the total count of non-ignored values and total count of correctly predicted values.\n",
        "\n",
        "    :param predictions: the network's predictions\n",
        "    :param truth: the true output labels\n",
        "    :param ignore_idx: the output padding value, to be ignored in accuracy calculation\n",
        "    :return the total count of non-ignored values, the total count of correctly predicted values\n",
        "    \"\"\"\n",
        "    correct_words = torch.ones(predictions.size())\n",
        "    # Zero out the incorrectly predicted values.\n",
        "    correct_words[predictions != truth] = 0\n",
        "    # Mark with 1 the values that need to be ignored.\n",
        "    correct_words[truth == ignore_idx] = 1\n",
        "    # Calculate the total count of correctly predicted values, incl. the ignored ones.\n",
        "    num_correct_words = correct_words.sum().item()\n",
        "    # Calculate the number of the values to be ignored.\n",
        "    num_masked_words = len(truth[truth == ignore_idx])\n",
        "    #\n",
        "    count_non_ignored = predictions.shape[0] * predictions.shape[1] - num_masked_words\n",
        "    count_correct = num_correct_words - num_masked_words\n",
        "    return count_non_ignored, count_correct\n",
        "\n",
        "\n",
        "def measure_accuracy(network: torch.nn.Module, dataloader: DataLoader, device: str) -> float:\n",
        "    \"\"\"\n",
        "    Compute the network's accuracy across all batches.\n",
        "\n",
        "    :param network: the trained network\n",
        "    :param dataloader: the dataloader for the validation data\n",
        "    :param device: the device to store the data on (\"cpu\" or \"cuda\")\n",
        "    :return the network's accuracy\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # Iterate over the batches.\n",
        "    for x_batch, y_batch in dataloader:\n",
        "        # Get the network predictions.\n",
        "        pred = network(x_batch.to(device))\n",
        "        # Compute the values to measure accuracy for the current batch.\n",
        "        # note that pos tags are mapped to numbers 1..48 and we can safely use 0 for making dummy padding slots\n",
        "        local_total, local_correct = accuracy(pred.argmax(dim=-1), y_batch.to(device), ignore_idx=0)\n",
        "        # Update the total counts.\n",
        "        correct += local_correct\n",
        "        total += local_total\n",
        "    # Compute the final accuracy across all batches.\n",
        "    acc = correct/total\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "wpWoJrI4RL6z",
        "lines_to_next_cell": 1
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 3.0)\n",
            "(8, 6.0)\n"
          ]
        }
      ],
      "source": [
        "# If you want to understand how accuracy works, you can verify these toy input/output pairs\n",
        "print(accuracy(LongTensor([[1,2,0,0], [3,4,5,0]]), LongTensor([[1,3,0,0], [1,4,5,0]]), ignore_idx=0))\n",
        "print(accuracy(LongTensor([[1,2,0,0], [3,4,5,0]]), LongTensor([[1,3,0,0], [1,4,5,0]]), ignore_idx=9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e35TY8s2RL6z"
      },
      "source": [
        "#### TASK 5\n",
        "\n",
        "Complete the functions `train_batch`, `train_epoch`, `eval_batch` and `eval_epoch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "CAODtkBQRL60",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# @title c5 [3pt]\n",
        "\n",
        "def train_batch(\n",
        "    network: torch.nn.Module,\n",
        "    X_batch: FloatTensor,\n",
        "    Y_batch: LongTensor,\n",
        "    loss_fn: Callable[[FloatTensor, FloatTensor], FloatTensor],\n",
        "    optimizer: torch.optim.Optimizer\n",
        ") -> float: #batch-specific loss\n",
        "    optimizer.zero_grad()\n",
        "    X_batch = X_batch.to(DEVICE)\n",
        "    Y_batch = Y_batch.to(DEVICE)\n",
        "    outputs = network(X_batch)\n",
        "    outputs = outputs.view(-1, outputs.size(-1))\n",
        "    Y_batch = Y_batch.view(-1)\n",
        "    loss = loss_fn(outputs, Y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def train_epoch(\n",
        "    network: torch.nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: Callable[[FloatTensor, FloatTensor], FloatTensor],\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    device: str\n",
        ") -> float: #epoch's loss\n",
        "    network.train()\n",
        "    total_loss = 0.0\n",
        "    for X_batch, Y_batch in dataloader:\n",
        "        batch_loss = train_batch(network, X_batch, Y_batch, loss_fn, optimizer)\n",
        "        total_loss += batch_loss\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "def eval_batch(\n",
        "    network: torch.nn.Module,\n",
        "    X_batch: FloatTensor,\n",
        "    Y_batch: LongTensor,\n",
        "    loss_fn: Callable[[FloatTensor, LongTensor], FloatTensor]\n",
        ") -> float: #batch-specific loss\n",
        "    with torch.no_grad():\n",
        "        X_batch = X_batch.to(DEVICE)\n",
        "        Y_batch = Y_batch.to(DEVICE)\n",
        "        outputs = network(X_batch)\n",
        "        outputs = outputs.view(-1, outputs.size(-1))\n",
        "        Y_batch = Y_batch.view(-1)\n",
        "        loss = loss_fn(outputs, Y_batch)\n",
        "    return loss.item()\n",
        "\n",
        "def eval_epoch(\n",
        "    network: torch.nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: Callable[[FloatTensor, LongTensor], FloatTensor],\n",
        "    device: str\n",
        ") -> float: #epoch's loss\n",
        "    network.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, Y_batch in dataloader:\n",
        "            batch_loss = eval_batch(network, X_batch, Y_batch, loss_fn)\n",
        "            total_loss += batch_loss\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shiaeNJ7RL60"
      },
      "source": [
        "### Training your SRN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKIT8AaERL60"
      },
      "source": [
        "#### TASK 6\n",
        "\n",
        "Complete `training_model` function that defines a simple recurrent network, trains it on the raining set and evaluates on the validation set.\n",
        "\n",
        "In the body of the function, define a simple recurrent network, with input size compatible with the vector dimensionality, output size compatible with the number of output classes (the number of different POS tags + 1 due to using 0 as padding in pos tag annotations) and a pre-defined hidden size. Don't forget to use `FastSRN` which was defined previously.\n",
        "\n",
        "<ins>Choose an appropriate combination of output activation and loss function</ins> (consider the task at hand and refer to the documentation or the tutorial/warm-up notebook if in doubt).\n",
        "\n",
        "Then instantiate an optimizer over your network and train the network for a specified number of epochs, measuring and printing all four metrics at the end of each epoch: for train and validation sets, loss and accuracy values.\n",
        "\n",
        "<font color=\"red\">_Hint_: Use `measure_accuracy` (defined earlier) to obtain accuracy. For the debugging you can try shorter hidden vectors and a single epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "psZY9rdGea1s"
      },
      "outputs": [],
      "source": [
        "# @title c6.1 [4pt]\n",
        "def training_model(nn_unit, num_epochs: int, hidden_dim: int=512,\n",
        "                   num_layers: int=1, device: str='cpu', seed: int=0) -> tuple:\n",
        "    \"\"\"\n",
        "    The code to train the model.\n",
        "    model is an object of torch.nn.Module, for example, srn.\n",
        "    num_epochs specifies how many epochs should be used for training\n",
        "    The function should train the model for the specified number of epochs.\n",
        "    It returns: train_losses (as a list), validation losses (as a list), train accuracies (as a list) and validation accuracies (as a list)\n",
        "    \"\"\"\n",
        "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
        "\n",
        "    srn = nn_unit(input_dim=X_train[0].size(1), hidden_dim=hidden_dim, output_dim=len(pos_to_int)+1,\n",
        "                  output_activation=torch.nn.LogSoftmax(dim=-1), num_layers=num_layers, device=device)\n",
        "    srn.to(device)\n",
        "    opt = torch.optim.Adam(srn.parameters())\n",
        "    loss_fn = torch.nn.NLLLoss(ignore_index=0)\n",
        "\n",
        "    # Seed makes sure that the shuffles done in the training set are same for each run\n",
        "    torch.manual_seed(seed)\n",
        "    for t in range(num_epochs):\n",
        "\n",
        "        train_loss = train_epoch(srn, train_dataloader, loss_fn, opt, device)\n",
        "        val_loss = eval_epoch(srn, val_dataloader, loss_fn, device)\n",
        "        train_acc = measure_accuracy(srn, train_dataloader, device)\n",
        "        val_acc = measure_accuracy(srn, val_dataloader, device)\n",
        "\n",
        "        print(f\"Epoch {t}\")\n",
        "        print(f\"\\tTraining / Validation Loss:     {train_loss} / {val_loss}\")\n",
        "        print(f\"\\tTraining / Validation Accuracy: {train_acc} / {val_acc}\")\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "    return srn, train_losses, val_losses, train_accuracies, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "niNIqTX_NeTC"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "expected scalar type Long but found Int",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[79], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TEST c6.1\u001b[39;00m\n\u001b[0;32m      2\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m srn, train_losses, val_losses, train_accuracies, val_accuracies \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m----> 4\u001b[0m     training_model(FastSRN, \u001b[38;5;241m10\u001b[39m, device\u001b[38;5;241m=\u001b[39mDEVICE)\n",
            "Cell \u001b[1;32mIn[78], line 22\u001b[0m, in \u001b[0;36mtraining_model\u001b[1;34m(nn_unit, num_epochs, hidden_dim, num_layers, device, seed)\u001b[0m\n\u001b[0;32m     19\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 22\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(srn, train_dataloader, loss_fn, opt, device)\n\u001b[0;32m     23\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m eval_epoch(srn, val_dataloader, loss_fn, device)\n\u001b[0;32m     24\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m measure_accuracy(srn, train_dataloader, device)\n",
            "Cell \u001b[1;32mIn[64], line 31\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(network, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, Y_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m---> 31\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m train_batch(network, X_batch, Y_batch, loss_fn, optimizer)\n\u001b[0;32m     32\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m     33\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
            "Cell \u001b[1;32mIn[64], line 16\u001b[0m, in \u001b[0;36mtrain_batch\u001b[1;34m(network, X_batch, Y_batch, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     15\u001b[0m Y_batch \u001b[38;5;241m=\u001b[39m Y_batch\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, Y_batch)\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\home_torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\home_torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\home_torch\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:216\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnll_loss(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\home_torch\\Lib\\site-packages\\torch\\nn\\functional.py:2729\u001b[0m, in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2728\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 2729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mnll_loss_nd(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Int"
          ]
        }
      ],
      "source": [
        "# TEST c6.1\n",
        "DEVICE =\"cpu\"\n",
        "srn, train_losses, val_losses, train_accuracies, val_accuracies = \\\n",
        "    training_model(FastSRN, 10, device=DEVICE) # feel free to change device value\n",
        "# Don't clear the output of this cell!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x_QAvaMzC2d"
      },
      "source": [
        "Plot the loss and accuracy curves for the training and validation sets. Set the x-axis for epoch number and y-axis for loss/accuracy values. Do this with the help of `plot_loss_accuracy` function. It is a good idea to wrap the plotting in a function as we will use it later too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csn1K--HRL62",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# @title c6.2 [1pt]\n",
        "# Your loss plotting here: x-axis for epochs and y-axis for train and validation losses\n",
        "\n",
        "def plot_loss_accuracy(train_losses: List[float], val_losses: List[float],\n",
        "                       train_accuracies: List[float], val_accuracies: List[float],\n",
        "                       baseline_accuracy: int) -> None:\n",
        "    \"\"\"\n",
        "    Display two plots, one for the loss curves for the training and validation sets\n",
        "    and the other for the accuracy curves.\n",
        "    (!) Mark the baseline accuracy as a horizontal line.\n",
        "    The function returns nothing, but displays the plots.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRUWcCzefUOS"
      },
      "outputs": [],
      "source": [
        "# TEST c6.2\n",
        "plot_loss_accuracy(train_losses, val_losses, train_accuracies, val_accuracies,\n",
        "                   unigram_score)\n",
        "# Don't clear the output of this cell!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsa5NUK3RL62"
      },
      "source": [
        "##### i6.3 [2pt]\n",
        "\n",
        "You should get accuracy above the baseline models discussed in Section 3 and 4. If your accuracy is lower than that, something is wrong.\n",
        "\n",
        "However, even though you beat the baseline model, you probably noticed that the accuracy is not very high. Most likely, it is below 50 percent on the validation set. Yet, POS tagging is basically a solved task nowadays - POS taggers usually have accuracy around 98 or 99 percent. Why is it that this model has a much lower accuracy? Say in a few sentences why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPgu9zikejol"
      },
      "source": [
        "**ANSWER**: <font color=\"red\">YOUR ANSWER HERE</font>  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC-am5sJRL62"
      },
      "source": [
        "### LSTM\n",
        "\n",
        "So far, we only worked with a simple recurrent neural network (which only had a single hidden layer). There are, however, many other more elaborated recurrent neural networks. One such recurrent neural network is LSTM (long short-term memory), which was developed mainly to battle one issue that simple RNNs battle with: the fact that gradient tends to vanish, making it hard for simple RNNs to update its weights across long sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QomW1ZbFRL62"
      },
      "source": [
        "#### TASK 7\n",
        "\n",
        "Implement an LSTM model. For this task, you can use the class `torch.nn.LSTM`. Before the implementation, make sure to check more details on ([link](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)). A few more notes: the code for your class should be similar to `FastSRN` but there is no specification for `hidden_activation` because activation across layers is already specified in the pytorch class. Second, make sure that you are using the unidirectional LSTM (if you used the bidirectional one, you would be predicting a POS tag based on preceding and following words, which is not what we want)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbzvvxf_RL63",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# @title c7.1 [1pt]\n",
        "\n",
        "class LSTMPredTag(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM module for predictions of POS tags using LSTM class in torch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int,\n",
        "        output_dim: int,\n",
        "        output_activation: Callable[[FloatTensor], FloatTensor],\n",
        "        num_layers: int = 1,\n",
        "        device: str = 'cpu'\n",
        "    ) -> None:\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    def forward(self, X:FloatTensor, hprev: Optional[FloatTensor]=None) -> FloatTensor:\n",
        "        \"\"\"\n",
        "        forward accepts a List of inputs X, an initial hidden vector hprev (h_{tâˆ’1}) and iteratively applies step until the input sequence is exhausted, returning a List of outputs Y (of the same length as X).\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFzuFikrRL63"
      },
      "source": [
        "Now, you can proceeed in the same way as with your RNN model.  \n",
        "Note that the arguments of `training_model` function was selected in such a way that the function can also accept `LSTMPredTag` and train LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWKRZwvARL64"
      },
      "outputs": [],
      "source": [
        "# TEST c7.1\n",
        "lstm, train_losses, val_losses, train_accuracies, val_accuracies = \\\n",
        "    training_model(LSTMPredTag, 10, device=DEVICE) # feel free to change device value\n",
        "# Don't clear the output of this cell!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy9rLPzbRL66"
      },
      "outputs": [],
      "source": [
        "# Let's plot the scores using the previously defined function\n",
        "plot_loss_accuracy(train_losses, val_losses, train_accuracies, val_accuracies, unigram_score)\n",
        "# Don't clear the output of this cell!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVPxYTTqRL66"
      },
      "source": [
        "If everything is correct, your LSTM model should beat your SRN model on both training and validation datasets (probably more so on the former).\n",
        "\n",
        "By tweaking certain hyperparameters in the network and its training, we can get better performance on the validation set. Your task is to experiment with different values for hyperparameters that are supported by `training_model` function: neural newtork unit, hidden dimension, the number of hidden layers, and the nuber of epochs.  \n",
        "After finding the combination of values that gives the highest accuracy on the validation set, provide the values below.  \n",
        "Don't provide any code that you used to find the optimal combinatin of the values.  \n",
        "Run the cell below with the optimal argument values and keep the output and plot. The score of your best model will be defined as the accuracy score on the validation set after the final epoch training.\n",
        "\n",
        "Bonus points 5, 3, and 2 will be given to the groups whose best score will make to the top three.\n",
        "\n",
        "<font color=\"red\">**Just fill in the optimal values that you found, train the model and plot the scores!**</font> No need to submit any other code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjBVspjse0MN"
      },
      "outputs": [],
      "source": [
        "# @title c7.2 [*]\n",
        "# training teh best model\n",
        "best_model, train_losses, val_losses, train_accuracies, val_accuracies = \\\n",
        "    training_model(FastSRN, # choose the network class\n",
        "                   num_epochs=5, # max 10\n",
        "                   hidden_dim=256, # whatever value you want\n",
        "                   num_layers=5, # you can also have as many hidden layers as you want\n",
        "                   device=DEVICE) # you should want gpu here\n",
        "print(f\"The best performance accuracy = {val_accuracies[-1]}\")\n",
        "# Don't clear the output of this cell!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk-teT6-gGyp"
      },
      "outputs": [],
      "source": [
        "plot_loss_accuracy(train_losses, val_losses, train_accuracies, val_accuracies, unigram_score)\n",
        "# Don't clear the output of this cell!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZhExpzzRL66"
      },
      "source": [
        "### Exploring the models\n",
        "\n",
        "We will now start exploring the models. We will start with the error analyis, in which we will find sentences from the validation set where the network predicted wrong POS tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdFRYTz0RL66"
      },
      "source": [
        "#### TASK 8\n",
        "\n",
        "Complete the function `predict_and_contrast` that returns, for a list of sentences, a list of lists of (word, true_tag, predicted_tag) triplets when the prediction of the model does not correspond to the actual tag, and a tuple (word, true_tag) when the prediction is right. Note that for the first word in a sentence, the model makes no predictions - you can collect the first word along with `None` as its tag.\n",
        "\n",
        "Concretely, for `['John sleeps .']`, assuming the model predicts VBZ and IN, the output should be:  \n",
        "`[[('John', None), ('sleeps', 'VBZ'), ('.', '.', 'IN')]]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoakyPSnRL67",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# @title c8.1 [3pt]\n",
        "\n",
        "def predict_and_contrast(nn: torch.nn.Module, sentences: list, tags: list, sent_vec: list, tag2idx: dict) -> list:\n",
        "    \"\"\"\n",
        "    :param nn: the network representing a POS tagger\n",
        "    :param sentences: the list of sentences\n",
        "    :param tags: a list of list of tags (aligned with sentences)\n",
        "    :param sent_vec: sentences with vectorized tokens\n",
        "    :param tag2idx: mapping of tags to indices\n",
        "    :param device: device for computation, defaults to the global DEVICE value\n",
        "    returns a list of sentences, where sentences are a list of tuples:\n",
        "        (token, tag) for correctly tagged tokens and\n",
        "        (token, reference_tag, predicted_tag) for wrongly tagged tokens\n",
        "    \"\"\"\n",
        "    int_to_pos = {v: k for k, v in tag2idx.items()}\n",
        "    all_predictions = []\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    return all_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-LJ59GleRN_"
      },
      "outputs": [],
      "source": [
        "# it is up to you which model to use here: srn, lstm, or best_model\n",
        "tok_gold_pred = predict_and_contrast(lstm, sentences_val, postags_val, X_val, pos_to_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnuNrIAvfw26"
      },
      "source": [
        "If you want to sanity check the implementation of the function. You could test whether you will get the same accuracy score from `tok_gold_pred` as the model got during the training-validation phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utTIBR5LeXK3"
      },
      "outputs": [],
      "source": [
        "# TEST c8.1\n",
        "# Don't clear the output of this cell!\n",
        "for s in tok_gold_pred[37:39]: # feel free to change the slice indices\n",
        "    print(' '.join([ f\"{t[0]}|{t[1]}\" if len(t) < 3 else f\"{t[0]}|{t[1]}|{t[2]}\" for t in s ]))\n",
        "    # we print just one tag when it is guessed correctly, two tags (true and predicted) when the model fails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHGxWzpSRL67"
      },
      "source": [
        "##### i8.2 [2pt]\n",
        "\n",
        "Among the examples printed by the above code cell, **find two examples** where the model successfully predicts the POS tag of an upcoming word and **two examples where it fails** to do so. All the examples could be from the same or different sentences.\n",
        "\n",
        "Describe what you observe for these cases. Does the model behave according to your intuitions? Does it get the prediction correct when it should be possible? Does it fail when it is hard to get the prediction right?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFIbI2hBc3XI"
      },
      "source": [
        "**ANSWER**: <font color=\"red\">YOUR ANSWER HERE</font>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KJVmPZnKcIE"
      },
      "source": [
        "Finally, find an answer to the following question regarding the validation set: which POS tag is most often correctly predicted? And which one is most often not predicted by the model?\n",
        "\n",
        "To get such tags, complete `tag_accuracy_cnt` function that takes predictions of the POS tags of an upcoming word and a cut-off value and returns a list of tuples of `('TAG', accuracy_score, number_of_occurrences_of_TAG)`. Note that `number_of_occurrences_of_TAG` should not be less than the cut-off value. The elements in the list are sorted in descending order of the accuracy score. The cut-off value helps to ignore rare POS tags that might be difficult/easy to predict because of their infrequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rJqKIZDKcIE"
      },
      "outputs": [],
      "source": [
        "# @title c8.3 [3pt]\n",
        "\n",
        "def tag_accuracy_cnt(tok_gold_predictions: List[tuple], freq_cut_off: int=100) -> List[tuple]:\n",
        "    \"\"\"\n",
        "    :param tok_gold_predictions: a list of sentences, where sentences are a list of tuples:\n",
        "        (token, tag) for correctly tagged tokens and\n",
        "        (token, reference_tag, predicted_tag) for wrongly tagged tokens\n",
        "    :param freq_cut_off: to ignore tags that are occurring less frequently\n",
        "    returns a list of tuples of (tag, tag_specific_accuracy_score, number_of_occurrences_of_tag)\n",
        "    the list is sorted in descending order of the accuracy score\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iRWbXlHlZw9"
      },
      "outputs": [],
      "source": [
        "# TEST c8.3\n",
        "tag_score_cnt = tag_accuracy_cnt(tok_gold_pred)\n",
        "\n",
        "assert all([ 0 <= i[1] <= 1 for i in tag_score_cnt ])\n",
        "assert tag_score_cnt[0][1] > tag_score_cnt[-1][1]\n",
        "\n",
        "tag_score_cnt\n",
        "# Don't clear the output of this cell!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYGTKwDm-IVz"
      },
      "source": [
        "##### i8.4 [2pt]\n",
        "\n",
        "Pick any POS tag at the beginning of the list (i.e., frequently correctly predicted tags) and any POS tag at the end of the list (i.e., frequently wrongly predicted tags). Provide rationale why these POS tags are often correctly and wrongly predicted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hALx-40w4422"
      },
      "source": [
        "**ANSWER**: <font color=\"red\">YOUR ANSWER HERE</font>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY9_NyYhRL67"
      },
      "source": [
        "### RNNs and human sentence processing\n",
        "\n",
        "We now move on to psycholinguistics and sentence processing.\n",
        "\n",
        "You might have wondered up to now: what is the point of the model predicting a POS tag of the upcoming word? Who needs that? Would it not be easier to simply wait for the word and assign the POS tag when we observe it? Indeed, that would make the correctness of POS labels for a sequence go way up. Such a task is much much easier.\n",
        "\n",
        "The reason we want to predict a POS tag is not to get POS labels right: we actually do not care about them at all; we do this to *get a model that can be useful to study human sentence processing* (just like we let language models predict, not observe the upcoming word, to create models that reflects human creativity and language competence). So the real question is: is our model a good approximation of human sentence processing?\n",
        "\n",
        "We know that people constantly predict upcoming text, including abstract information like categories. When the actual text does not match our predictions, cognitive difficulties ensue. Such difficulties can be very subtle and only measurable with techniques like eye tracking or EEG (when the mismatch between predictions and the actuality is small) or can be very robust and observable even by, say, introspections (e.g., some sentences might feel odd). In order to know whether our model is any good as a model of processing, we need to know whether there is correspondence between (i) good/bad predictions of our models and (ii) cognitive easiness/difficulties experiences by language users? We explore that in Task 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huBGOr4cRL67"
      },
      "source": [
        "#### TASK 9\n",
        "\n",
        "We want to first measure how surprising a particular outcome is. The standard measure for this is *surprisal*. *Surprisal* is a log of inverse probability. That is, if our model predicts that a particular POS appears with the probability $p$, we calculate its suprisal $s$ as:\n",
        "$s=\\log(1/p)=-\\log(p)$\n",
        "\n",
        "With this background, implement the function `get_surprisals`, which returns, for a list of sentences, a list of lists of tuples (word, $s$) where $s$ is the surprisal value that the model has for *true tag*. The function to some extent does the same initial steps as `predict_and_contrast`.  \n",
        "<font color=\"red\">_Hint_: you should take into account what the output vector of the RNN model represents and how it is related to a log-probability distribution over POS tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iG7mgjyRL67",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# @title c9.1 [3pt]\n",
        "def get_surprisals(nn, sentences: list, tags: list, sent_vec: list, tag2idx: dict):\n",
        "    \"\"\"\n",
        "    :param nn: the network representing a POS tagger\n",
        "    :param sentences: the list of sentences\n",
        "    :param tags: a list of list of tags (aligned with sentences)\n",
        "    :param sent_vec: sentences with vectorized tokens\n",
        "    :param tag2idx: mapping of tags to indices\n",
        "    :param device: device for computation, defaults to the global DEVICE value\n",
        "    returns a list of sentences, where sentences are a list of tuples:\n",
        "        (token, reference_tag, surprisal)\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPx_qrLVRL68"
      },
      "outputs": [],
      "source": [
        "# TEST c9.1\n",
        "sent_tags_surp = get_surprisals(lstm, sentences_val, postags_val, X_val, pos_to_int)\n",
        "\n",
        "assert all([ len(t) == 3 for s in sent_tags_surp for t in s ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7TZhqOzRL67"
      },
      "source": [
        "Now, check the code on a few sentences from the validation set. You should see that often, where the model was off with its prediction (as noticed in Task 8), the surprisal should be higher, where it was correct, it should be lower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx5NMBAJLf6s"
      },
      "outputs": [],
      "source": [
        "# we check the surprisal values for 2 sentences (feel free to pick your own sentences)\n",
        "for s in sent_tags_surp[37:39]: # feel free to change the slice indices\n",
        "    print('\\n'.join([ f\"{t[0]}|{t[1]}|{t[2]:.6f}\" for t in s  ]), end=\"\\n\\n\") # we translate surprisal back to probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f862dqrKcIG"
      },
      "source": [
        "Finally, let's check the average surprisal per POS tag. What POS has the lowest average surprisal? And what POS has the highest surprisal? The result should be correlated with the accuracy scores per tag: more predictable tags get lower surprisal and less predictable tags higher surprisal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76nuHSBRKcIG"
      },
      "outputs": [],
      "source": [
        "# @title c9.2 [1pt]\n",
        "def tag_surprisal(sent_tag_surp: list, cut_off: int=100) -> list:\n",
        "    \"\"\"\n",
        "    :param sent_tag_surp: a list of sentences, where sentences are a list of tuples:\n",
        "        (token, correct POS tag, surprisal of the POS tag)\n",
        "    :param cut_off: the minimum number of occurrences of a POS tag\n",
        "    return a list of tuples of (tag, average_surprisal, number_of_occurrences_of_tag)\n",
        "    the list is sorted in ascending order of the average_surprisal\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2luPtEzFSHS5"
      },
      "outputs": [],
      "source": [
        "# TEST c9.2\n",
        "tag_avg_surp = tag_surprisal(sent_tags_surp, cut_off=100)\n",
        "\n",
        "assert all([ len(i) == 3 for i in tag_avg_surp ])\n",
        "assert tag_avg_surp[0][1] < tag_avg_surp[-1][1]\n",
        "\n",
        "tag_avg_surp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJysJ-4oRL68"
      },
      "source": [
        "#### TASK 10\n",
        "\n",
        "One famous case of processing difficulties is represented by [garden-path sentences](https://en.wikipedia.org/wiki/Garden-path_sentence): sentences that are hard to parse. The reason that garden path sentences are hard to parse is because they do not match our expectations.\n",
        "\n",
        "Do we see the same with the models?\n",
        "\n",
        "Below, we collected sentences (printed in pairs, such that the first element in the pair is a garden-path sentence, the second element is a minimally different sentence which carries the same interpretation but which is not garden path because the expected interpretation is signalled early on). The comments show names under which such garden path constructions are categorized in literature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtDGZdx0RL68"
      },
      "outputs": [],
      "source": [
        "# some examples\n",
        "gps = [\n",
        "    \"The banker informed about the recession resigned .\", \"The banker who was informed about the recession resigned .\", # main-clause/reduced relative ambiguity\n",
        "    \"Before the manager walks the dog is happy .\", \"Before the manager walks , the dog is happy .\", # NP/Z ambiguity\n",
        "    \"I saw the students danced .\", \"I saw that the students danced .\", #NP/S ambiguity\n",
        "    \"The man put the book on the towel into the box\", \"The man put the book that was on the towel into the box\"] #PP ambiguity\n",
        "    # ADD NEW SENTENCE PAIR (see i10): garden path and its disambiguated version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eexcn3EJRL68"
      },
      "source": [
        "We let `spaCy` create docs out of the sentences (just as we did for training and validation), then we collect POS tags as generated by `spaCy` and create tensors for words and tags. Fortunately, spaCy's POS tagger is enough precise to tag the given sentences correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWVMaOtYRL69"
      },
      "outputs": [],
      "source": [
        "gps_docs = [ spacy.tokens.doc.Doc(nlp.vocab, words=s.split()) for s in gps ]\n",
        "\n",
        "gps_postags = [ [word.tag_ for word in nlp(s)] for s in gps ]\n",
        "\n",
        "print(gps_postags)\n",
        "\n",
        "# convert to tensors\n",
        "gps_vectors = [ np.array([word.vector for word in doc]) for doc in gps_docs ]\n",
        "gps_tensors = [ torch.tensor(sentence_vectors) for sentence_vectors in gps_vectors ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJaRBff3RL69"
      },
      "source": [
        "##### i10 [6pt]\n",
        "\n",
        "Run your models on the sentences and collect surprisals for both LSTM and SRN models.\n",
        "\n",
        "Inspect and describe the results. Do models capture any of the cases right?\n",
        "\n",
        "When answering these questions, keep in mind that we do not care about surprisal values for all words. We only care about surprisal values for those words at which people experience surprises about the sentences: these are the verbs 'resigned', 'is', 'danced', and the preposition 'into' in the examples above. Do the models assign higher surprisals/lower probabilities to the target words in garden paths compared to minimally different sentences? And do the two models differ? If so, speculate why this might be. **Also, add one extra pair of a garden path and inspect its surprisal values.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9dXQFR6RL69"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# use some code lines from task 9\n",
        "# Don't clear the output of this cell!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XreXf0Eqx9_"
      },
      "source": [
        "**ANSWER**: <font color=\"red\">YOUR ANSWER HERE</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbgNN_S8W9Y6"
      },
      "source": [
        "# Acknowledgment\n",
        "\n",
        "The jupyter notebook was initially created by Konstantinos Kogkalidis and Tejaswini Deoskar.  \n",
        "The changes, including adaptation to the Colab environment and formulation of several coding tasks in terms of functions, are by Lasha Abzianidze.\n",
        "Modeling surprisal of the next words POS tag was added by Jakub Dotlacil."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "home_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
